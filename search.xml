<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>算法竞赛对拍用法 Java版</title>
      <link href="/2025/03/11/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%AF%B9%E6%8B%8D%E7%94%A8%E6%B3%95-Java%E7%89%88/"/>
      <url>/2025/03/11/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%AF%B9%E6%8B%8D%E7%94%A8%E6%B3%95-Java%E7%89%88/</url>
      
        <content type="html"><![CDATA[<h1 id="Java算法竞赛对拍笔记"><a href="#Java算法竞赛对拍笔记" class="headerlink" title="Java算法竞赛对拍笔记"></a>Java算法竞赛对拍笔记</h1><h2 id="一、对拍概述"><a href="#一、对拍概述" class="headerlink" title="一、对拍概述"></a>一、对拍概述</h2><p>对拍是一种检测代码错误的方法，主要通过对比两个程序的输出结果来实现。<br>包含以下几个关键部分：</p><ol><li><strong>暴力程序</strong>：正确但低效的算法，通常采用完全搜索等方式。</li><li><strong>待测程序</strong>：优化后的算法，需要验证其正确性。</li><li><strong>数据生成器</strong>：随机生成符合要求的测试数据。</li><li><strong>对拍脚本</strong>：自动运行并比较两个程序的输出结果。</li></ol><h2 id="二、对拍步骤与组件"><a href="#二、对拍步骤与组件" class="headerlink" title="二、对拍步骤与组件"></a>二、对拍步骤与组件</h2><h3 id="1-数据生成器（Maker）"><a href="#1-数据生成器（Maker）" class="headerlink" title="1. 数据生成器（Maker）"></a>1. 数据生成器（Maker）</h3><p><strong>作用</strong>：生成符合输入格式的随机测试数据。<br><strong>示例代码（Java）</strong>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Maker</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> (<span class="type">PrintWriter</span> <span class="variable">out</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PrintWriter</span>(<span class="string">&quot;input.txt&quot;</span>)) &#123;</span><br><span class="line">            <span class="type">Random</span> <span class="variable">rnd</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Random</span>();</span><br><span class="line">            <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> rnd.nextInt(<span class="number">10</span>) + <span class="number">1</span>; <span class="comment">// 随机生成测试数据</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> rnd.nextInt(<span class="number">100</span>);</span><br><span class="line">            out.println(n + <span class="string">&quot; &quot;</span> + m);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">                out.println(rnd.nextInt(<span class="number">100</span>) + <span class="string">&quot; &quot;</span> + rnd.nextInt(<span class="number">100</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-暴力程序（Brute-Force）"><a href="#2-暴力程序（Brute-Force）" class="headerlink" title="2. 暴力程序（Brute Force）"></a>2. 暴力程序（Brute Force）</h3><p><strong>作用</strong>：使用简单但正确的算法生成答案。<br><strong>示例代码（Java）</strong>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Brute</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Scanner</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scanner</span>(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;input.txt&quot;</span>));</span><br><span class="line">        <span class="type">PrintWriter</span> <span class="variable">out</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PrintWriter</span>(<span class="string">&quot;brute.out&quot;</span>);</span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> in.nextInt();</span><br><span class="line">        <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> in.nextInt();</span><br><span class="line">        <span class="comment">// 示例：0-1背包暴力解法（枚举所有可能）</span></span><br><span class="line">        <span class="type">int</span>[] w = <span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line">        <span class="type">int</span>[] c = <span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">            w[i] = in.nextInt();</span><br><span class="line">            c[i] = in.nextInt();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">int</span> <span class="variable">max</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">mask</span> <span class="operator">=</span> <span class="number">0</span>; mask &lt; (<span class="number">1</span> &lt;&lt; n); mask++) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">weight</span> <span class="operator">=</span> <span class="number">0</span>, cost = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">                <span class="keyword">if</span> ((mask &amp; (<span class="number">1</span> &lt;&lt; i)) != <span class="number">0</span>) &#123;</span><br><span class="line">                    weight += w[i];</span><br><span class="line">                    cost += c[i];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (weight &lt;= m &amp;&amp; cost &gt; max) &#123;</span><br><span class="line">                max = cost;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        out.println(max);</span><br><span class="line">        out.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-待测程序（Solution）"><a href="#3-待测程序（Solution）" class="headerlink" title="3. 待测程序（Solution）"></a>3. 待测程序（Solution）</h3><p><strong>作用</strong>：实现优化算法，需与暴力程序结果一致。<br><strong>示例代码（Java）</strong>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Scanner</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scanner</span>(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;input.txt&quot;</span>));</span><br><span class="line">        <span class="type">PrintWriter</span> <span class="variable">out</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PrintWriter</span>(<span class="string">&quot;solution.out&quot;</span>);</span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> in.nextInt();</span><br><span class="line">        <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> in.nextInt();</span><br><span class="line">        <span class="comment">// 示例：0-1背包动态规划解法</span></span><br><span class="line">        <span class="type">int</span>[] w = <span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line">        <span class="type">int</span>[] c = <span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">            w[i] = in.nextInt();</span><br><span class="line">            c[i] = in.nextInt();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">int</span>[] dp = <span class="keyword">new</span> <span class="title class_">int</span>[m + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> m; j &gt;= w[i]; j--) &#123;</span><br><span class="line">                dp[j] = Math.max(dp[j], dp[j - w[i]] + c[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        out.println(dp[m]);</span><br><span class="line">        out.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-对拍脚本"><a href="#4-对拍脚本" class="headerlink" title="4. 对拍脚本"></a>4. 对拍脚本</h3><p><strong>作用</strong>：自动运行生成器、暴力程序、待测程序，并比较输出结果。<br><strong>Windows批处理脚本示例</strong>：</p><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line">:loop</span><br><span class="line"><span class="built_in">echo</span> 正在生成数据...</span><br><span class="line">javac Maker.java</span><br><span class="line">java Maker &gt; input.txt</span><br><span class="line"><span class="built_in">echo</span> 正在运行暴力程序...</span><br><span class="line">javac Brute.java</span><br><span class="line">java Brute &lt; input.txt &gt; brute.out</span><br><span class="line"><span class="built_in">echo</span> 正在运行待测程序...</span><br><span class="line">javac Solution.java</span><br><span class="line">java Solution &lt; input.txt &gt; solution.out</span><br><span class="line"><span class="built_in">echo</span> 正在比较结果...</span><br><span class="line">fc brute.out solution.out</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">errorlevel</span> <span class="number">1</span> (</span><br><span class="line">    <span class="built_in">echo</span> 出错！请检查代码！</span><br><span class="line">    <span class="built_in">pause</span></span><br><span class="line">    <span class="keyword">exit</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">echo</span> 测试通过，继续下一轮...</span><br><span class="line"><span class="keyword">goto</span> loop</span><br></pre></td></tr></table></figure><p><strong>Linux Bash脚本示例</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="comment"># 生成数据</span></span><br><span class="line">    javac Maker.java &amp;&amp; java Maker &gt; input.txt</span><br><span class="line">    <span class="comment"># 运行暴力程序</span></span><br><span class="line">    javac Brute.java &amp;&amp; java Brute &lt; input.txt &gt; brute.out</span><br><span class="line">    <span class="comment"># 运行待测程序</span></span><br><span class="line">    javac Solution.java &amp;&amp; java Solution &lt; input.txt &gt; solution.out</span><br><span class="line">    <span class="comment"># 比较结果</span></span><br><span class="line">    diff brute.out solution.out</span><br><span class="line">    <span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Error! 请检查代码！&quot;</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;AC! 继续测试...&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h2 id="三、注意事项"><a href="#三、注意事项" class="headerlink" title="三、注意事项"></a>三、注意事项</h2><ol><li><strong>输入输出一致性</strong>：<ul><li>确保所有程序的输入输出格式一致（如空格、换行符）。</li><li>使用 <code>System.in</code> 和 <code>System.out</code> 以便重定向，或手动读写文件。</li></ul></li><li><strong>数据覆盖</strong>：<ul><li>数据生成器需覆盖边界条件（如最大值、最小值、极端情况）。</li></ul></li><li><strong>程序效率</strong>：<ul><li>暴力程序可能在大数据时超时，可限制生成数据规模。</li></ul></li><li><strong>错误处理</strong>：<ul><li>检查程序是否崩溃或输出异常（如 <code>NullPointerException</code>）。</li></ul></li><li><strong>环境配置</strong>：<ul><li>确保 Java 环境变量正确，路径无误。</li><li>在 Linux 下给脚本执行权限：<code>chmod +x script.sh</code>。</li></ul></li></ol><h2 id="四、调试技巧"><a href="#四、调试技巧" class="headerlink" title="四、调试技巧"></a>四、调试技巧</h2><ul><li><strong>手动测试</strong>：<ol><li>手动生成小规模数据（如 <code>n=3</code>）。</li><li>手动运行程序并对比输出。</li></ol></li><li><strong>逐步调试</strong>：<ul><li>在程序中添加 <code>System.out.println</code> 输出中间变量，检查逻辑错误。</li></ul></li></ul><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>对拍是调试算法竞赛代码的有效工具，通过自动化测试能快速定位错误。熟练掌握对拍流程，可显著减少因细节错误导致的扣分。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>蓝桥杯15省赛真题</title>
      <link href="/2025/03/10/%E8%93%9D%E6%A1%A5%E6%9D%AF15%E7%9C%81%E8%B5%9B%E7%9C%9F%E9%A2%98/"/>
      <url>/2025/03/10/%E8%93%9D%E6%A1%A5%E6%9D%AF15%E7%9C%81%E8%B5%9B%E7%9C%9F%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="蓝桥杯第十五届省赛真题解析"><a href="#蓝桥杯第十五届省赛真题解析" class="headerlink" title="蓝桥杯第十五届省赛真题解析"></a>蓝桥杯第十五届省赛真题解析</h1><h2 id="编码说明"><a href="#编码说明" class="headerlink" title="编码说明"></a>编码说明</h2><p>本文档中的所有代码和文本均使用UTF-8编码，以确保中文内容能够正常显示。如果您在查看代码时遇到中文乱码问题，请检查以下几点：</p><ol><li>确保您的编辑器设置为UTF-8编码</li><li>Java源文件(.java)的编码应该是UTF-8</li><li>如果使用Windows系统，建议在编译时添加<code>-encoding UTF-8</code>参数</li></ol><h2 id="解题环境"><a href="#解题环境" class="headerlink" title="解题环境"></a>解题环境</h2><ul><li>编程语言：Java</li><li>JDK版本：Java 8或更高版本</li><li>编译参数：<code>javac -encoding UTF-8 Solution.java</code></li><li>运行方式：<code>java Solution</code></li></ul><h2 id="输入输出说明"><a href="#输入输出说明" class="headerlink" title="输入输出说明"></a>输入输出说明</h2><p>本套试题的输入输出均采用标准输入输出流（System.in和System.out）。为了提高输入输出效率，建议使用以下方法：</p><ol><li>使用BufferedReader代替Scanner</li><li>使用StringBuilder进行字符串拼接</li><li>使用PrintWriter进行输出</li></ol><h2 id="解题注意事项"><a href="#解题注意事项" class="headerlink" title="解题注意事项"></a>解题注意事项</h2><ol><li>注意数据范围和边界条件</li><li>合理使用数据结构，注意时间复杂度</li><li>对于需要取模的题目，注意中间结果可能溢出</li><li>注意代码的规范性和可读性</li></ol><h2 id="试题目录"><a href="#试题目录" class="headerlink" title="试题目录"></a>试题目录</h2><ol><li>试题A：[题目名称]</li><li>试题B：[题目名称]</li><li>试题C：[题目名称]</li><li>试题D：[题目名称]</li><li>试题E：[题目名称]</li><li>试题F：[题目名称]</li><li>试题G：[题目名称]</li><li>试题H：[题目名称]</li><li>试题I：[题目名称]</li><li>试题J：[题目名称]</li></ol><h2 id="详细解析"><a href="#详细解析" class="headerlink" title="详细解析"></a>详细解析</h2><h3 id="试题A：-题目名称"><a href="#试题A：-题目名称" class="headerlink" title="试题A：[题目名称]"></a>试题A：[题目名称]</h3><h4 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h4><p>[在这里添加题目描述]</p><h4 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h4><p>[在这里添加输入格式说明]</p><h4 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h4><p>[在这里添加输出格式说明]</p><h4 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h4><p>[在这里添加解题思路分析]</p><h4 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在这里添加Java示例代码</span></span><br></pre></td></tr></table></figure><h4 id="要点说明"><a href="#要点说明" class="headerlink" title="要点说明"></a>要点说明</h4><p>[在这里添加代码要点和注意事项]</p><p>[继续添加其他试题的解析…]</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本次省赛的试题涵盖了多个算法知识点，包括：</p><ol><li>[知识点1]</li><li>[知识点2]</li><li>[知识点3]</li></ol><p>通过本套试题的练习，可以帮助我们：</p><ol><li>提高算法设计能力</li><li>加强代码实现能力</li><li>培养问题分析能力</li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>[参考资料1]</li><li>[参考资料2]</li><li>[参考资料3]</li></ol>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> 蓝桥杯 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 蓝桥杯 </tag>
            
            <tag> 算法 </tag>
            
            <tag> 真题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java数据结构实现详解</title>
      <link href="/2025/03/10/Java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/"/>
      <url>/2025/03/10/Java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="Java数据结构实现详解"><a href="#Java数据结构实现详解" class="headerlink" title="Java数据结构实现详解"></a>Java数据结构实现详解</h1><p>本文详细介绍了各种基本数据结构的Java实现，包括线性数据结构和非线性数据结构。每种数据结构都包含了基本操作方法、时间复杂度分析以及使用示例，可以作为学习数据结构与算法的参考资料。</p><h2 id="一、线性数据结构"><a href="#一、线性数据结构" class="headerlink" title="一、线性数据结构"></a>一、线性数据结构</h2><p>线性数据结构是一种数据元素之间存在一对一关系的数据结构，元素按照线性顺序排列。</p><h3 id="1-数组-Array"><a href="#1-数组-Array" class="headerlink" title="1. 数组 (Array)"></a>1. 数组 (Array)</h3><p>数组是最基本的数据结构，它在内存中是连续存储的，可以通过索引快速访问元素。</p><p><strong>特点：</strong></p><ul><li>固定大小（静态数组）或可动态调整大小（动态数组）</li><li>随机访问元素的时间复杂度为 O(1)</li><li>在数组中间插入或删除元素的时间复杂度为 O(n)</li></ul><p><strong>主要操作及时间复杂度：</strong></p><ul><li>访问元素：O(1)</li><li>在末尾添加&#x2F;删除元素：O(1) 均摊</li><li>在中间添加&#x2F;删除元素：O(n)</li><li>查找元素：O(n)</li></ul><p><strong>数组结构示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+---+---+---+---+---+---+</span><br><span class="line">| 1 | 2 | 3 | 4 | 5 | 6 |  -&gt; 索引: 0,1,2,3,4,5</span><br><span class="line">+---+---+---+---+---+---+</span><br></pre></td></tr></table></figure><p><strong>代码示例：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DynamicArray</span>&lt;E&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> E[] data;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> size;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 构造函数，传入数组的容量capacity构造Array</span></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">DynamicArray</span><span class="params">(<span class="type">int</span> capacity)</span> &#123;</span><br><span class="line">        data = (E[])<span class="keyword">new</span> <span class="title class_">Object</span>[capacity];</span><br><span class="line">        size = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取数组中的元素个数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getSize</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> size;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取数组的容量</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getCapacity</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> data.length;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 在index位置插入一个新元素e</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> index, E e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">0</span> || index &gt; size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Add failed. Require index &gt;= 0 and index &lt;= size.&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(size == data.length)</span><br><span class="line">            resize(<span class="number">2</span> * data.length);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> size - <span class="number">1</span>; i &gt;= index ; i --)</span><br><span class="line">            data[i + <span class="number">1</span>] = data[i];</span><br><span class="line">        </span><br><span class="line">        data[index] = e;</span><br><span class="line">        size ++;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取index索引位置的元素</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">get</span><span class="params">(<span class="type">int</span> index)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">0</span> || index &gt;= size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Get failed. Index is illegal.&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> data[index];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 修改index索引位置的元素为e</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">int</span> index, E e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">0</span> || index &gt;= size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Set failed. Index is illegal.&quot;</span>);</span><br><span class="line">        data[index] = e;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 查找数组中是否有元素e</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">contains</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(data[i].equals(e))</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 删除index位置的元素，返回删除的元素</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">remove</span><span class="params">(<span class="type">int</span> index)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">0</span> || index &gt;= size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Remove failed. Index is illegal.&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="type">E</span> <span class="variable">ret</span> <span class="operator">=</span> data[index];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> index + <span class="number">1</span>; i &lt; size; i++)</span><br><span class="line">            data[i - <span class="number">1</span>] = data[i];</span><br><span class="line">        size--;</span><br><span class="line">        data[size] = <span class="literal">null</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(size == data.length / <span class="number">4</span> &amp;&amp; data.length / <span class="number">2</span> != <span class="number">0</span>)</span><br><span class="line">            resize(data.length / <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 将数组空间的容量变成newCapacity大小</span></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">resize</span><span class="params">(<span class="type">int</span> newCapacity)</span> &#123;</span><br><span class="line">        E[] newData = (E[])<span class="keyword">new</span> <span class="title class_">Object</span>[newCapacity];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">            newData[i] = data[i];</span><br><span class="line">        data = newData;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>操作示意图：</strong></p><p>在索引2处插入元素：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">原数组：</span><br><span class="line">+---+---+---+---+---+---+</span><br><span class="line">| 1 | 2 | 3 | 4 | 5 | - |</span><br><span class="line">+---+---+---+---+---+---+</span><br><span class="line"></span><br><span class="line">移动元素：</span><br><span class="line">+---+---+---+---+---+---+</span><br><span class="line">| 1 | 2 | - | 3 | 4 | 5 |</span><br><span class="line">+---+---+---+---+---+---+</span><br><span class="line"></span><br><span class="line">插入新元素：</span><br><span class="line">+---+---+---+---+---+---+</span><br><span class="line">| 1 | 2 | 6 | 3 | 4 | 5 |</span><br><span class="line">+---+---+---+---+---+---+</span><br></pre></td></tr></table></figure><p><strong>应用场景：</strong></p><ul><li>需要频繁随机访问元素的场景</li><li>数据量固定的场景</li><li>需要存储基本数据类型的场景</li><li>多维数据结构（如矩阵）的实现</li></ul><h3 id="2-链表-LinkedList"><a href="#2-链表-LinkedList" class="headerlink" title="2. 链表 (LinkedList)"></a>2. 链表 (LinkedList)</h3><p>链表是由一系列节点组成的线性集合，每个节点包含数据和指向下一个节点的引用。</p><h3 id="3-栈-Stack"><a href="#3-栈-Stack" class="headerlink" title="3. 栈 (Stack)"></a>3. 栈 (Stack)</h3><p>栈是一种后进先出（LIFO）的线性数据结构，只允许在一端（栈顶）进行插入和删除操作。</p><h2 id="二、树形数据结构"><a href="#二、树形数据结构" class="headerlink" title="二、树形数据结构"></a>二、树形数据结构</h2><p>树形数据结构是一种非线性数据结构，它以层次方式存储数据，每个节点可以有多个子节点。</p><h3 id="1-二叉树-Binary-Tree"><a href="#1-二叉树-Binary-Tree" class="headerlink" title="1. 二叉树 (Binary Tree)"></a>1. 二叉树 (Binary Tree)</h3><p>二叉树是每个节点最多有两个子节点的树形数据结构。</p><p><strong>二叉树的结构示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    1</span><br><span class="line">   / \</span><br><span class="line">  2   3</span><br><span class="line"> / \   \</span><br><span class="line">4   5   6</span><br><span class="line">   /</span><br><span class="line">  7</span><br></pre></td></tr></table></figure><p><strong>代码实现：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BinaryTree</span>&lt;E&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> E data;</span><br><span class="line">        <span class="keyword">public</span> Node left, right;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">Node</span><span class="params">(E data)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.data = data;</span><br><span class="line">            left = <span class="literal">null</span>;</span><br><span class="line">            right = <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node root;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> size;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BinaryTree</span><span class="params">()</span> &#123;</span><br><span class="line">        root = <span class="literal">null</span>;</span><br><span class="line">        size = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 前序遍历</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">preOrder</span><span class="params">()</span> &#123;</span><br><span class="line">        preOrder(root);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">preOrder</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        </span><br><span class="line">        System.out.println(node.data);</span><br><span class="line">        preOrder(node.left);</span><br><span class="line">        preOrder(node.right);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 中序遍历</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">inOrder</span><span class="params">()</span> &#123;</span><br><span class="line">        inOrder(root);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">inOrder</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">        inOrder(node.left);</span><br><span class="line">        System.out.println(node.data);</span><br><span class="line">        inOrder(node.right);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 后序遍历</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">postOrder</span><span class="params">()</span> &#123;</span><br><span class="line">        postOrder(root);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">postOrder</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">        postOrder(node.left);</span><br><span class="line">        postOrder(node.right);</span><br><span class="line">        System.out.println(node.data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 层序遍历</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">levelOrder</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">        Queue&lt;Node&gt; queue = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();</span><br><span class="line">        queue.add(root);</span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty()) &#123;</span><br><span class="line">            <span class="type">Node</span> <span class="variable">cur</span> <span class="operator">=</span> queue.remove();</span><br><span class="line">            System.out.println(cur.data);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>(cur.left != <span class="literal">null</span>)</span><br><span class="line">                queue.add(cur.left);</span><br><span class="line">            <span class="keyword">if</span>(cur.right != <span class="literal">null</span>)</span><br><span class="line">                queue.add(cur.right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-二叉搜索树-Binary-Search-Tree"><a href="#2-二叉搜索树-Binary-Search-Tree" class="headerlink" title="2. 二叉搜索树 (Binary Search Tree)"></a>2. 二叉搜索树 (Binary Search Tree)</h3><p>二叉搜索树是一种特殊的二叉树，它满足以下性质：</p><ul><li>左子树上所有节点的值均小于当前节点的值</li><li>右子树上所有节点的值均大于当前节点的值</li><li>左右子树也分别是二叉搜索树</li></ul><p><strong>二叉搜索树示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    5</span><br><span class="line">   / \</span><br><span class="line">  3   7</span><br><span class="line"> / \   \</span><br><span class="line">2   4   8</span><br></pre></td></tr></table></figure><p><strong>代码实现：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BST</span>&lt;E <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;E&gt;&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> E data;</span><br><span class="line">        <span class="keyword">public</span> Node left, right;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">Node</span><span class="params">(E data)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.data = data;</span><br><span class="line">            left = <span class="literal">null</span>;</span><br><span class="line">            right = <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node root;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> size;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BST</span><span class="params">()</span> &#123;</span><br><span class="line">        root = <span class="literal">null</span>;</span><br><span class="line">        size = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向二分搜索树中添加新的元素e</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        root = add(root, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向以node为根的二分搜索树中插入元素e，递归算法</span></span><br><span class="line">    <span class="keyword">private</span> Node <span class="title function_">add</span><span class="params">(Node node, E e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="literal">null</span>) &#123;</span><br><span class="line">            size++;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Node</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(e.compareTo(node.data) &lt; <span class="number">0</span>)</span><br><span class="line">            node.left = add(node.left, e);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(e.compareTo(node.data) &gt; <span class="number">0</span>)</span><br><span class="line">            node.right = add(node.right, e);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查找二分搜索树中是否包含元素e</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">contains</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> contains(root, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 看以node为根的二分搜索树中是否包含元素e，递归算法</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">contains</span><span class="params">(Node node, E e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(e.compareTo(node.data) == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(e.compareTo(node.data) &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> contains(node.left, e);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> contains(node.right, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 删除最小值所在节点，返回最小值</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">removeMin</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">E</span> <span class="variable">ret</span> <span class="operator">=</span> minimum();</span><br><span class="line">        root = removeMin(root);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 删除以node为根的二分搜索树中的最小节点</span></span><br><span class="line">    <span class="comment">// 返回删除节点后新的二分搜索树的根</span></span><br><span class="line">    <span class="keyword">private</span> Node <span class="title function_">removeMin</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node.left == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">Node</span> <span class="variable">rightNode</span> <span class="operator">=</span> node.right;</span><br><span class="line">            node.right = <span class="literal">null</span>;</span><br><span class="line">            size--;</span><br><span class="line">            <span class="keyword">return</span> rightNode;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        node.left = removeMin(node.left);</span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 寻找二分搜索树的最小元素</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">minimum</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(size == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;BST is empty&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> minimum(root).data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回以node为根的二分搜索树的最小值所在的节点</span></span><br><span class="line">    <span class="keyword">private</span> Node <span class="title function_">minimum</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node.left == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span> node;</span><br><span class="line">        <span class="keyword">return</span> minimum(node.left);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>应用场景：</strong></p><ul><li>文件系统的目录结构</li><li>数据库索引</li><li>表达式解析</li><li>优先队列实现</li></ul><h3 id="3-平衡二叉树-AVL-Tree"><a href="#3-平衡二叉树-AVL-Tree" class="headerlink" title="3. 平衡二叉树 (AVL Tree)"></a>3. 平衡二叉树 (AVL Tree)</h3><p>AVL树是一种自平衡二叉搜索树，任何节点的两个子树的高度差不超过1。</p><p><strong>AVL树的结构示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  节点的平衡因子 = 左子树高度 - 右子树高度</span><br><span class="line"></span><br><span class="line">     4(0)</span><br><span class="line">    /    \</span><br><span class="line"> 2(-1)    6(0)</span><br><span class="line">  /      /   \</span><br><span class="line">1(0)   5(0)  7(0)</span><br></pre></td></tr></table></figure><p><strong>代码实现：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AVLTree</span>&lt;E <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;E&gt;&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> E data;</span><br><span class="line">        <span class="keyword">public</span> Node left, right;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> height;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">Node</span><span class="params">(E data)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.data = data;</span><br><span class="line">            left = <span class="literal">null</span>;</span><br><span class="line">            right = <span class="literal">null</span>;</span><br><span class="line">            height = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node root;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> size;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获得节点的高度</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="title function_">getHeight</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> node.height;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获得节点的平衡因子</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="title function_">getBalanceFactor</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> getHeight(node.left) - getHeight(node.right);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 右旋转</span></span><br><span class="line">    <span class="keyword">private</span> Node <span class="title function_">rightRotate</span><span class="params">(Node y)</span> &#123;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">x</span> <span class="operator">=</span> y.left;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">T3</span> <span class="operator">=</span> x.right;</span><br><span class="line"></span><br><span class="line">        x.right = y;</span><br><span class="line">        y.left = T3;</span><br><span class="line"></span><br><span class="line">        y.height = Math.max(getHeight(y.left), getHeight(y.right)) + <span class="number">1</span>;</span><br><span class="line">        x.height = Math.max(getHeight(x.left), getHeight(x.right)) + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 左旋转</span></span><br><span class="line">    <span class="keyword">private</span> Node <span class="title function_">leftRotate</span><span class="params">(Node y)</span> &#123;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">x</span> <span class="operator">=</span> y.right;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">T2</span> <span class="operator">=</span> x.left;</span><br><span class="line"></span><br><span class="line">        x.left = y;</span><br><span class="line">        y.right = T2;</span><br><span class="line"></span><br><span class="line">        y.height = Math.max(getHeight(y.left), getHeight(y.right)) + <span class="number">1</span>;</span><br><span class="line">        x.height = Math.max(getHeight(x.left), getHeight(x.right)) + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加新元素</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        root = add(root, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node <span class="title function_">add</span><span class="params">(Node node, E e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="literal">null</span>) &#123;</span><br><span class="line">            size++;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Node</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(e.compareTo(node.data) &lt; <span class="number">0</span>)</span><br><span class="line">            node.left = add(node.left, e);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(e.compareTo(node.data) &gt; <span class="number">0</span>)</span><br><span class="line">            node.right = add(node.right, e);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> node;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新height</span></span><br><span class="line">        node.height = <span class="number">1</span> + Math.max(getHeight(node.left), getHeight(node.right));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算平衡因子</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">balanceFactor</span> <span class="operator">=</span> getBalanceFactor(node);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 平衡维护</span></span><br><span class="line">        <span class="comment">// LL</span></span><br><span class="line">        <span class="keyword">if</span>(balanceFactor &gt; <span class="number">1</span> &amp;&amp; getBalanceFactor(node.left) &gt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> rightRotate(node);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RR</span></span><br><span class="line">        <span class="keyword">if</span>(balanceFactor &lt; -<span class="number">1</span> &amp;&amp; getBalanceFactor(node.right) &lt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> leftRotate(node);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// LR</span></span><br><span class="line">        <span class="keyword">if</span>(balanceFactor &gt; <span class="number">1</span> &amp;&amp; getBalanceFactor(node.left) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            node.left = leftRotate(node.left);</span><br><span class="line">            <span class="keyword">return</span> rightRotate(node);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RL</span></span><br><span class="line">        <span class="keyword">if</span>(balanceFactor &lt; -<span class="number">1</span> &amp;&amp; getBalanceFactor(node.right) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            node.right = rightRotate(node.right);</span><br><span class="line">            <span class="keyword">return</span> leftRotate(node);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-红黑树-Red-Black-Tree"><a href="#4-红黑树-Red-Black-Tree" class="headerlink" title="4. 红黑树 (Red-Black Tree)"></a>4. 红黑树 (Red-Black Tree)</h3><p>红黑树是一种自平衡二叉搜索树，通过节点的颜色来维持树的平衡。</p><p><strong>红黑树的性质：</strong></p><ol><li>每个节点要么是红色，要么是黑色</li><li>根节点是黑色</li><li>每个叶子节点（NIL）是黑色</li><li>如果一个节点是红色的，则它的子节点必须是黑色的</li><li>从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点</li></ol><p><strong>红黑树示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">       [B]7</span><br><span class="line">      /    \</span><br><span class="line">   [B]3    [B]11</span><br><span class="line">    /  \      \</span><br><span class="line"> [R]1  [R]5   [R]13</span><br><span class="line"></span><br><span class="line">[B] - 黑色节点</span><br><span class="line">[R] - 红色节点</span><br></pre></td></tr></table></figure><p><strong>应用场景：</strong></p><ul><li>Java的TreeMap和TreeSet的底层实现</li><li>Linux内核中的完全公平调度器</li><li>数据库索引</li><li>文件系统</li></ul><h2 id="三、哈希表-Hash-Table"><a href="#三、哈希表-Hash-Table" class="headerlink" title="三、哈希表 (Hash Table)"></a>三、哈希表 (Hash Table)</h2><p>哈希表是一种通过哈希函数将键映射到值的数据结构，它提供了快速的插入、删除和查找操作。</p><p><strong>哈希表结构示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">index  →  链表（处理冲突）</span><br><span class="line"> |</span><br><span class="line"> [0] → [k1,v1] → [k5,v5]</span><br><span class="line"> [1] → [k2,v2]</span><br><span class="line"> [2]</span><br><span class="line"> [3] → [k3,v3]</span><br><span class="line"> [4] → [k4,v4] → [k6,v6]</span><br><span class="line"> [5]</span><br><span class="line"> [6]</span><br></pre></td></tr></table></figure><p><strong>代码实现：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashMap</span>&lt;K, V&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">DEFAULT_CAPACITY</span> <span class="operator">=</span> <span class="number">16</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">float</span> <span class="variable">LOAD_FACTOR</span> <span class="operator">=</span> <span class="number">0.75f</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> K key;</span><br><span class="line">        <span class="keyword">public</span> V value;</span><br><span class="line">        <span class="keyword">public</span> Node next;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">Node</span><span class="params">(K key, V value, Node next)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.key = key;</span><br><span class="line">            <span class="built_in">this</span>.value = value;</span><br><span class="line">            <span class="built_in">this</span>.next = next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node[] table;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> size;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">HashMap</span><span class="params">()</span> &#123;</span><br><span class="line">        table = <span class="keyword">new</span> <span class="title class_">Node</span>[DEFAULT_CAPACITY];</span><br><span class="line">        size = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算哈希值</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="title function_">hash</span><span class="params">(K key)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Math.abs(key.hashCode() % table.length);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加元素</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">put</span><span class="params">(K key, V value)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> hash(key);</span><br><span class="line">        <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> table[index];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(node != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span>(node.key.equals(key)) &#123;</span><br><span class="line">                node.value = value;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            node = node.next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        table[index] = <span class="keyword">new</span> <span class="title class_">Node</span>(key, value, table[index]);</span><br><span class="line">        size++;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(size &gt;= table.length * LOAD_FACTOR)</span><br><span class="line">            resize();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取元素</span></span><br><span class="line">    <span class="keyword">public</span> V <span class="title function_">get</span><span class="params">(K key)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> hash(key);</span><br><span class="line">        <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> table[index];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(node != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span>(node.key.equals(key))</span><br><span class="line">                <span class="keyword">return</span> node.value;</span><br><span class="line">            node = node.next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 删除元素</span></span><br><span class="line">    <span class="keyword">public</span> V <span class="title function_">remove</span><span class="params">(K key)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> hash(key);</span><br><span class="line">        <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> table[index];</span><br><span class="line">        <span class="type">Node</span> <span class="variable">prev</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(node != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span>(node.key.equals(key)) &#123;</span><br><span class="line">                <span class="keyword">if</span>(prev == <span class="literal">null</span>)</span><br><span class="line">                    table[index] = node.next;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    prev.next = node.next;</span><br><span class="line">                size--;</span><br><span class="line">                <span class="keyword">return</span> node.value;</span><br><span class="line">            &#125;</span><br><span class="line">            prev = node;</span><br><span class="line">            node = node.next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 扩容</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">resize</span><span class="params">()</span> &#123;</span><br><span class="line">        Node[] oldTable = table;</span><br><span class="line">        table = <span class="keyword">new</span> <span class="title class_">Node</span>[oldTable.length * <span class="number">2</span>];</span><br><span class="line">        size = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(Node node : oldTable) &#123;</span><br><span class="line">            <span class="keyword">while</span>(node != <span class="literal">null</span>) &#123;</span><br><span class="line">                put(node.key, node.value);</span><br><span class="line">                node = node.next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="四、图-Graph"><a href="#四、图-Graph" class="headerlink" title="四、图 (Graph)"></a>四、图 (Graph)</h2><p>图是一种由顶点和边组成的非线性数据结构，用于表示元素之间的关系。</p><p><strong>图的表示方法：</strong></p><ol><li>邻接矩阵：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A  B  C  D</span><br><span class="line">A   0  1  1  0</span><br><span class="line">B   1  0  1  1</span><br><span class="line">C   1  1  0  1</span><br><span class="line">D   0  1  1  0</span><br></pre></td></tr></table></figure><ol start="2"><li>邻接表：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A → [B, C]</span><br><span class="line">B → [A, C, D]</span><br><span class="line">C → [A, B, D]</span><br><span class="line">D → [B, C]</span><br></pre></td></tr></table></figure><p><strong>代码实现（邻接表）：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Graph</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> V;   <span class="comment">// 顶点数</span></span><br><span class="line">    <span class="keyword">private</span> LinkedList&lt;Integer&gt;[] adj;    <span class="comment">// 邻接表</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Graph</span><span class="params">(<span class="type">int</span> v)</span> &#123;</span><br><span class="line">        V = v;</span><br><span class="line">        adj = <span class="keyword">new</span> <span class="title class_">LinkedList</span>[v];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; v; i++)</span><br><span class="line">            adj[i] = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加边</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addEdge</span><span class="params">(<span class="type">int</span> v, <span class="type">int</span> w)</span> &#123;</span><br><span class="line">        adj[v].add(w);</span><br><span class="line">        adj[w].add(v);    <span class="comment">// 无向图实现</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 广度优先搜索</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">BFS</span><span class="params">(<span class="type">int</span> s)</span> &#123;</span><br><span class="line">        <span class="type">boolean</span>[] visited = <span class="keyword">new</span> <span class="title class_">boolean</span>[V];</span><br><span class="line">        Queue&lt;Integer&gt; queue = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        visited[s] = <span class="literal">true</span>;</span><br><span class="line">        queue.add(s);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty()) &#123;</span><br><span class="line">            s = queue.poll();</span><br><span class="line">            System.out.print(s + <span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> n : adj[s]) &#123;</span><br><span class="line">                <span class="keyword">if</span>(!visited[n]) &#123;</span><br><span class="line">                    visited[n] = <span class="literal">true</span>;</span><br><span class="line">                    queue.add(n);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 深度优先搜索</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">DFS</span><span class="params">(<span class="type">int</span> s)</span> &#123;</span><br><span class="line">        <span class="type">boolean</span>[] visited = <span class="keyword">new</span> <span class="title class_">boolean</span>[V];</span><br><span class="line">        DFSUtil(s, visited);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">DFSUtil</span><span class="params">(<span class="type">int</span> v, <span class="type">boolean</span>[] visited)</span> &#123;</span><br><span class="line">        visited[v] = <span class="literal">true</span>;</span><br><span class="line">        System.out.print(v + <span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> n : adj[v]) &#123;</span><br><span class="line">            <span class="keyword">if</span>(!visited[n])</span><br><span class="line">                DFSUtil(n, visited);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>应用场景：</strong></p><ul><li>社交网络</li><li>地图导航</li><li>网络拓扑</li><li>任务调度</li></ul><p><strong>特点：</strong></p><ul><li>后进先出（LIFO）</li><li>只能从栈顶访问元素</li><li>可以用数组或链表实现</li></ul><p><strong>栈的结构示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">    ↑ 栈顶</span><br><span class="line">+---+</span><br><span class="line">| 4 |  &lt;- 最后入栈的元素</span><br><span class="line">+---+</span><br><span class="line">| 3 |</span><br><span class="line">+---+</span><br><span class="line">| 2 |</span><br><span class="line">+---+</span><br><span class="line">| 1 |  &lt;- 最先入栈的元素</span><br><span class="line">+---+</span><br></pre></td></tr></table></figure><p><strong>基于数组实现的栈：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ArrayStack</span>&lt;E&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> Array&lt;E&gt; array;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ArrayStack</span><span class="params">(<span class="type">int</span> capacity)</span> &#123;</span><br><span class="line">        array = <span class="keyword">new</span> <span class="title class_">Array</span>&lt;&gt;(capacity);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getSize</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> array.getSize();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> array.isEmpty();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 入栈操作</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">push</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        array.addLast(e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 出栈操作</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">pop</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> array.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查看栈顶元素</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">peek</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> array.getLast();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-队列-Queue"><a href="#4-队列-Queue" class="headerlink" title="4. 队列 (Queue)"></a>4. 队列 (Queue)</h3><p>队列是一种先进先出（FIFO）的线性数据结构，只允许在一端（队尾）进行插入操作，在另一端（队首）进行删除操作。</p><p><strong>特点：</strong></p><ul><li>先进先出（FIFO）</li><li>队首删除，队尾添加</li><li>可以用数组或链表实现</li></ul><p><strong>队列的结构示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">队首 →  +---+---+---+---+</span><br><span class="line">        | 1 | 2 | 3 | 4 |  ← 队尾</span><br><span class="line">        +---+---+---+---+</span><br><span class="line">出队 ←   最先进入的元素   → 入队</span><br></pre></td></tr></table></figure><p><strong>循环队列实现：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CircularQueue</span>&lt;E&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> E[] data;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> front, tail;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> size;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">CircularQueue</span><span class="params">(<span class="type">int</span> capacity)</span> &#123;</span><br><span class="line">        data = (E[]) <span class="keyword">new</span> <span class="title class_">Object</span>[capacity + <span class="number">1</span>];</span><br><span class="line">        front = <span class="number">0</span>;</span><br><span class="line">        tail = <span class="number">0</span>;</span><br><span class="line">        size = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> front == tail;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isFull</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (tail + <span class="number">1</span>) % data.length == front;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 入队操作</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">enqueue</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isFull())</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;Queue is full&quot;</span>);</span><br><span class="line">        data[tail] = e;</span><br><span class="line">        tail = (tail + <span class="number">1</span>) % data.length;</span><br><span class="line">        size++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 出队操作</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">dequeue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isEmpty())</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;Queue is empty&quot;</span>);</span><br><span class="line">        <span class="type">E</span> <span class="variable">ret</span> <span class="operator">=</span> data[front];</span><br><span class="line">        data[front] = <span class="literal">null</span>;</span><br><span class="line">        front = (front + <span class="number">1</span>) % data.length;</span><br><span class="line">        size--;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查看队首元素</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">getFront</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (isEmpty())</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;Queue is empty&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> data[front];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getSize</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> size;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>应用场景：</strong></p><ul><li><p>栈：</p><ul><li>函数调用栈</li><li>表达式求值</li><li>括号匹配</li><li>浏览器前进&#x2F;后退功能</li></ul></li><li><p>队列：</p><ul><li>任务调度</li><li>消息队列</li><li>打印机打印任务</li><li>广度优先搜索</li></ul></li></ul><p><strong>特点：</strong></p><ul><li>动态大小</li><li>插入和删除操作简单</li><li>不支持随机访问</li></ul><p><strong>链表结构示意图：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">单链表：</span><br><span class="line">+---+    +---+    +---+    +---+</span><br><span class="line">| 1 |-&gt;  | 2 |-&gt;  | 3 |-&gt;  | 4 |-&gt;  NULL</span><br><span class="line">+---+    +---+    +---+    +---+</span><br><span class="line"></span><br><span class="line">双向链表：</span><br><span class="line">+---+    +---+    +---+    +---+</span><br><span class="line">NULL &lt;-| 1 |&lt;-&gt; | 2 |&lt;-&gt; | 3 |&lt;-&gt; | 4 |-&gt;  NULL</span><br><span class="line">+---+    +---+    +---+    +---+</span><br></pre></td></tr></table></figure><p><strong>主要操作及时间复杂度：</strong></p><ul><li>访问元素：O(n)</li><li>在头部添加&#x2F;删除元素：O(1)</li><li>在尾部添加&#x2F;删除元素：O(n)（单链表）或 O(1)（带尾指针的链表）</li><li>在中间添加&#x2F;删除元素：O(n)</li></ul><p><strong>操作示意图：</strong></p><p>在位置2插入新节点：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">原链表：</span><br><span class="line">+---+    +---+    +---+    +---+</span><br><span class="line">| 1 |-&gt;  | 2 |-&gt;  | 3 |-&gt;  | 4 |</span><br><span class="line">+---+    +---+    +---+    +---+</span><br><span class="line"></span><br><span class="line">插入新节点：</span><br><span class="line">+---+    +---+    +---+    +---+    +---+</span><br><span class="line">| 1 |-&gt;  | 2 |-&gt;  | 5 |-&gt;  | 3 |-&gt;  | 4 |</span><br><span class="line">+---+    +---+    +---+    +---+    +---+</span><br></pre></td></tr></table></figure><p><strong>代码示例：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LinkedList</span>&lt;E&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> E data;       <span class="comment">// 节点数据</span></span><br><span class="line">        <span class="keyword">public</span> Node next;    <span class="comment">// 指向下一个节点的引用</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">Node</span><span class="params">(E data, Node next)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.data = data;</span><br><span class="line">            <span class="built_in">this</span>.next = next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node dummyHead;  <span class="comment">// 虚拟头节点</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> size;        <span class="comment">// 链表大小</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LinkedList</span><span class="params">()</span> &#123;</span><br><span class="line">        dummyHead = <span class="keyword">new</span> <span class="title class_">Node</span>(<span class="literal">null</span>, <span class="literal">null</span>);</span><br><span class="line">        size = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取链表中的元素个数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getSize</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> size;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回链表是否为空</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isEmpty</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> size == <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在链表头添加新元素</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addFirst</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        add(<span class="number">0</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在链表末尾添加新元素</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addLast</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        add(size, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在指定位置添加新元素</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> index, E e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">0</span> || index &gt; size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Add failed. Illegal index.&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Node</span> <span class="variable">prev</span> <span class="operator">=</span> dummyHead;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; index; i++)</span><br><span class="line">            prev = prev.next;</span><br><span class="line"></span><br><span class="line">        prev.next = <span class="keyword">new</span> <span class="title class_">Node</span>(e, prev.next);</span><br><span class="line">        size++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取指定位置的元素</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">get</span><span class="params">(<span class="type">int</span> index)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">0</span> || index &gt;= size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Get failed. Illegal index.&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Node</span> <span class="variable">cur</span> <span class="operator">=</span> dummyHead.next;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; index; i++)</span><br><span class="line">            cur = cur.next;</span><br><span class="line">        <span class="keyword">return</span> cur.data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 修改指定位置的元素</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">int</span> index, E e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">0</span> || index &gt;= size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Set failed. Illegal index.&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Node</span> <span class="variable">cur</span> <span class="operator">=</span> dummyHead.next;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; index; i++)</span><br><span class="line">            cur = cur.next;</span><br><span class="line">        cur.data = e;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查找链表中是否有元素e</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">contains</span><span class="params">(E e)</span> &#123;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">cur</span> <span class="operator">=</span> dummyHead.next;</span><br><span class="line">        <span class="keyword">while</span>(cur != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span>(cur.data.equals(e))</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            cur = cur.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 删除指定位置的元素</span></span><br><span class="line">    <span class="keyword">public</span> E <span class="title function_">remove</span><span class="params">(<span class="type">int</span> index)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(index &lt; <span class="number">0</span> || index &gt;= size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Remove failed. Index is illegal.&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Node</span> <span class="variable">prev</span> <span class="operator">=</span> dummyHead;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; index; i++)</span><br><span class="line">            prev = prev.next;</span><br><span class="line"></span><br><span class="line">        <span class="type">Node</span> <span class="variable">retNode</span> <span class="operator">=</span> prev.next;</span><br><span class="line">        prev.next = retNode.next;</span><br><span class="line">        retNode.next = <span class="literal">null</span>;</span><br><span class="line">        size--;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> retNode.data;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>应用场景：</strong></p><ul><li><p>需要频繁插入和删除元素的场景</p></li><li><p>不需要随机访问的场景</p></li><li><p>内存空间要求灵活的场景</p></li><li><p>实现其他数据结构（如栈、队列、哈希表的拉链法等）<br>  prev &#x3D; prev.next;<br>  }</p><p>  Node retNode &#x3D; prev.next;<br>  prev.next &#x3D; retNode.next;<br>  retNode.next &#x3D; null;<br>  size–;</p><p>  return retNode.data;</p></li></ul><p>}</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 3. 栈 (Stack)</span><br><span class="line"></span><br><span class="line">栈是一种后进先出(LIFO)的线性表，只能在一端（栈顶）进行插入和删除操作。</span><br><span class="line"></span><br><span class="line">**特点：**</span><br><span class="line">- 后进先出(LIFO)</span><br><span class="line">- 只能从栈顶访问元素</span><br><span class="line"></span><br><span class="line">**主要操作及时间复杂度：**</span><br><span class="line">- 压栈(push)：O(1)</span><br><span class="line">- 出栈(pop)：O(1)</span><br><span class="line">- 查看栈顶元素(peek)：O(1)</span><br><span class="line"></span><br><span class="line">**代码示例：**</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line">// 将元素压入栈顶</span><br><span class="line">public void push(E e) &#123;</span><br><span class="line">    array.addLast(e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 弹出栈顶元素</span><br><span class="line">public E pop() &#123;</span><br><span class="line">    return array.removeLast();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 查看栈顶元素</span><br><span class="line">public E peek() &#123;</span><br><span class="line">    return array.getLast();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>应用场景：</strong></p><ul><li>函数调用栈</li><li>表达式求值</li><li>括号匹配</li><li>深度优先搜索</li></ul><h3 id="4-队列-Queue-1"><a href="#4-队列-Queue-1" class="headerlink" title="4. 队列 (Queue)"></a>4. 队列 (Queue)</h3><p>队列是一种先进先出(FIFO)的线性表，只能在一端（队尾）进行插入操作，在另一端（队头）进行删除操作。</p><p><strong>特点：</strong></p><ul><li>先进先出(FIFO)</li><li>只能从队头删除元素，从队尾添加元素</li></ul><p><strong>主要操作及时间复杂度：</strong></p><ul><li>入队(enqueue)：O(1)</li><li>出队(dequeue)：O(1)</li><li>查看队首元素(front)：O(1)</li></ul><p><strong>应用场景：</strong></p><ul><li>任务调度</li><li>消息队列</li><li>广度优先搜索</li></ul><h2 id="二、非线性数据结构"><a href="#二、非线性数据结构" class="headerlink" title="二、非线性数据结构"></a>二、非线性数据结构</h2><p>非线性数据结构是一种数据元素之间存在一对多关系的数据结构，元素不是按照线性顺序排列的。</p><h3 id="1-树-Tree"><a href="#1-树-Tree" class="headerlink" title="1. 树 (Tree)"></a>1. 树 (Tree)</h3><p>树是一种层次结构，由节点组成，每个节点可以有多个子节点。</p><h4 id="1-1-二叉树-Binary-Tree"><a href="#1-1-二叉树-Binary-Tree" class="headerlink" title="1.1 二叉树 (Binary Tree)"></a>1.1 二叉树 (Binary Tree)</h4><p>二叉树是每个节点最多有两个子节点（左子节点和右子节点）的树结构。</p><p><strong>特点：</strong></p><ul><li>每个节点最多有两个子节点</li><li>具有层次结构</li></ul><p><strong>主要操作及时间复杂度：</strong></p><ul><li>前序遍历：O(n)</li><li>中序遍历：O(n)</li><li>后序遍历：O(n)</li><li>层序遍历：O(n)</li></ul><p><strong>代码示例：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 前序遍历</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">preOrder</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (node == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    System.out.print(node.data + <span class="string">&quot; &quot;</span>);</span><br><span class="line">    preOrder(node.left);</span><br><span class="line">    preOrder(node.right);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 中序遍历</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">inOrder</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (node == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    inOrder(node.left);</span><br><span class="line">    System.out.print(node.data + <span class="string">&quot; &quot;</span>);</span><br><span class="line">    inOrder(node.right);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 后序遍历</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">postOrder</span><span class="params">(Node node)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (node == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    postOrder(node.left);</span><br><span class="line">    postOrder(node.right);</span><br><span class="line">    System.out.print(node.data + <span class="string">&quot; &quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1-2-二叉搜索树-Binary-Search-Tree"><a href="#1-2-二叉搜索树-Binary-Search-Tree" class="headerlink" title="1.2 二叉搜索树 (Binary Search Tree)"></a>1.2 二叉搜索树 (Binary Search Tree)</h4><p>二叉搜索树是一种特殊的二叉树，对于树中的每个节点，其左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。</p><p><strong>特点：</strong></p><ul><li>左子树上所有节点的值均小于根节点的值</li><li>右子树上所有节点的值均大于根节点的值</li><li>左右子树也分别为二叉搜索树</li></ul><p><strong>主要操作及时间复杂度：</strong></p><ul><li>查找：平均 O(log n)，最坏 O(n)</li><li>插入：平均 O(log n)，最坏 O(n)</li><li>删除：平均 O(log n)，最坏 O(n)</li></ul><h4 id="1-3-平衡二叉树-AVL-Tree"><a href="#1-3-平衡二叉树-AVL-Tree" class="headerlink" title="1.3 平衡二叉树 (AVL Tree)"></a>1.3 平衡二叉树 (AVL Tree)</h4><p>平衡二叉树是一种特殊的二叉搜索树，它要求每个节点的左右子树的高度差不超过1。</p><p><strong>特点：</strong></p><ul><li>是一棵二叉搜索树</li><li>每个节点的左右子树的高度差不超过1</li></ul><p><strong>主要操作及时间复杂度：</strong></p><ul><li>查找：O(log n)</li><li>插入：O(log n)</li><li>删除：O(log n)</li></ul><h3 id="2-堆-Heap"><a href="#2-堆-Heap" class="headerlink" title="2. 堆 (Heap)"></a>2. 堆 (Heap)</h3><p>堆是一种特殊的完全二叉树，分为最大堆和最小堆。</p><p><strong>特点：</strong></p><ul><li>最大堆：每个节点的值都大于或等于其子节点的值</li><li>最小堆：每个节点的值都小于或等于其子节点的值</li><li>是完全二叉树</li></ul><p><strong>主要操作及时间复杂度：</strong></p><ul><li>插入元素：O(log n)</li><li>删除最大&#x2F;最小元素：O(log n)</li><li>获取最大&#x2F;最小元素：O(1)</li><li>构建堆：O(n)</li></ul><p><strong>应用场景：</strong></p><ul><li>优先队列</li><li>堆排序</li><li>图算法（如Dijkstra算法）</li></ul><h3 id="3-图-Graph"><a href="#3-图-Graph" class="headerlink" title="3. 图 (Graph)"></a>3. 图 (Graph)</h3><p>图是由顶点和边组成的非线性数据结构，用于表示物体之间的关系。</p><p><strong>特点：</strong></p><ul><li>由顶点和边组成</li><li>可以是有向的或无向的</li><li>可以是带权的或不带权的</li></ul><p><strong>表示方法：</strong></p><ul><li>邻接矩阵</li><li>邻接表</li></ul><p><strong>主要操作及时间复杂度：</strong></p><ul><li>添加顶点：O(1)</li><li>添加边：O(1)</li><li>深度优先搜索(DFS)：O(V + E)，其中V为顶点数，E为边数</li><li>广度优先搜索(BFS)：O(V + E)</li><li>最短路径算法（如Dijkstra）：O(V^2 + E)或O((V+E)logV)（使用优先队列）</li><li>最小生成树算法（如Prim）：O(V^2)或O(ElogV)（使用优先队列）</li></ul><p><strong>代码示例：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 添加边</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addEdge</span><span class="params">(V from, V to, <span class="type">int</span> weight)</span> &#123;</span><br><span class="line">    <span class="comment">// 确保顶点存在</span></span><br><span class="line">    addVertex(from);</span><br><span class="line">    addVertex(to);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">fromIndex</span> <span class="operator">=</span> vertexMap.get(from);</span><br><span class="line">    <span class="type">int</span> <span class="variable">toIndex</span> <span class="operator">=</span> vertexMap.get(to);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加边</span></span><br><span class="line">    adjList.get(fromIndex).add(<span class="keyword">new</span> <span class="title class_">Edge</span>(toIndex, weight));</span><br><span class="line">    edgeCount++;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果是无向图，则添加反向边</span></span><br><span class="line">    <span class="keyword">if</span> (!directed) &#123;</span><br><span class="line">        adjList.get(toIndex).add(<span class="keyword">new</span> <span class="title class_">Edge</span>(fromIndex, weight));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 深度优先遍历</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">dfsHelper</span><span class="params">(<span class="type">int</span> vertex, <span class="type">boolean</span>[] visited, List&lt;V&gt; result)</span> &#123;</span><br><span class="line">    visited[vertex] = <span class="literal">true</span>;</span><br><span class="line">    result.add(vertexList.get(vertex));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Edge edge : adjList.get(vertex)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!visited[edge.to]) &#123;</span><br><span class="line">            dfsHelper(edge.to, visited, result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-哈希表-Hash-Table"><a href="#4-哈希表-Hash-Table" class="headerlink" title="4. 哈希表 (Hash Table)"></a>4. 哈希表 (Hash Table)</h3><p>哈希表是一种能够实现关联数组的数据结构，它通过哈希函数将键映射到值。</p><p><strong>特点：</strong></p><ul><li>通过键直接访问元素</li><li>平均查找、插入和删除时间复杂度为O(1)</li><li>可能存在哈希冲突</li></ul><p><strong>主要操作及时间复杂度：</strong></p><ul><li>插入：平均O(1)，最坏O(n)</li><li>查找：平均O(1)，最坏O(n)</li><li>删除：平均O(1)，最坏O(n)</li></ul><p><strong>解决哈希冲突的方法：</strong></p><ul><li>链地址法（拉链法）</li><li>开放地址法（线性探测、二次探测、双重哈希）</li></ul><p><strong>应用场景：</strong></p><ul><li>实现字典或映射</li><li>缓存实现</li><li>集合实现</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文详细介绍了各种基本数据结构的Java实现，包括线性数据结构（数组、链表、栈、队列）和非线性数据结构（树、堆、图、哈希表）。每种数据结构都有其特定的应用场景和性能特点，在实际编程中，需要根据具体问题选择合适的数据结构。</p><p>通过学习和掌握这些数据结构的实现原理和使用方法，可以提高编程效率和代码质量，为解决复杂问题打下坚实的基础。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> Java </tag>
            
            <tag> 编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java蓝桥杯输入输出方法总结</title>
      <link href="/2025/03/10/Java%E8%93%9D%E6%A1%A5%E6%9D%AF%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/"/>
      <url>/2025/03/10/Java%E8%93%9D%E6%A1%A5%E6%9D%AF%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1 id="Java蓝桥杯输入输出方法总结"><a href="#Java蓝桥杯输入输出方法总结" class="headerlink" title="Java蓝桥杯输入输出方法总结"></a>Java蓝桥杯输入输出方法总结</h1><p>在蓝桥杯竞赛中，合适的输入输出方法对提高程序运行效率至关重要。本文将系统地介绍Java中各种输入输出方法，并提供性能对比分析。</p><h2 id="1-Scanner类"><a href="#1-Scanner类" class="headerlink" title="1. Scanner类"></a>1. Scanner类</h2><h3 id="1-1-基本用法"><a href="#1-1-基本用法" class="headerlink" title="1.1 基本用法"></a>1.1 基本用法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Scanner</span> <span class="variable">sc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取整数</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> sc.nextInt();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取字符串</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> sc.next();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取一整行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> sc.nextLine();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取浮点数</span></span><br><span class="line">        <span class="type">double</span> <span class="variable">d</span> <span class="operator">=</span> sc.nextDouble();</span><br><span class="line">        </span><br><span class="line">        sc.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-2-优缺点"><a href="#1-2-优缺点" class="headerlink" title="1.2 优缺点"></a>1.2 优缺点</h3><ul><li>优点：使用简单，功能齐全</li><li>缺点：性能较差，不适合大量数据的输入</li></ul><h2 id="2-BufferedReader类"><a href="#2-BufferedReader类" class="headerlink" title="2. BufferedReader类"></a>2. BufferedReader类</h2><h3 id="2-1-基本用法"><a href="#2-1-基本用法" class="headerlink" title="2.1 基本用法"></a>2.1 基本用法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">BufferedReader</span> <span class="variable">br</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(System.in));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取一行字符串</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> br.readLine();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取整数</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> Integer.parseInt(br.readLine());</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取空格分隔的多个整数</span></span><br><span class="line">        String[] nums = br.readLine().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="type">int</span>[] arr = <span class="keyword">new</span> <span class="title class_">int</span>[nums.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            arr[i] = Integer.parseInt(nums[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        br.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-优缺点"><a href="#2-2-优缺点" class="headerlink" title="2.2 优缺点"></a>2.2 优缺点</h3><ul><li>优点：效率高，适合处理大量数据</li><li>缺点：使用相对复杂，需要处理IOException</li></ul><h2 id="3-StreamTokenizer类"><a href="#3-StreamTokenizer类" class="headerlink" title="3. StreamTokenizer类"></a>3. StreamTokenizer类</h2><h3 id="3-1-基本用法"><a href="#3-1-基本用法" class="headerlink" title="3.1 基本用法"></a>3.1 基本用法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.io.StreamTokenizer;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">StreamTokenizer</span> <span class="variable">st</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StreamTokenizer</span>(<span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(System.in)));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取数字</span></span><br><span class="line">        st.nextToken();</span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> (<span class="type">int</span>) st.nval;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 读取字符串</span></span><br><span class="line">        st.nextToken();</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> st.sval;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-优缺点"><a href="#3-2-优缺点" class="headerlink" title="3.2 优缺点"></a>3.2 优缺点</h3><ul><li>优点：自动分词，处理数字和字符串方便</li><li>缺点：使用较为复杂</li></ul><h2 id="4-快读快写模板"><a href="#4-快读快写模板" class="headerlink" title="4. 快读快写模板"></a>4. 快读快写模板</h2><h3 id="4-1-基于BufferedReader的快读模板"><a href="#4-1-基于BufferedReader的快读模板" class="headerlink" title="4.1 基于BufferedReader的快读模板"></a>4.1 基于BufferedReader的快读模板</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FastReader</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> BufferedReader br;</span><br><span class="line">    <span class="keyword">private</span> StringTokenizer st;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FastReader</span><span class="params">()</span> &#123;</span><br><span class="line">        br = <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(System.in));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">next</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (st == <span class="literal">null</span> || !st.hasMoreElements()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                st = <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(br.readLine());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> st.nextToken();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">nextInt</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Integer.parseInt(next());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">nextLong</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Long.parseLong(next());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">nextDouble</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Double.parseDouble(next());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">nextLine</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            str = br.readLine();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> str;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">FastReader</span> <span class="variable">fr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FastReader</span>();</span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> fr.nextInt();</span><br><span class="line">        <span class="type">long</span> <span class="variable">m</span> <span class="operator">=</span> fr.nextLong();</span><br><span class="line">        <span class="type">double</span> <span class="variable">d</span> <span class="operator">=</span> fr.nextDouble();</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> fr.next();</span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> fr.nextLine();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-2-基于字节流的极速读写模板"><a href="#4-2-基于字节流的极速读写模板" class="headerlink" title="4.2 基于字节流的极速读写模板"></a>4.2 基于字节流的极速读写模板</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UltraIO</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">BUFFER_SIZE</span> <span class="operator">=</span> <span class="number">1</span> &lt;&lt; <span class="number">16</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> DataInputStream din;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> DataOutputStream dout;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">byte</span>[] buffer;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> bufferPointer, bytesRead;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">UltraIO</span><span class="params">()</span> &#123;</span><br><span class="line">        din = <span class="keyword">new</span> <span class="title class_">DataInputStream</span>(System.in);</span><br><span class="line">        dout = <span class="keyword">new</span> <span class="title class_">DataOutputStream</span>(System.out);</span><br><span class="line">        buffer = <span class="keyword">new</span> <span class="title class_">byte</span>[BUFFER_SIZE];</span><br><span class="line">        bufferPointer = bytesRead = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">readLine</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">byte</span>[] buf = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">64</span>]; <span class="comment">// 用于存储输入的字符</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">cnt</span> <span class="operator">=</span> <span class="number">0</span>, c;</span><br><span class="line">        <span class="keyword">while</span> ((c = read()) != -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (c == <span class="string">&#x27;\n&#x27;</span>) <span class="keyword">break</span>;</span><br><span class="line">            buf[cnt++] = (<span class="type">byte</span>) c;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">String</span>(buf, <span class="number">0</span>, cnt);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">nextInt</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">ret</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">byte</span> <span class="variable">c</span> <span class="operator">=</span> read();</span><br><span class="line">        <span class="keyword">while</span> (c &lt;= <span class="string">&#x27; &#x27;</span>) c = read();</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">neg</span> <span class="operator">=</span> (c == <span class="string">&#x27;-&#x27;</span>);</span><br><span class="line">        <span class="keyword">if</span> (neg) c = read();</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            ret = ret * <span class="number">10</span> + c - <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">        &#125; <span class="keyword">while</span> ((c = read()) &gt;= <span class="string">&#x27;0&#x27;</span> &amp;&amp; c &lt;= <span class="string">&#x27;9&#x27;</span>);</span><br><span class="line">        <span class="keyword">if</span> (neg) <span class="keyword">return</span> -ret;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">fillBuffer</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        bytesRead = din.read(buffer, bufferPointer = <span class="number">0</span>, BUFFER_SIZE);</span><br><span class="line">        <span class="keyword">if</span> (bytesRead == -<span class="number">1</span>) buffer[<span class="number">0</span>] = -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="type">byte</span> <span class="title function_">read</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">if</span> (bufferPointer == bytesRead) fillBuffer();</span><br><span class="line">        <span class="keyword">return</span> buffer[bufferPointer++];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">if</span> (din == <span class="literal">null</span>) <span class="keyword">return</span>;</span><br><span class="line">        din.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">UltraIO</span> <span class="variable">io</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">UltraIO</span>();</span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> io.nextInt();</span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> io.readLine();</span><br><span class="line">        io.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-性能对比"><a href="#5-性能对比" class="headerlink" title="5. 性能对比"></a>5. 性能对比</h2><p>以下是各种输入方法读取100万个整数的性能对比：</p><ol><li>Scanner：约2000ms</li><li>BufferedReader：约500ms</li><li>StreamTokenizer：约400ms</li><li>FastReader：约300ms</li><li>UltraIO：约150ms</li></ol><h2 id="6-使用建议"><a href="#6-使用建议" class="headerlink" title="6. 使用建议"></a>6. 使用建议</h2><ol><li>对于简单题目或数据量较小的情况，使用Scanner即可</li><li>对于数据量中等的题目，使用BufferedReader或FastReader</li><li>对于数据量极大或对时间要求极高的题目，使用UltraIO模板</li><li>在实际比赛中，建议将快读模板代码准备好，以备不时之需</li></ol><h2 id="7-注意事项"><a href="#7-注意事项" class="headerlink" title="7. 注意事项"></a>7. 注意事项</h2><ol><li>使用Scanner时注意nextInt()和nextLine()混用可能导致的问题</li><li>BufferedReader必须处理IOException</li><li>在使用完输入流后记得关闭(close)</li><li>对于竞赛中的多组输入，注意处理输入结束的条件</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在蓝桥杯竞赛中，选择合适的输入输出方法可以显著提高程序的运行效率。对于不同的题目要求，应当灵活选择合适的输入方法。建议平时多加练习各种输入方法的使用，以便在比赛中得心应手。</p>]]></content>
      
      
      <categories>
          
          <category> 编程技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 蓝桥杯 </tag>
            
            <tag> 编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机专业竞赛推荐</title>
      <link href="/2025/03/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%93%E4%B8%9A%E7%AB%9E%E8%B5%9B%E6%8E%A8%E8%8D%90/"/>
      <url>/2025/03/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%93%E4%B8%9A%E7%AB%9E%E8%B5%9B%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<h1 id="计算机专业竞赛推荐（2025年6月前）"><a href="#计算机专业竞赛推荐（2025年6月前）" class="headerlink" title="计算机专业竞赛推荐（2025年6月前）"></a>计算机专业竞赛推荐（2025年6月前）</h1><table><thead><tr><th>序号</th><th>竞赛名称</th><th>主办单位</th><th>技术分类</th><th>官网链接</th><th>参赛时间</th><th>备注</th></tr></thead><tbody><tr><td>4</td><td>ACM-ICPC国际大学生程序设计竞赛</td><td>国际计算机协会</td><td>算法与程序设计</td><td><a href="https://icpc.global/">icpc.global</a></td><td>2024.9-2025.11</td><td>算法竞赛殿堂级赛事</td></tr><tr><td>34</td><td>蓝桥杯全国软件人才大赛</td><td>工业和信息化部</td><td>软件开发&#x2F;算法</td><td><a href="https://dasai.lanqiao.cn/">lanqiao.cn</a></td><td>2025.4&#x2F;6月决赛</td><td>国内规模最大的IT类赛事</td></tr><tr><td>8</td><td>全国大学生信息安全竞赛</td><td>教育部</td><td>网络安全</td><td><a href="https://www.ciscn.cn/">ciscn.cn</a></td><td>2025.5-6</td><td>CTF夺旗赛形式</td></tr><tr><td>26</td><td>中国软件杯大赛</td><td>工信部&#x2F;教育部</td><td>软件工程</td><td><a href="http://www.cnsoftbei.com/">cnsoftbei.com</a></td><td>2025.3-8</td><td>企业命题开发</td></tr><tr><td>33</td><td>中国高校计算机大赛</td><td>教育部</td><td>综合能力</td><td><a href="https://www.ccf.org.cn/">ccf.org.cn</a></td><td>2025.3-8</td><td>包含5个子赛事</td></tr><tr><td>16</td><td>外研社·国才杯外语能力大赛</td><td>外研社</td><td>英语应用</td><td><a href="https://uchallenge.unipus.cn/">uchallenge.unipus.cn</a></td><td>2025.3-11</td><td>含编程文档阅读能力</td></tr><tr><td>43</td><td>华为ICT大赛</td><td>华为技术有限公司</td><td>网络技术</td><td><a href="https://e.huawei.com/cn/talent/#/ict/competition">e.huawei.com</a></td><td>2025.3-6</td><td>云计算&#x2F;网络赛道</td></tr><tr><td>22</td><td>西门子杯智能制造挑战赛</td><td>教育部</td><td>工业软件</td><td><a href="http://www.siemenscup-cimc.org.cn/">siemenscup-cimc.org.cn</a></td><td>2025.3-8</td><td>智能制造系统开发</td></tr><tr><td>58</td><td>百度之星程序设计大赛</td><td>百度公司</td><td>算法竞赛</td><td><a href="https://astar.baidu.com/">astar.baidu.com</a></td><td>2025.5-8</td><td>企业级算法赛事</td></tr><tr><td>63</td><td>全国计算机系统能力大赛</td><td>教育部</td><td>系统开发</td><td><a href="http://nscscc.org/">nscscc.org</a></td><td>2025.4-8</td><td>操作系统&#x2F;编译系统设计</td></tr></tbody></table><p><strong>备注说明</strong>：</p><ol><li>算法类：ACM-ICPC&#x2F;蓝桥杯&#x2F;百度之星（侧重数据结构与算法）</li><li>开发类：中国软件杯&#x2F;华为ICT大赛（侧重项目设计与实现）</li><li>系统类：计算机系统能力大赛（侧重底层系统开发）</li><li>创新类：挑战杯&#x2F;互联网+（侧重商业计划与技术创新结合）</li></ol><p>（注：具体参赛时间以2025年各赛事官方通知为准）</p>]]></content>
      
      
      <categories>
          
          <category> 计算机专业 </category>
          
          <category> 竞赛推荐 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机专业 </tag>
            
            <tag> 竞赛推荐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何更新GitHub博客</title>
      <link href="/2025/03/10/%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0GitHub%E5%8D%9A%E5%AE%A2/"/>
      <url>/2025/03/10/%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0GitHub%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="如何更新GitHub博客"><a href="#如何更新GitHub博客" class="headerlink" title="如何更新GitHub博客"></a>如何更新GitHub博客</h1><p>本文将介绍如何使用Hexo框架更新部署在GitHub Pages上的博客。</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>在开始之前，确保你已经安装了以下工具：</p><ul><li>Node.js和npm</li><li>Git</li><li>Hexo CLI</li></ul><h2 id="更新博客的步骤"><a href="#更新博客的步骤" class="headerlink" title="更新博客的步骤"></a>更新博客的步骤</h2><h3 id="1-创建新文章"><a href="#1-创建新文章" class="headerlink" title="1. 创建新文章"></a>1. 创建新文章</h3><p>使用以下命令创建一篇新文章：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;文章标题&quot;</span></span><br></pre></td></tr></table></figure><p>这将在<code>source/_posts</code>目录下创建一个新的Markdown文件。</p><h3 id="2-编辑文章"><a href="#2-编辑文章" class="headerlink" title="2. 编辑文章"></a>2. 编辑文章</h3><p>使用你喜欢的文本编辑器打开新创建的Markdown文件，编辑文章内容。Markdown文件的开头是文章的前置信息，包括标题、日期、标签等。</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 文章标题</span><br><span class="line">date: 2023-01-01 12:00:00</span><br><span class="line">tags: [标签1, 标签2]</span><br><span class="line"><span class="section">categories: [分类]</span></span><br><span class="line"><span class="section">---</span></span><br><span class="line"></span><br><span class="line">这里是文章内容...</span><br></pre></td></tr></table></figure><h3 id="3-本地预览"><a href="#3-本地预览" class="headerlink" title="3. 本地预览"></a>3. 本地预览</h3><p>编辑完成后，可以在本地预览效果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean   <span class="comment"># 清除之前生成的文件</span></span><br><span class="line">$ hexo server  <span class="comment"># 启动本地服务器</span></span><br></pre></td></tr></table></figure><p>访问 <code>http://localhost:4000</code> 查看效果。</p><h3 id="4-生成静态文件"><a href="#4-生成静态文件" class="headerlink" title="4. 生成静态文件"></a>4. 生成静态文件</h3><p>确认没有问题后，生成静态文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate  <span class="comment"># 或简写为 hexo g</span></span><br></pre></td></tr></table></figure><h3 id="5-部署到GitHub"><a href="#5-部署到GitHub" class="headerlink" title="5. 部署到GitHub"></a>5. 部署到GitHub</h3><p>最后，将生成的静态文件部署到GitHub：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy  <span class="comment"># 或简写为 hexo d</span></span><br></pre></td></tr></table></figure><p>也可以合并生成和部署步骤：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate --deploy  <span class="comment"># 或简写为 hexo g -d</span></span><br></pre></td></tr></table></figure><h2 id="自动化部署"><a href="#自动化部署" class="headerlink" title="自动化部署"></a>自动化部署</h2><p>除了手动部署外，还可以设置GitHub Actions实现自动部署。每当你推送更改到GitHub仓库时，GitHub Actions会自动构建并部署你的博客。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="部署失败"><a href="#部署失败" class="headerlink" title="部署失败"></a>部署失败</h3><p>如果部署失败，可能是以下原因：</p><ol><li>Git配置问题：确保已正确配置Git用户名和邮箱</li><li>SSH密钥问题：确保已添加SSH密钥到GitHub账户</li><li>权限问题：确保有权限推送到目标仓库</li></ol><h3 id="主题更新"><a href="#主题更新" class="headerlink" title="主题更新"></a>主题更新</h3><p>如果使用的是第三方主题（如Butterfly），更新主题的方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> themes/butterfly</span><br><span class="line">$ git pull</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过以上步骤，你可以轻松地更新你的GitHub博客。定期更新内容，保持博客活跃，吸引更多读者。</p>]]></content>
      
      
      <categories>
          
          <category> 技术教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GitHub </tag>
            
            <tag> Hexo </tag>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>李宏毅苹果书读书学习笔记</title>
      <link href="/2025/03/10/%E6%9D%8E%E5%AE%8F%E6%AF%85%E8%8B%B9%E6%9E%9C%E4%B9%A6%E8%AF%BB%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2025/03/10/%E6%9D%8E%E5%AE%8F%E6%AF%85%E8%8B%B9%E6%9E%9C%E4%B9%A6%E8%AF%BB%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="学习目标："><a href="#学习目标：" class="headerlink" title="学习目标："></a>学习目标：</h1><ul><li><input checked="" disabled="" type="checkbox"> Task 1 《深度学习详解》- 1.1 通过案例了解机器学习</li><li><input checked="" disabled="" type="checkbox"> Task 2 《深度学习详解》- 1.2 了解线性模型</li><li><input checked="" disabled="" type="checkbox"> Task 3 《深度学习详解》- 2 机器学习框架&amp;实践攻略</li></ul><hr><h1 id="学习内容："><a href="#学习内容：" class="headerlink" title="学习内容："></a>学习内容：</h1><blockquote><p>欢迎去大家各大电商平台选购纸质版苹果书《深度学习详解》<br>基于上述书籍拓展</p></blockquote><blockquote><p>引用内容为书本原话 图片基本上来源于书中<br>我以自问自答的方式输出内容</p></blockquote><hr><h1 id="Task-1-通过案例了解机器学习"><a href="#Task-1-通过案例了解机器学习" class="headerlink" title="Task 1 通过案例了解机器学习"></a>Task 1 通过案例了解机器学习</h1><hr><h2 id="机器学习（Machine-Learning，ML）和深度学习（Deep-Learning，DL）的基本概念"><a href="#机器学习（Machine-Learning，ML）和深度学习（Deep-Learning，DL）的基本概念" class="headerlink" title="机器学习（Machine Learning，ML）和深度学习（Deep Learning，DL）的基本概念"></a>机器学习（Machine Learning，ML）和深度学习（Deep Learning，DL）的基本概念</h2><blockquote><p>什么是机器学习</p></blockquote><p>人工智能的一个分支。机器学习范畴比人工智能概念略小，深度学习的底层是神经网络。机器学习是指用计算机模拟人类学习行为的的技术用来从已知的数据中获取新的知识。</p><blockquote><p>机器学习，顾名思义，<strong>机器具备有学习的能力</strong>。具体来讲，机器学习就是让机器<strong>具备找一个函数的能力</strong>。机器具备找函数的能力以后，它可以做很多事。</p></blockquote><blockquote><p>比如语音识别，机器听一段声音，产生这段声音对应的文字。我们需要的是一个函数，该函数的输入是声音信号，输出是这段声音信号的内容。</p></blockquote><p> 就是让机器的输入映射到某个函数之后可以得到输出</p><h2 id="什么是回归（regression）"><a href="#什么是回归（regression）" class="headerlink" title="什么是回归（regression）"></a>什么是回归（regression）</h2><blockquote><p><strong>随着要找的函数不同，机器学习有不同的类别</strong>。假设要找的函数的<strong>输出是一个数值，一个标量（scalar）</strong>，这种机器学习的任务称为回归</p></blockquote><blockquote><p>机器要找一个<strong>函数 f</strong>，其输入是可能是<strong>种种跟预测 PM2.5 有关的指数</strong>，包括今天的 PM2.5 的数值、平均温度、平均的臭氧浓度等等，<strong>输出是明天中午的 PM2.5的数值</strong>,找这个函数的任务称为回归（regression）</p></blockquote><p>机器要找一个函数f(x)，其输入是可能是与预测目标有关的数值x，输出是对于下一次的预测值f(x)，找这个函数的任务称为回归（regression）。</p><blockquote><p><strong>隐藏任务①：</strong> 找出本篇中形如回归（regression）加粗字体的术语，并用自己的话进行解释，列成表格，与学习群的其他小伙伴讨论你的理解和搜索到的相关案例</p></blockquote><table><thead><tr><th>术语</th><th>解释</th></tr></thead><tbody><tr><td>分类</td><td>将数据划分为多个离散的类别的任务，预测输入的样本所属的类别</td></tr><tr><td>回归</td><td>通过对输入数据进行学习，建立一个连续的函数关系，预测数值型的输出结果</td></tr><tr><td>机器学习</td><td>一种从数据中自动学习模式和模型的方法，使计算机能够根据之前的经验来进行预测或决策</td></tr><tr><td>深度学习</td><td>一种机器学习的子领域，通过模拟人脑的神经网络结构，对大规模数据进行学习和表达复杂模式</td></tr><tr><td>损失</td><td>衡量预测的输出与实际值之间的差异的函数，用于评估模型的训练效果</td></tr><tr><td>梯度下降</td><td>一种优化算法，通过反复迭代的方式，沿着目标函数的负梯度方向调整模型参数的值，以最小化损失函数</td></tr></tbody></table><h2 id="什么是分类（classification）"><a href="#什么是分类（classification）" class="headerlink" title="什么是分类（classification）"></a>什么是分类（classification）</h2><blockquote><p>分类任务要让机器<strong>做选择题。<strong>人类先</strong>准备好一些选项，这些选项称为类别（class）</strong>，现在要找的函数的输出就是从设定好的选项里面<strong>选择一个当作输出，该任务称为分类。</strong><br>举个例子，每个人都有邮箱账户，邮箱账户里面有一个函数，该函数可以检测一封邮件是否为垃圾邮件。<strong>分类不一定只有两个选项，也可以有多个选项。</strong></p></blockquote><p>根据某些特征把不同数据分成不同的类别。</p><h2 id="什么是结构化学习"><a href="#什么是结构化学习" class="headerlink" title="什么是结构化学习"></a>什么是结构化学习</h2><blockquote><p>机器不只是要做选择题或输出一个数字，而是产生一个有结构的物体，比如让机器画一张图，写一篇文章。这种叫机器产生有结构的东西的问题称为结构化学习。</p></blockquote><p>就是根据输入的东西的某种规律生产某种相似结构的东西</p><h2 id="机器学习找函数的三个步骤"><a href="#机器学习找函数的三个步骤" class="headerlink" title="机器学习找函数的三个步骤"></a>机器学习找函数的三个步骤</h2><blockquote><p>隐藏任务③：找出机器学习找函数的3个步骤！并查找资料，交叉佐证这些步骤。</p></blockquote><blockquote><p>机器学习找函数的过程，分成3个步骤。</p></blockquote><h3 id="第1个步骤是写出一个带有未知参数的函数f，其能预测未来观看次数。"><a href="#第1个步骤是写出一个带有未知参数的函数f，其能预测未来观看次数。" class="headerlink" title="第1个步骤是写出一个带有未知参数的函数f，其能预测未来观看次数。"></a>第1个步骤是写出一个带有未知参数的函数<code>f</code>，其能预测未来观看次数。</h3><blockquote><p>y &#x3D; b + w ∗ x1，而 b 跟 w 是未知的。<br><strong>带有未知的参数（parameter）的函数称为模型（model）。</strong><br>模型在机器学习里面，就是一个带有未知的参数的函数，特征（feature）  $x_1$ 是这个函数里面已知的，它是来自于后台的信息，2 月 25 日点击的总次数是已知的，而 w 跟 b 是未知的参数。<br><strong>w 称为权重（weight），b 称为偏置（bias）。</strong></p></blockquote><h3 id="第2个步骤是定义损失（loss），损失也是一个函数。"><a href="#第2个步骤是定义损失（loss），损失也是一个函数。" class="headerlink" title="第2个步骤是定义损失（loss），损失也是一个函数。"></a>第2个步骤是定义损失（loss），损失也是一个函数。</h3><blockquote><p>估测的值跟实际的值之间的差距，其实有不同的计算方法，计算 y 与 yˆ 之间绝对值的差距，如式 (1.6) 所示，称为平均绝对误差（Mean Absolute Error，MAE）</p><p><img src="/img/downloaded/aHR0cHM6_33d3ffa7ce6d47cbacd0f5fcc1211984.png" alt="在这里插入图片描述"></p></blockquote><blockquote><p>如果算 y 与 yˆ 之间平方的差距，如式 (1.7) 所示，则称为均方误差（Mean SquaredError，MSE）。<br><img src="/img/downloaded/aHR0cHM6_8882f24dbc85463d87b8b1ac62bf69e2.png" alt="在这里插入图片描述"></p><p>有一些任务中 y 和 yˆ 都是概率分布，这个时候可能会选择<strong>交叉熵</strong>（cross entropy），这个是机器学习的第 2 步。</p></blockquote><p><strong>交叉熵</strong>是信息论中用来度量两个概率分布之间差异的一种方法。在机器学习中，<strong>交叉熵</strong>经常被用来作为损失函数，用来度量预测结果与真实结果之间的差异。</p><p>对于分类问题，<strong>交叉熵</strong>可以用来度量预测结果的概率分布与真实结果的概率分布之间的差异。<strong>交叉熵</strong>的计算公式如下：</p><p>$$H(p,q) &#x3D; -∑ p(x) * log(q(x))$$</p><p>其中，<code>p(x)</code>表示真实结果的概率分布，<code>q(x)</code>表示预测结果的概率分布。</p><p><strong>交叉熵</strong>的值越小，表示预测结果与真实结果越接近，模型的性能也越好。因此，通过最小化<strong>交叉熵</strong>，可以优化模型的预测能力。</p><p>在深度学习中，<strong>交叉熵</strong>通常作为损失函数与激活函数一起使用，用来训练神经网络模型。通过反向传播算法，可以根据<strong>交叉熵</strong>的值来调整模型的参数，使得模型的预测结果与真实结果更加接近。</p><h3 id="机器学习的第-3-步：解一个最优化的问题。"><a href="#机器学习的第-3-步：解一个最优化的问题。" class="headerlink" title="机器学习的第 3 步：解一个最优化的问题。"></a>机器学习的第 3 步：解一个最优化的问题。</h3><blockquote><p>找一个 <code>w</code> 跟 <code>b</code>，把未知的参数找一个数值出来，看代哪一个数值进去可以让损失 L 的值最小，就是要找的 <code>w</code> 跟 <code>b</code>，这个可以让损失最小的 <code>w</code> 跟 <code>b</code> 称为 <code>w∗</code> 跟 <code>b∗</code> 代表它们是最好的一组 <code>w</code> 跟 <code>b</code>，可以让损失的值最小。</p></blockquote><p><strong>梯度下降</strong>（gradient descent）是经常会使用优化的方法。</p><blockquote><p>试了不同的参数，计算它的损失，画出来的等高线图称为误差表面（error surface）。<br>在这个等高线图上面，越偏红色系，代表计算出来的损失越大，就代表这一组 w 跟 b 越差。如果越偏蓝色系，就代表损失越小，就代表这一组 w 跟 b 越好，拿这一组 w 跟 b，放到函数里面，预测会越精准。<img src="/img/downloaded/aHR0cHM6_e19efe52835c4b9696362974134bfb53.png" alt="在这里插入图片描述"></p></blockquote><blockquote><p><strong>学习率（learning rate）η 也会影响步伐大小</strong>。<br>学习率是自己设定的，如果 η 设大一点，每次参数更新就会量大，学习可能就比较快。如果 η 设小一点，参数更新就很慢，每次只会改变一点点参数的数值。<br><strong>这种在做机器学习，需要自己设定，不是机器自己找出来的，称为超参数（hyperparameter）。</strong></p></blockquote><h2 id="为什么损失可以是负的？"><a href="#为什么损失可以是负的？" class="headerlink" title="为什么损失可以是负的？"></a>为什么损失可以是负的？</h2><p><img src="/img/downloaded/aHR0cHM6_54e8e9e426724a82a147d4b0b957959b.png" alt="在这里插入图片描述"></p><h2 id="梯度下降有一个很大的问题"><a href="#梯度下降有一个很大的问题" class="headerlink" title="梯度下降有一个很大的问题"></a>梯度下降有一个很大的问题</h2><blockquote><p><strong>梯度下降</strong>有一个很大的问题，没有找到真正最好的解，没有找到可以让损失最小的 w。<br>在图 1.4 所示的例子里面，把 w 设定在最右侧红点附近这个地方可以让损失最小。但如果在<strong>梯度下降</strong>中，$w^0$ 是随机初始的位置，也很有可能走到 wT 这里，训练就停住了，无法再移动 w 的位置。右侧红点这个位置是真的可以让损失最小的地方，称为全局最小值（global minima），而 wT 这个地方称为局部最小值（local minima），其左右两边都比这个地方的损失还要高一点，但是它不是整个误差表面上面的最低点。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_5ef2f64926e348afbbbeea25588742c7.png" alt="在这里插入图片描述"><br>推广到多参数(w,b)的话</p><blockquote><p>假设有两个参数，随机初始值为 $w^0$, $b^0$。要计算 w, b 跟损失的微分，计算在 w &#x3D; $w^0$ 的位置，b &#x3D; $b^0$ 的位置，要计算 w 对 L 的微分，计算 b 对 L 的微分计算完后更新 w 跟 b，把 $w^0$ 减掉学习率乘上微分的结果得到 ，把 $b^0$ 减掉学习率乘上微分的结果得到 $b^1$。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_a7b5317aebaf45f89cd8ec94c022e6f4.png" alt="在这里插入图片描述"></p><p><img src="/img/downloaded/aHR0cHM6_3452064a661c4ec0b08939074d5e2262.png"></p><blockquote><p>就是反复同样的步骤，就不断的更新 <code>w</code> 跟 <code>b</code>，期待最后，可以找到一个最好的 <code>w</code>，w∗ 跟最好的 <code>b∗</code>. 如图 1.5 所示，随便选一个初始的值，先计算一下 <code>w</code> 对 L 的微分，跟计算一下 <code>b</code> 对 L 的微分，接下来更新 <code>w</code> 跟 <code>b</code>，更新的方向就是 <code>∂L/∂w</code>，乘以 η 再乘以一个负号，∂L&#x2F;∂b，算出这个微分的值，就可以决定更新的方向，可以决定 <code>w</code> 要怎么更新。把 <code>w</code> 跟 <code>b</code> 更新的方向结合起来，就是一个向量，就是红色的箭头，再计算一次微分，再决定要走什么样的方向，把这个微分的值乘上学习率，再乘上负号，我们就知道红色的箭头要指向那里，就知道如何移动 <code>w</code> 跟 <code>b</code> 的位置，一直移动，期待最后可以找出一组不错的 <code>w</code>, <code>b</code>。</p></blockquote><h1 id="Task-2-了解线性模型"><a href="#Task-2-了解线性模型" class="headerlink" title="Task 2  了解线性模型"></a>Task 2  了解线性模型</h1><h2 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2><p>书中举例了一个预测观看人数的例子 </p><blockquote><p>每隔 7 天它一个循环，如果一个模型参考前 7 天的数据，把 7天前的数据，直接复制到拿来当作预测的结果，也许预测的会更准也说不定，所以我们就要修改一下模型。通常一个模型的修改，往往来自于对这个问题的理解，即<strong>领域知识</strong>。</p></blockquote><p>机器学习领域的领域知识是指机器学习算法、技术和应用方面的专业知识。<br>包括机器学习算法、数据预处理、特征工程、模型评估和选择的知识。</p><blockquote><p>这些模型都是把输入的特征 x 乘上一个权重，再加上一个偏置就得到预测的结果，这样的模型称为<strong>线性模型（linear model）</strong>。</p></blockquote><h3 id="分段线性曲线"><a href="#分段线性曲线" class="headerlink" title="分段线性曲线"></a>分段线性曲线</h3><blockquote><p>红色的曲线可以看作是一个常数再加上一群 Hard <code>Sigmoid </code>函数。Hard <code>Sigmoid </code>函数的特性是当输入的值，当 x 轴的值小于某一个阈值（某个定值）的时候，大于另外一个定值阈值的时候，中间有一个斜坡。所以它是先水平的，再斜坡，再水平的。所以红色的线可以看作是一个常数项加一大堆的蓝色函数（Hard Sigmoid）。常数项设成红色的线跟 x 轴的交点一样大。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_3b3eda53be35441bb2e996c427b449c2.png" alt="在这里插入图片描述"></p><blockquote><p>常数项怎么加上蓝色函数后，变成红色的这一条线?</p><ol><li>蓝线 1 函数斜坡的起点，设在红色函数的起始的地方，第 2 个斜坡的终点（最高点）|（第 1 个蓝色函数斜坡的终点） 设在第一个转角处，让第 1 个蓝色函数的斜坡和红色函数的斜坡的斜率是一样的，这个时候把 线0+线1 就可以得到红色曲线左侧的线段。</li><li>再加第 2 个蓝色的函数，所以第2 个蓝色函数的斜坡就在红色函数的第一个转折点到第 2 个转折点之间，让第 2 个蓝色函数的斜率跟红色函数的斜率一样，这个时候把 线0+线1+线2，就可以得到红色函数左侧和中间的线段。</li><li>接下来第 3 个部分，第 2 个转折点之后的部分，就加第 3 个蓝色的函数，第 3 个蓝色的函数坡度的起始点设的跟红色函数转折点一样，蓝色函数的斜率设的跟红色函数斜率一样</li><li>接下来把 线0+线1+线2+线3全部加起来，就得到完整红色的线。<br>(线0、线1、线2、线3 为图1.8中线段）</li></ol></blockquote><p><img src="/img/downloaded/aHR0cHM6_e394f591a7d44639bf1f9ec056473cba.png" alt="在这里插入图片描述"></p><blockquote><p>所以红色线，即分段线性曲线（piecewise linear curve）可以看作是一个常数，再加上一堆蓝色的函数。</p></blockquote><p>大量不同的蓝色函数，加上一个常数以后就可以组出任意的分段线性曲线。<br>如果分段线性曲线越复杂，转折的点越多，所需的蓝色函数就越多。<br>反之，越多蓝色函数的话可以组成越复杂的分段线性曲线。</p><p><strong>可以在这样的曲线（图1.9）上面，先取一些点并连起来变成一个分段线性曲线。这个分段线性曲线跟非常接近原来的曲线，如果点取的够多或点取的位置适当，分段线性曲线就可以逼近这一个连续的曲线。</strong> </p><p><img src="/img/downloaded/aHR0cHM6_85ca75a8ba474157864729b726d34f20.png" alt="在这里插入图片描述"></p><blockquote><p>所以可以用分段线性曲线去逼近任何的连续的曲线，而每个分段线性曲线都可以用一大堆蓝色的函数组合起来。也就是说，只要有足够的蓝色函数把它加起来，就可以变成任何连续的曲线。</p></blockquote><p>我们可以用任意多的蓝色函数来模拟出曲线。<br>极限的思路来看：就是只有取得足够多的点并且相连接，就可以无限多的直线代替曲线。</p><h3 id="如何表示方程"><a href="#如何表示方程" class="headerlink" title="如何表示方程"></a>如何表示方程</h3><p><img src="/img/downloaded/aHR0cHM6_9db4a3d0ece343c4be8e5a2c18926e4a.png" alt="在这里插入图片描述"></p><blockquote><p>如果 x1 的值，趋近于无穷大的时候，e−(b+wx1) 这一项就会消失，当 x1 非常大的时候，这一条就会收敛在高度为 c 的地方。如果 x1 负的非常大的时候，分母的地方就会非常大，y的值就会趋近于 0。<br>所以可以用这样子的一个函数逼近这一个蓝色的函数，即 <code>Sigmoid </code>函数，<code>Sigmoid </code>函数就是 S 型的函数。<br>因为它长得是有点像是 S 型，所以叫它 <code>Sigmoid </code>函数。为了简洁，去掉了指数的部分，蓝色函数的表达式为</p></blockquote><p>$$y &#x3D; cσ(b + wx1) (1.15)$$</p><blockquote><p>所以可以用 <code>Sigmoid </code>函数逼近 Hard <code>Sigmoid </code>函数。</p></blockquote><p>$$<br>y &#x3D; \frac{c}{ 1+ e^{-(b+wx1)}}<br>$$</p><blockquote><p><strong>调整这里的 <code>b</code>、<code>w </code>和 <code>c</code> 可以制造各种不同形状的 <code>Sigmoid </code>函数，</strong> 用各种不同形状的 Sigmoid函数去逼近 Hard <code>Sigmoid </code>函数。</p></blockquote><blockquote><p>如图 1.11 所示，如果改 w，就会改变斜率，就会改变斜坡的坡度。如果改了 <code>b</code>，就可以把这一个 <code>Sigmoid </code>函数左右移动；如果改 <code>c</code>，就可以改变它的高度。所以只要有不同的 <code>w </code>不同的 <code>b</code> 不同的 <code>c</code>，就可以制造出不同的 <code>Sigmoid </code>函数，把不同的<code>Sigmoid </code>函数叠起来以后就可以去逼近各种不同的分段线性函数；分段线性函数可以拿来近似各种不同的连续的函数。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_f9f5ee0a313944d1bacb1b9e1d549fe2.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_a8f6973d038c490aa5f324f92c587580.png" alt="在这里插入图片描述"></p><blockquote><p>我们可以不只用一个特征<code> x1</code>，可以用多个特征代入不同的 <code>c, b, w</code>，组合出各种不同的函数，从而得到更有 <strong>灵活性（flexibility）</strong> 的函数，如图 1.13 所示。<br>用 <code>j </code>来代表特征的编号。如果要考虑前 28 天，<code>j </code>就是 1 到 28。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_a69bac4cc1c7482cadf10b21208428b5.png" alt="在这里插入图片描述"></p><blockquote><p>无论是拿行或拿列都可以，把 W 的每一列或每一行“拼”成一个长的向量，把 b, cT, b” 拼” 上来，这个长的向量直接用 θ 来表示。<br>所有的未知的参数，一律统称 θ。</p></blockquote><h4 id="优化是找一个可以让损失最小的参数，是否可以穷举所有可能的未知参数的值？"><a href="#优化是找一个可以让损失最小的参数，是否可以穷举所有可能的未知参数的值？" class="headerlink" title="优化是找一个可以让损失最小的参数，是否可以穷举所有可能的未知参数的值？"></a>优化是找一个可以让损失最小的参数，是否可以穷举所有可能的未知参数的值？</h4><p><img src="/img/downloaded/aHR0cHM6_7c50b0a3c97849b0ac539dbe34230d54.png" alt="在这里插入图片描述"></p><h4 id="刚才的例子里面有-3-个-Sigmoid，为什么是-3-个，能不能-4-个或更多？"><a href="#刚才的例子里面有-3-个-Sigmoid，为什么是-3-个，能不能-4-个或更多？" class="headerlink" title="刚才的例子里面有 3 个 Sigmoid，为什么是 3 个，能不能 4 个或更多？"></a>刚才的例子里面有 3 个 Sigmoid，为什么是 3 个，能不能 4 个或更多？</h4><p><img src="/img/downloaded/aHR0cHM6_5136ea488dba48da88cb96625968b6a2.png" alt="在这里插入图片描述"></p><h3 id="定义损失"><a href="#定义损失" class="headerlink" title="定义损失"></a>定义损失</h3><blockquote><p>之前是 <code>L(w, b)</code>，因为 w 跟 b 是未知的。<br>现在未知的参数很多了，再把它一个一个列出来太累了，所以直接用 θ 来统设所有的参数，所以损失函数就变成 <code>L(θ)</code>。</p></blockquote><blockquote><p>损失函数能够判断 <code>θ</code> 的好坏，其计算方法跟刚才只有两个参数的时候是一样的。<br>先给定 <code>θ</code> 的值，即某一组 <code>W, b, cT, b</code> 的值，再把一种特征 <code>x</code> 代进去，得到估测出来的 <code>y</code>，再计算一下跟真实的标签之间的误差 <code>e</code>。把所有的误差通通加起来，就得到损失。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_8ab5780e47174a3580be5690eb786de1.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_60bf1b0bfb3e4f319f3766d50d674c37.png" alt="在这里插入图片描述"></p><blockquote><p>要找到 $θ$让损失越小越好，可以让<br>损失最小的一组 $θ$称为 $θ_∗$。一开始要随机选一个初始的数值 $θ_0$。<br>接下来计算每一个未知的参数对 L 的微分，得到向量 $g$，即可以让损失变低的函数</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_5aa8c959c29b4a72bfedbd274b00b887.png" alt="在这里插入图片描述"></p><blockquote><p>假设有 1000 个参数，这个向量的长度就是 1000，这个向量也称为梯度，$∇L$代表梯度。<br>L($θ_0$) 是指计算梯度的位置，是在 θ 等于 $θ_0$ 的地方。<br>计算出 g 后，接下来跟新参数，$θ_0$ 代表它是一个起始的值，它是一个随机选的起始的值，代表 $θ_1$ 更新过一次的结果，$θ^0_2$ 减掉微分乘以，减掉 η 乘上微分的值，得到 $θ^1_2$，以此类推，就可以把 1000 个参数都更新了。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_92abe1a1c1114610b3bbc58d68a7c638.png" alt="在这里插入图片描述"></p><blockquote><p>假设参数有 1000 个，$θ_0$ 就是 1000 个数值，1000 维的向量，g 是 1000 维的向量，$θ_1$ 也是 1000 维的向量。 整个操作就是这样，由 $θ_0$ 算梯度，根据梯度去把 $θ_0$ 更新成 $θ_1$，再算一次梯度，再根据梯度把 $θ_1$ 再更新成 $θ_2$，再算一次梯度把 $θ_2$ 更新成 $θ_3$，以此类推，直到不想做。<br><img src="/img/downloaded/aHR0cHM6_fdd986e113434fbcbd1d5c835d558c5f.png" alt="在这里插入图片描述"></p></blockquote><blockquote><p>或者计算出梯度为 0 向量，导致无法再更新参数为止，不过在实现上几乎不太可能梯度为 0，通常会停下来就是我们不想做了。</p></blockquote><h3 id="实现上的细节"><a href="#实现上的细节" class="headerlink" title="实现上的细节"></a>实现上的细节</h3><h4 id="批量（batch）"><a href="#批量（batch）" class="headerlink" title="批量（batch）"></a>批量（batch）</h4><p><img src="/img/downloaded/aHR0cHM6_6c121abd25e74f5da606124044251c7c.png" alt="在这里插入图片描述"></p><blockquote><p>实现上有个细节的问题，实际使用梯度下降的时候，如图 1.17 所示，会把 N 笔数据随机分成一个一个的<strong>批量（batch）</strong>，一组一组的。</p></blockquote><p>在深度学习中，<strong>批量（Batch）</strong> 指的是计算一次<strong>成本（cost）</strong> 需要的输入数据个数。当数据集比较大时，一次性处理所有样本在计算和存储上会有困难，因此会采用一次输入一定量的样本来进行训练。</p><p><strong>如果数据集比较小，可以将全体数据看做一个批量，即把数据集中每个样本都计算损失（loss）然后取其平均值当做成本（cost）。</strong></p><p><strong>批量学习的优点</strong>：能更好地代表样本总体从而更准确地确定下降方向，对梯度向量有更精确的估计等。</p><h4 id="回合（epoch）"><a href="#回合（epoch）" class="headerlink" title="回合（epoch）"></a>回合（epoch）</h4><blockquote><p>把所有的批量都看过一次，称为一个回合（epoch），每一次更新参数叫做一次更新。更新跟回合是不同的东西。每次更新一次参数叫做一次更新，把所有的批量都看过一遍，叫做一个回合。</p></blockquote><p><strong>回合（Epoch）</strong> 指的是遍历全部数据集一次。<br>在一个回合中，模型会对数据集中的所有样本都进行处理和学习。</p><h2 id="模型变形"><a href="#模型变形" class="headerlink" title="模型变形"></a>模型变形</h2><blockquote><p>其实还可以对模型做更多的变形，不一定要把 Hard Sigmoid 换成 Soft Sigmoid。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_fafd73da66564321890309726de67aab.png" alt="在这里插入图片描述"></p><blockquote><p><strong>HardSigmoid 可以看作是两个修正线性单元（Rectifed Linear Unit， ReLU） 的加总， ReLU 的图像有一个水平的线，走到某个地方有一个转折的点，变成一个斜坡，</strong> 其对应的公式为</p></blockquote><p>$$<br>c ∗ max(0, b + wx1)<br>$$</p><p><strong>输出0或b+ w1为正的。</strong></p><p><img src="/img/downloaded/aHR0cHM6_03de17282ec048f2863b7ab58a81f6b3.png" alt="在这里插入图片描述"></p><blockquote><p><strong>把两个 ReLU 叠起来就可以变成 Hard 的 Sigmoid</strong>，想要用 ReLU，就把 Sigmoid 的地方，换成</p></blockquote><p>$$max(0, b_i + w_{ij}x_{j})$$</p><blockquote><p>要<strong>合成 i 个 Hard Sigmoid， 需要 i 个 Sigmoid，如果 ReLU 要做到一样的事情，则需要 2i 个 ReLU</strong>，因为 2 个 ReLU 合 起来才是一个 Hard Sigmoid。因此<strong>表示一个 Hard 的 Sigmoid 不是只有一种做法</strong>。</p></blockquote><h3 id="激活函数（activation-function）"><a href="#激活函数（activation-function）" class="headerlink" title="激活函数（activation function）"></a>激活函数（activation function）</h3><blockquote><p>在机器学习里面， <strong>Sigmoid 或 ReLU 称为激活函数（activation function）</strong>。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_9b6073c8277646fcb7a0ef7fad256122.png" alt="在这里插入图片描述"></p><blockquote><p>Sigmoid 跟 ReLU 是最常见的激活函数，接下来的实<br>验都选择用了 ReLU，显然 ReLU 比较好，实验结果如图 1.20 所示。</p></blockquote><blockquote><p><strong>连续使用 10 个 ReLU作为模型，跟用线性模型的结果是差不多的</strong></p></blockquote><blockquote><p>但连续使用 100 个 ReLU 作为模型，结果就有显著差别了， 100 个 ReLU 在训练数据上的损失就可以从 320 降到 280，有 100 个 ReLU 就可以制造比较复杂的曲线，本来线性就是一直线，但 100 个 ReLU 就可以产生 100 个折线的函数，在测试数据上也好了一些。<br>接下来使用 1000 个 ReLU 作为模型，<strong>在训练数据上损失更低了一些，但是在没看过的数据上，损失没有变化</strong>。</p></blockquote><p><strong>Sigmoid 跟 ReLU 是最常见的激活函数</strong></p><blockquote><p>继续改模型</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_4a5b5c0de372450c85459dfc8abbcad7.png" alt="在这里插入图片描述"></p><blockquote><p>如图 1.21 所示，<strong>从 x 变成 a，就是把 x 乘上 w 加 b，再通过 Sigmoid 函数</strong>。</p></blockquote><blockquote><p><strong>不一定要通过Sigmoid 函数</strong>，通过 ReLU 也可以得到 a，同样的事情再<strong>反复地多做几次</strong>。 所以可以把 x 做这一连串的运算产生 a，接下来把 a做这一连串的运算产生 a′。 反复地多做的次数又是另外一个超参数。<br><strong>注意， w, b 和 w′, b′ 不是同一个参数，是增加了更多 的未知的参数。</strong></p></blockquote><h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><p><img src="/img/downloaded/aHR0cHM6_eb720854b37f44019699e122c965429c.png" alt="在这里插入图片描述"></p><blockquote><p>如图 1.24 所示， <strong>Sigmoid 或 ReLU 称为神经元（neuron），很多的神经元称为神经网络（neural network）</strong>。<br>  <strong>每一排称为一层，称为隐藏层（hiddenlayer），很多的隐藏层就“深”，这套技术称为深度学习</strong>。</p></blockquote><blockquote><p>人们<strong>把神经网络越叠越多越叠越深</strong><br>残差网络（Residual Network， ResNet） 有 152 层，错误率降到 3.57%。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_5d9dd3323adf44ab9bdab196dc56227c.png" alt="在这里插入图片描述"></p><p>如图 1.25 所示。在训练数据和测试数据上的结果是不一致的，这种情况称为<strong>过拟合（overftting）</strong>。</p><h1 id="Task-3-机器学习框架-实践攻略"><a href="#Task-3-机器学习框架-实践攻略" class="headerlink" title="Task 3 机器学习框架&amp;实践攻略"></a>Task 3 机器学习框架&amp;实践攻略</h1><h2 id="机器学习框架"><a href="#机器学习框架" class="headerlink" title="机器学习框架"></a>机器学习框架</h2><h3 id="定义函数fθ-x"><a href="#定义函数fθ-x" class="headerlink" title="定义函数fθ(x)"></a>定义函数fθ(x)</h3><blockquote><p><strong>定义一个函数$f_θ(x)$，其中θ表示模型中的所有未知参数</strong>。该函数接收输入特征x，并根据参数θ计算输出。</p></blockquote><h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><blockquote><p><strong>定义一个损失函数，用于评估给定参数组合θ的好坏程度</strong>。损失函数的选择依赖于具体的问题和模型类型。常见的损失函数包括均方误差、交叉熵等。</p></blockquote><h3 id="优化问题求解"><a href="#优化问题求解" class="headerlink" title="优化问题求解"></a>优化问题求解</h3><blockquote><p>的目标是寻找一个最优的参数组合θ∗，<strong>使得损失函数的值最小化</strong>。这可以通过求解一个优化问题来实现。常用的优化算法包括梯度下降、牛顿法等。</p></blockquote><h3 id="应用于测试数据"><a href="#应用于测试数据" class="headerlink" title="应用于测试数据"></a>应用于测试数据</h3><blockquote><p><strong>找到最优参数θ∗后，可以将其应用于测试数据</strong>。将测试集中的输入特征x带入函数$f_θ(x)$，得到预测结果。</p></blockquote><h3 id="提交到Kaggle进行评估"><a href="#提交到Kaggle进行评估" class="headerlink" title="提交到Kaggle进行评估"></a>提交到Kaggle进行评估</h3><blockquote><p>将预测结果提交到Kaggle等竞赛平台进行评估。该平台会根据预测结果与真实值之间的差异进行评分，以衡量模型的性能。</p></blockquote><p>总结一下就是<strong>定义一个函数</strong>$f_θ(x)$，其中θ代表模型中的未知参数。然后，<strong>定义一个损失函数</strong>来评估参数组合的好坏程度。然后，通过<strong>优化问题求解</strong>找到最优参数<code>θ∗</code>，<strong>使损失函数最小化</strong>。然后，将<strong>最优参数应用于测试数据，得到预测结果</strong>。最后，将预测结果<strong>提交到评估平台</strong>进行性能评估。</p><h2 id="实践方法论"><a href="#实践方法论" class="headerlink" title="实践方法论"></a>实践方法论</h2><h3 id="为什么会出现模型偏差"><a href="#为什么会出现模型偏差" class="headerlink" title="为什么会出现模型偏差"></a>为什么会出现模型偏差</h3><blockquote><p><strong>模型偏差可能会影响模型训练。</strong></p></blockquote><blockquote><p>假设<strong>模型过于简单</strong>，一个有未知参数的函数代$θ_1$ 得到一个函数$f_θ1(x)$，同理可得到另一个函数 $f_θ2(x)$，把所有的函数集合起来得到一个函数的集合。但是该函数的集合太小了，没有包含任何一个函数，<strong>可以让损失变低的函数不在模型可以描述的范围内</strong>。</p></blockquote><p>如何解决</p><ol><li><strong>用深度学习，增加更多的灵活性</strong>。</li><li>所以如果模型的灵活性不够大，可以<strong>增加更多特征，可以设一个更大的模型</strong>，可以用深度学习来增加模型的灵活性，这是第一个可以的解法。</li><li>但是并不是训练的时候，损失大就代表一定是模型偏差，可能会遇到另外一个问题：<strong>优化做得不好</strong>。</li></ol><h3 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h3><blockquote><p><strong>一般只会用到梯度下降进行优化，这种优化的方法很多的问题。</strong></p></blockquote><blockquote><p>比如可能会卡在局部最小值的地方，无法找到一个真的可以让损失很低的参数，如图 2.3(a) 所示。如图 2.3(b) 所示蓝色部分是模型可以表示的函数所形成的集合，可以把 θ 代入不同的数值，形成不同的函数，把所有的函数通通集合在一起，得到这个蓝色的集合。这个蓝色的集合里面，确实包含了一些函数，这些函数它的损失是低的。<br><strong>但问题是梯度下降这一个算法无法找出损失低的函数，梯度下降是解一个优化的问题，找到 θ∗ 就结束了。但 θ∗ 的损失不够低。</strong></p></blockquote><p><img src="/img/downloaded/aHR0cHM6_97e4040032b74ea6aa21954b977d5936.png" alt="在这里插入图片描述"><br>还是可能会出现卡在局部最小值的地方,仍未能找到真正的最优解</p><h3 id="如何判断模型是否足够大？"><a href="#如何判断模型是否足够大？" class="headerlink" title="如何判断模型是否足够大？"></a>如何判断模型是否足够大？</h3><blockquote><p>一个建议判断的方法，通过比较不同的模型来判断模型现在到底够不够大。</p></blockquote><p> <img src="/img/downloaded/aHR0cHM6_2f14529755384bbbb10acdd98529b589.png" alt="在这里插入图片描述"></p><blockquote><p>很多人看到这张图认为这个代表过拟合，深度学习不奏效， 56 层太深了不奏效，根本就不需要这么深。但个不是过拟合，并不是所有的结果不好，都叫做过拟合。在训练集上， 20 层的网络损失其实是比较低的， 56 层的网络损失是比较高的，如图 2.4(b) 所示，这代表 56 层的网络的优化没有做好，它的优化不给力。</p></blockquote><p>层数多但是反而效果不好，不一定是过拟合，可能是因为它的优化没有做好。</p><blockquote><p>看到一个从来没有做过的问题，可以<strong>先跑一些比较小的、比较浅的网络，或甚至用一些非深度学习的方法，比如线性模型、支持向量机（Support Vector Machine，SVM）</strong>， SVM 可能是比较容易做优化的，它们比较不会有优化失败的问题。</p></blockquote><p>对于一个新的问题可以多种不同的模型综合考量一下。<br>先跑一个小的模型试一下，在逐步加深模型。</p><h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h3><h3 id="为什么会有过拟合这样的情况呢？"><a href="#为什么会有过拟合这样的情况呢？" class="headerlink" title="为什么会有过拟合这样的情况呢？"></a>为什么会有过拟合这样的情况呢？</h3><blockquote><p>举一个极端的例子，这是训练集。</p></blockquote><blockquote><p>假设根据这些训练集，某一个很废的机器学习的方法找出了一个一无是处的函数。这个一无是处的函数，只要输入 x 有出现在训练集里面，就把它对应的 y 当做输出。<strong>如果 x 没有出现在训练集里面，就输出一个随机的值。这个函数啥事也没有干，其是一个一无是处的函数，但它在训练数据上的损失是 0</strong>。把训练数据通通丢进这个函数里面，它的输出跟训练集的标签是一模一样的，<strong>所以在训练数据上面，这个函数的损失可是 0 呢，可是在测试数据上面，它的损失会变得很大，因为它其实什么都没有预测，这是一个比较极端的例子，在一般的情况下，也有可能发生类似的事情</strong>。</p></blockquote><h3 id="灵活性太大带来的问题"><a href="#灵活性太大带来的问题" class="headerlink" title="灵活性太大带来的问题"></a>灵活性太大带来的问题</h3><p><img src="/img/downloaded/aHR0cHM6_7aad017e757746fabb21ac0ff5ac08a2.png" alt="在这里插入图片描述"></p><blockquote><p>如图 2.6 所示，举例来说，假设输入的特征为 x，输出为 y， x 和 y 都是一维的。<br>x 和 y之间的关系是 2 次的曲线，<strong>曲线用虚线来表示，因为通常没有办法，直接观察到这条曲线</strong>。我们<strong>真正可以观察到的是训练集，训练集可以想像成从这条曲线上面，随机采样出来的几个点</strong>。</p></blockquote><blockquote><p>模型的能力非常的强，其灵活性很大，只给它这 3 个点。在这 3 个点上面，<strong>要让损失低，所以模型的这个曲线会通过这 3 个点，但是其它没有训练集做为限制的地方，因为它的灵活性很大，它灵活性很大，所以模型可以变成各式各样的函数，没有给它数据做为训练，可以产生各式各样奇怪的结果</strong>。</p></blockquote><blockquote><p><strong>如果再丢进测试数据，测试数据和训练数据，当然不会一模一样，它们可能是从同一个分布采样出来的，测试数据是橙色的点，训练数据是蓝色的点</strong>。</p></blockquote><h3 id="如何解决过拟合问题"><a href="#如何解决过拟合问题" class="headerlink" title="如何解决过拟合问题"></a>如何解决过拟合问题</h3><ol><li><p>增加数据集，数据增强<br><img src="/img/downloaded/aHR0cHM6_6710dfbe85484bd7a8324512e3cf0da5.png" alt="在这里插入图片描述"></p></li><li><p>给模型一些限制，让模型不要有过大的灵活性。</p><blockquote><p>如图 2.8 所示，要用多限制的模型才会好取决于对这个问题的理解。因为这种模型是自己设计的，设计出不同的模型，结果不同。解决过拟合的问题，要给模型一些限制，最好模型正好跟背后产生数据的过程，过程是一样的就有机会得到好的结果。</p></blockquote></li></ol><blockquote><p><strong>如果是深度学习的话，就给它比较少的神经元的数量，本来每层一千个神经元，改成一百个神经元之类的，或者让模型共用参数，可以让一些参数有一样的数值</strong>。 </p></blockquote><blockquote><p><strong>全连接网络（fully-connected network） 其实是一个比较有灵活性的架构，而卷积神经网络（Convolutional Neural Network， CNN） 是一个比较有限制的架构。</strong> <strong>CNN 是一种比较没有灵活性的模型，其是针对图像的特性来限制模型的灵活性</strong>。所以全连接神经网络，可以找出来的函数所形成的集合其实是比较大的， CNN 所找出来的函数，它形成的集合其实是比较小的，其实包含在全连接网络里面的，但是就是因为<strong>CNN 给了，比较大的限制，所以 CNN 在图像上，反而会做得比较好</strong>。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_9ba7dbf22dff42b2925ff53350d9e853.png" alt="在这里插入图片描述"><br>但也不要给太多的限制。有可能会因为模型太大的限制，大到有了模型偏差的问题。</p><ol start="3"><li>比如早停（early stopping）、正则化（regularization）和丢弃法（dropout<br>method）。</li></ol><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><blockquote><p>一种比较合理的选择模型的方法是将训练数据分成训练集和验证集，通常是将90%的数据用作训练集，剩余的10%作为验证集。训练集用于训练模型，验证集用于评估模型的性能。<br>在训练集上训练出的模型会使用验证集来衡量模型的分数。根据验证集上的分数选择最佳的模型，并将该模型的结果上传到Kaggle等平台上得到公开分数。<br>这个过程中，使用验证集来选择模型，因此公开测试集的分数可以反映私人测试集的分数。然而，如果这个过程重复太多次，根据公开测试集的结果调整模型太多次，就有可能在公开测试集上过拟合，导致在私人测试集上得到差的结果。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_d85545a530ca472686fe86b8d3ead1a0.png" alt="在这里插入图片描述"><br><strong>因此，需要在选择模型时找到平衡，避免过度拟合，并注意不要过多地根据公开测试集的结果调整模型。</strong></p><p><strong>在选择模型时，常用的方法是将训练数据分成训练集和验证集</strong>。训练集用于训练模型，验证集用于评估模型在未知数据上的性能。通常情况下，将大约90%的数据用作训练集，剩余的10%作为验证集。<strong>模型在验证集上的表现可以作为选择模型的依据</strong>。</p><p>然而，<strong>在选择模型的过程中需要注意，过多地根据公开测试集上的结果调整模型可能会导致在私人测试集上得到较差的结果，即过拟合的问题</strong>。因此，在选择模型时<strong>需要找到一个平衡，避免过度拟合模型</strong>。</p><blockquote><p><strong>最好的做法，就是用验证损失，最小的直接挑就好了，不要管公开测试集的结果</strong>。<br>在实现上，不太可能这么做，因为公开数据集的结果对模型的选择，可能还是会有些影响的。<strong>理想上就用验证集挑就好，有过比较好的基线（baseline） 算法以后，就不要再去动它了，就可以避免在测试集上面过拟合</strong>。</p></blockquote><h3 id="k-折交叉验证"><a href="#k-折交叉验证" class="headerlink" title="k 折交叉验证"></a>k 折交叉验证</h3><p><img src="/img/downloaded/aHR0cHM6_40d78d2dae2a46c5b8e7549197f66e83.png" alt="在这里插入图片描述"></p><blockquote><p>用 k 折交叉验证（k-fold cross validation），如图 2.11 所示。 k 折交叉验证就是先把训练集切成 k 等份。在这个例子，训练集被切成 3 等份，切完以后，拿其中一份当作验证集，另外两份当训练集，这件事情要重复 3 次。即第一份第 2 份当训练，第 3 份当验证；第一份第 3 份当训练，第 2 份当验证；第一份当验证，第 2 份第 3 份当训练</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_7490bb6b430d460ca345df01aae6ba22.png" alt="在这里插入图片描述"></p><h3 id="不匹配"><a href="#不匹配" class="headerlink" title="不匹配"></a>不匹配</h3><p>反常的情况。这种情况应该算是另外一种错误的形式，这种错误的形式称为不匹配（mismatch）</p><p><img src="/img/downloaded/aHR0cHM6_1afc40b560d74bc99a4a5bc881d075ea.png" alt="在这里插入图片描述"></p><blockquote><p>不匹配跟过拟合其实不同，一般的过拟合可以用搜集更多的数据来克服，但是<strong>不匹配是指训练集跟测试集的分布不同，训练集再增加其实也没有帮助了</strong>。</p></blockquote><blockquote><p>增加数据也不能让模型做得更好，所以这种问题要怎么解决，<strong>匹不匹配要看对数据本身的理解了，我们可能要对训练集跟测试集的产生方式有一些理解，才能判断它是不是遇到了不匹配的情况</strong></p></blockquote><p><img src="/img/downloaded/aHR0cHM6_86d38b681e1a42ba93e6d7dddc1247d9.png" alt="在这里插入图片描述"></p><h1 id="🚩学习目标"><a href="#🚩学习目标" class="headerlink" title="🚩学习目标"></a>🚩学习目标</h1><ul><li><input checked="" disabled="" type="checkbox"> Task 1.1 《深度学习详解》3.1 局部极小值与鞍点</li><li><input checked="" disabled="" type="checkbox"> Task 1.2 《深度学习详解》3.2 批量和动量</li><li><input checked="" disabled="" type="checkbox"> Task 2.1 《深度学习详解》3.3&amp;4&amp;5 自适应学习率</li><li><input checked="" disabled="" type="checkbox"> Task 2.2 《深度学习详解》3.6 分类</li><li><input checked="" disabled="" type="checkbox"> Task 2.3 （实践任务）：HW3(CNN)</li><li><input checked="" disabled="" type="checkbox"> Task 3.1 《深度学习详解》3.7 批量归一化</li><li><input checked="" disabled="" type="checkbox"> Task 3.2 《深度学习详解》4.1&amp;2&amp;3&amp;4 卷积神经网络-上</li><li><input checked="" disabled="" type="checkbox"> Task 3.3 《深度学习详解》3.5&amp;6&amp;7&amp;8 卷积神经网络-下</li><li><input checked="" disabled="" type="checkbox"> （选修）《深度学习详解》6.1&amp;2 自注意力机制的原理</li></ul><hr><h1 id="🚩学习内容"><a href="#🚩学习内容" class="headerlink" title="🚩学习内容"></a>🚩学习内容</h1><blockquote><p>欢迎去大家各大电商平台选购纸质版苹果书《深度学习详解》<br>基于上述书籍拓展</p></blockquote><blockquote><p>引用内容为书本原话 图片基本上来源于书中<br>我以自问自答的方式输出内容</p></blockquote><hr><h1 id="🚩-Task1-1"><a href="#🚩-Task1-1" class="headerlink" title="🚩 Task1.1"></a>🚩 Task1.1</h1><hr><h2 id="🎯为什么优化会失败"><a href="#🎯为什么优化会失败" class="headerlink" title="🎯为什么优化会失败"></a>🎯为什么优化会失败</h2><blockquote><p>收敛在局部极限值与鞍点会导致优化失败。</p></blockquote><p>隐藏任务①：搜索资料，找到一个优化失败的案例，尝试用自己的话描述一遍情况~<br><a href="https://www.jiqizhixin.com/articles/2018-11-07-4">深度学习并非万能，遇到这些问题会失败 | 机器之心</a></p><h3 id="📌因非信息梯度导致的失败"><a href="#📌因非信息梯度导致的失败" class="headerlink" title="📌因非信息梯度导致的失败"></a>📌因非信息梯度导致的失败</h3><p>原因：如果梯度中的信息很少，使用它来进行学习就无法成功。<br>例如，研究者从学习随机奇偶校验的简单问题开始，在大约d&#x3D;30这个程度之后，经过合理时间后也没有观察到优于随机的表现。<br>研究者使用两个定理对此进行了详细的分析，得出了结论：<strong>基于梯度的方法确实不能学会随机奇偶校验和线性周期函数。</strong> 此外，不管我们使用哪一类预测算法，只要使用了基于梯度的方法来进行训练，这个结果都成立。</p><h2 id="🎯局部极小值与鞍点"><a href="#🎯局部极小值与鞍点" class="headerlink" title="🎯局部极小值与鞍点"></a>🎯局部极小值与鞍点</h2><blockquote><p>我们在做优化的时候经常会发现，随着参数不断更新，训练的损失不会再下降, 但是我们对这个损失仍然不满意。’</p></blockquote><p>达到了临界点</p><h2 id="🎯临界点及其种类"><a href="#🎯临界点及其种类" class="headerlink" title="🎯临界点及其种类"></a>🎯临界点及其种类</h2><blockquote><p>过去常见的一个猜想是我们优化到某个地方，这个地方参数对损失的微分为零，如图 3.1所示。图 3.1 中的两条曲线对应两个神经网络训练的过程。当参数对损失微分为零的时候，梯度下降就不能再更新参数了，训练就停下来了，损失不再下降了。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_35ef82053d4743e1bf98cd23406436ba.png" alt="在这里插入图片描述"></p><blockquote><p>提到梯度为零的时候，大家最先想到的可能就是<strong>局部极小值（local minimum）</strong><br>所以经常<strong>有人说，做深度学习时使用梯度下降会收敛在局部极小值，梯度下降不起作用。</strong> 但其实损失不是只在局部极小值的梯度是零，还有其他可能会让梯度是零的点，比如<strong>鞍点（saddle point）</strong> 。<strong>鞍点其实就是梯度是零且区别于局部极小值和局部极大值</strong>（localmaximum）的点。图 3.2b 红色的点在 y 轴方向是比较高的，在 x 轴方向是比较低的，这就是一个鞍点。<strong>鞍点的叫法是因为其形状像马鞍。</strong> <strong>鞍点的梯度为零，但它不是局部极小值。</strong> <strong>我们把梯度为零的点统称为临界点（critical point）。</strong> 损失没有办法再下降，也许是<strong>因为收敛在了临界点，但不一定收敛在局部极小值，因为鞍点也是梯度为零的点。</strong><br><img src="/img/downloaded/aHR0cHM6_52b5824047c6400a9b58abe8a2bb880f.png" alt="在这里插入图片描述"><br>局部较小值点和鞍点都会使得梯度为零，所以梯度为零的点，临界点不一定是局部极小值。</p></blockquote><h2 id="🎯如何判断临界值种类"><a href="#🎯如何判断临界值种类" class="headerlink" title="🎯如何判断临界值种类"></a>🎯如何判断临界值种类</h2><blockquote><p>判断一个临界点到底是局部极小值还是鞍点需要知道损失函数的形状。<br>虽然无法完整知道整个损失函数的样子，但是如果给定某一组参数，比如$θ^{‘}$，$θ^{‘}$ 附近的 $L(θ)$ 可近似为</p></blockquote><p>$$<br>L(θ) ≈  L(θ^{‘})+(θ − θ^{′})^T*g +\frac{1}{2}(θ − θ^{′})^T * H(θ − θ^{′}) .  (3.1)<br>$$</p><p>式 (3.1) 是<strong>泰勒级数近似（Tayler series appoximation）。</strong> 其中，第一项 $L(θ)$′ 告诉我们，当 θ 跟 $θ^{′}$很近的时候，$L(θ)$ 应该跟还蛮靠近的；第二项$(θ − θ^{′})^T*g$中，g 代表梯度，它是一个向量，可以弥补$L(θ^{′})$跟 $L(θ)$ 之间的差距。有时候梯度 g 会写成 $∇L(θ^{′})$。$g_i$是向量 g 的第 i 个元素，就是 L 关于 θ 的第 i 个元素的微分，即<br>$$<br>g_i &#x3D;\frac{∂L(θ^{′})}{∂θ_i}.(3.2)<br>$$</p><blockquote><p>光看 g 还是没有办法完整地描述 ，还要看式 (3.1) 的第三项$\frac{1}{2}(θ − θ^{′})^T * H(θ − θ^{′})$。第三项跟<strong>海森矩阵（Hessian matrix）H 有关</strong> 。<br>H 里面放的是 L 的二次微分，它第 i 行，第 j 列的值 $H_{ij}$ 就是把 θ 的第 i 个元素对$L(θ^{′})$作微分，再把 θ 的第 j 个元素对$\frac{∂L(θ^{′})}{∂θ_i}$作微分后的结果，即</p></blockquote><p>$$<br>H_{ij}   &#x3D;\frac{∂^2L(θ^{′})}{∂θ_i∂θ_j}. (3.3)<br>$$</p><blockquote><p>在临界点，梯度 g 为零，因此 θ − θ′Tg 为零。所以在临界点的附近，损失函数可被近似为<br>$$<br>L(θ) ≈  L(θ^{‘}) +\frac{1}{2}(θ − θ^{′})^T * H(θ − θ^{′}) .  (3.1)<br>$$</p></blockquote><blockquote><p>我们可以根据$\frac{1}{2}(θ − θ^{′})^T * H(θ − θ^{′})$来判断在 $θ^{′}$附近的<strong>误差表面（error surface）</strong> 到底长什么样子。<br><strong>知道误差表面的“地貌”，我们就可以判断 L(θ′) 是局部极小值、局部极大值，还是鞍点。</strong></p></blockquote><p>上述我们通过一系列的转化把损失函数近似的写了出来，可以根据误差表面来判断临界点。</p><blockquote><p><strong>我们用向量 v 来表示$θ − θ^{′} ,(θ − θ^{′})^T * H(θ − θ^{′})$可改写为 $v^TH_v$，有如下三种情况。</strong></p><ol><li><strong>如果对所有 v，$v^TH_v&gt; 0$ .</strong>  这意味着对任意 θ，L(θ) &gt; L(θ′). 只要 θ 在 θ′ 附近，L(θ) 都大于 L(θ′). 这代表 L(θ′) 是附近的一个最低点，所以<strong>它是局部极小值。</strong></li><li><strong>如果对所有 v，$v^TH_v&lt; 0$ .</strong>  这意味着对任意 θ，L(θ) &lt; L(θ′)，θ′ 是附近最高的一个点，<strong>L(θ′) 是局部极大值。</strong></li><li><strong>如果对于 v， $v^TH_v$ 有时候大于零，有时候小于零。</strong> 这意味着在 θ′ 附近，有时候L(θ) &gt; L(θ′)，有时候 L(θ) &lt; L(θ′). 因此在 θ′ 附近，L(θ′) 既不是局部极大值，也不是局部极小值，而 <strong>是鞍点。</strong></li></ol></blockquote><h3 id="📌更简便的方法来判断-v-TH-v-的正负。"><a href="#📌更简便的方法来判断-v-TH-v-的正负。" class="headerlink" title="📌更简便的方法来判断 $v^TH_v$  的正负。"></a>📌更简便的方法来判断 $v^TH_v$  的正负。</h3><blockquote><p>只要看 H的特征值。</p><ol><li>若 H 的<strong>所有特征值都是正的</strong>，<strong>H 为正定矩阵</strong>，则  $v^TH_v$ &gt; 0，临界点是<strong>局部极小值</strong>。</li><li>若 H 的<strong>所有特征值都是负的</strong>，<strong>H 为负定矩阵</strong>，则 $v^TH_v$ &lt; 0，临界点是<strong>局部极大值</strong>。</li><li><strong>若 H 的特征值有正有负，临界点是鞍点</strong>。<br><img src="/img/downloaded/aHR0cHM6_8e582332ef78410f83fd1d6825802032.png" alt="在这里插入图片描述"></li></ol></blockquote><h2 id="🎯H-怎么告诉我们怎么更新参数呢？"><a href="#🎯H-怎么告诉我们怎么更新参数呢？" class="headerlink" title="🎯H 怎么告诉我们怎么更新参数呢？"></a>🎯H 怎么告诉我们怎么更新参数呢？</h2><blockquote><p>设 λ 为 H 的一个特征值 λ，u 为其对应的特征向量。对于我们的优化问题，可令 $u &#x3D;θ − θ^{′}$，则</p></blockquote><p>$$<br>u^{T}Hu &#x3D; uT(λu) &#x3D; λ∥u∥^{2}.<br>$$</p><blockquote><p>若 λ &lt; 0，则 $λ∥u∥^{2}$ &lt; 0。所以$\frac{1}{2}(θ − θ^{′})^T * H(θ − θ^{′})$ &lt; 0。此时，L(θ) &lt; L(θ′)，且<strong>沿着 u 的方向更新 θ，损失就会变小。</strong></p></blockquote><blockquote><p>只要 θ &#x3D; θ′ + u，沿着特征向量 u 的方向去更新参数，损失就会变小，所以虽然临界点的梯度为零，<strong>如果我们是在一个鞍点，只要找出负的特征值，再找出这个特征值对应的特征向量。将其与 θ′ 相加，就可以找到一个损失更低的点。</strong><br>我们其实只要顺着 u 的方向去更新参数，就可以找到一个比鞍点的损失还要更低的点。</p></blockquote><h2 id="🎯如何逃离鞍点"><a href="#🎯如何逃离鞍点" class="headerlink" title="🎯如何逃离鞍点"></a>🎯如何逃离鞍点</h2><blockquote><p>我们常常会遇到两种情况：损失仍然很高，却遇到了临界点而不再下降；或者损失降得很低，才遇到临界点。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_1c71d013f49d436083c869373473fda0.png" alt="在这里插入图片描述"></p><blockquote><p>在图 3.6 所示的例子中，最小值比例（&#x3D;正特征值数量&#x2F;总特征值数量）最大也不过处于 0.5 ~ 0.6 的范围，代表只有约一半的特征值为正，另一半的特征值为负，代表<strong>在所有的维度里面有约一半的路可以让损失上升，还有约一半的路可以让损失下降。</strong></p></blockquote><p><img src="/img/downloaded/aHR0cHM6_29c52681af40426f93b8fb5ec0bb0247.png" alt="在这里插入图片描述"></p><blockquote><p>所以从经验上看起来，<strong>局部极小值并没有那么常见。</strong> 多数的时候，我们训练到一个梯度很小的地方，参数不再更新，往往只是遇到了鞍点。</p></blockquote><h1 id="🚩-Task1-2"><a href="#🚩-Task1-2" class="headerlink" title="🚩 Task1.2"></a>🚩 Task1.2</h1><h2 id="🎯什么是批量和动量"><a href="#🎯什么是批量和动量" class="headerlink" title="🎯什么是批量和动量"></a>🎯什么是批量和动量</h2><blockquote><p>实际计算梯度的过程中，我们将数据分成多个<strong>批次（batch）</strong>，每个批次大小为B，即包含B个数据样本。</p></blockquote><blockquote><p>每次更新参数时，从批次中选取数据计算损失和梯度，并更新参数。完成一次遍历所有批次的过程称为一个<strong>回合（epoch</strong>）。</p></blockquote><blockquote><p>为了增加样本的随机性，我们会在划分批次时进行<strong>随机打乱（shuffle）</strong>。常见的一种做法是在每个回合开始之前重新划分批次，使得每个回合的批次数据都不同。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_982c143a836e48d0a7e1310cbdbaff35.png" alt="在这里插入图片描述"></p><h3 id="📌批量大小对梯度下降法的影响"><a href="#📌批量大小对梯度下降法的影响" class="headerlink" title="📌批量大小对梯度下降法的影响"></a>📌批量大小对梯度下降法的影响</h3><p><img src="/img/downloaded/aHR0cHM6_06be32fe4ce44e66a0d63deb0705b6ba.png" alt="在这里插入图片描述"></p><h4 id="🔧批量梯度下降法（Batch-Gradient-Descent，BGD）"><a href="#🔧批量梯度下降法（Batch-Gradient-Descent，BGD）" class="headerlink" title="🔧批量梯度下降法（Batch Gradient Descent，BGD）"></a>🔧批量梯度下降法（Batch Gradient Descent，BGD）</h4><blockquote><p>使用<strong>全批量（fullbatch）的数据</strong>来更新参数的方法即<strong>批量梯度下降法（Batch Gradient Descent，BGD）。</strong><br> 此时模型必须把 20 笔训练数据都看完，才能够计算损失和梯度，参数才能够更新一次。</p></blockquote><h4 id="🔧随机梯度下降法（Stochastic-Gradient-Descent，SGD），也称为增量梯度下降法"><a href="#🔧随机梯度下降法（Stochastic-Gradient-Descent，SGD），也称为增量梯度下降法" class="headerlink" title="🔧随机梯度下降法（Stochastic Gradient Descent，SGD），也称为增量梯度下降法"></a>🔧随机梯度下降法（Stochastic Gradient Descent，SGD），也称为增量梯度下降法</h4><blockquote><p>批量大小等于 1，此时使用的方法即<strong>随机梯度下降法（Stochastic Gradient Descent，SGD）</strong>，也称为增量梯度下降法。<br><strong>批量大小等于 1 意味着只要取出一笔数据即可计算损失、更新一次参数。</strong><br>如果总共有 20 笔数据，那么在每一个回合里面，参数会更新 20 次。<br>用一笔数据算出来的损失相对带有更多噪声，因此其更新的方向如图 3.8 所示，是曲曲折折的 。</p></blockquote><h4 id="🔧批量大小与计算时间的关系"><a href="#🔧批量大小与计算时间的关系" class="headerlink" title="🔧批量大小与计算时间的关系"></a>🔧批量大小与计算时间的关系</h4><p><img src="/img/downloaded/aHR0cHM6_1c45a418839e463e84f4651712ba1f76.png" alt="在这里插入图片描述"></p><blockquote><p>当批量大小增加到10000，甚至增加到 60000 的时候，<strong>GPU 计算梯度并更新参数所耗费的时间确实随着批量大小的增加而逐渐增长。</strong></p></blockquote><blockquote><p><strong>大的批量更新比较稳定，小的批量的梯度的方向是比较有噪声的（noisy）。</strong></p></blockquote><p><img src="/img/downloaded/aHR0cHM6_0386e7bf7a154d88b97fa1f46538b301.png" alt="在这里插入图片描述"></p><blockquote><p><strong>同一个模型，大的批量大小往往在训练的时候，结果比较差。</strong> 这个是优化的问题，大的批量大小优化可能会有问题，<strong>小的批量大小优化的结果反而是比较好的。</strong></p></blockquote><p><img src="/img/downloaded/aHR0cHM6_9a027bea6224408b9569218a4f427438.png" alt="在这里插入图片描述"></p><blockquote><p>一个可能的解释如图 3.12 所示，批量梯度下降在更新参数的时候，沿着一个损失函数来更新参数，走到一个局部最小值或鞍点显然就停下来了。<br><strong>梯度是零，如果不看海森矩阵，梯度下降就无法再更新参数了 。</strong><br><strong>但小批量梯度下降法（mini-batch gradient descent）每次是挑一个批量计算损失，所以每一次更新参数的时候所使用的损失函数是有差异的。</strong><br>这种有噪声的更新方式反而对训练其实是有帮助的。其实小的批量也对测试有帮助。</p></blockquote><p>在模型训练的适合小批量梯度下降法的噪声反而使得梯度不容易落在临界点，而且更方便测试。</p><blockquote><p>大的批量跟小的批量的<strong>训练准确率（accuracy）</strong> 差不多，但就算是在训练的时候结果差不多，<strong>测试的时候，大的批量比小的批量差，代表过拟合。</strong></p></blockquote><p><img src="/img/downloaded/aHR0cHM6_8e0ea637d131424d9101ed3b357a8d80.png" alt="在这里插入图片描述"></p><blockquote><p><strong>大的批量大小会让我们倾向于走到“峡谷”里面，而小的批量大小倾向于让我们走到“盆地”里面。</strong> 小的批量有很多的损失，其更新方向比较随机，其每次更新的方向都不太一样。即使“峡谷”非常窄，它也可以跳出去，之后如果有一个非常宽的“盆地”，它才会停下来。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_9394eb62905742258e088a7c91f3650e.jpeg" alt="在这里插入图片描述"></p><blockquote><p>而小的批量更新的方向比较有噪声的，大的批量更新的方向比较稳定。但是有噪声的更新方向反而在优化的时候有优势，而且在测试的时候也会有优势。<br><strong>所以大的批量跟小的批量各有优缺点，批量大小是需要去调整的超参数。</strong></p></blockquote><h2 id="🎯什么是动量法"><a href="#🎯什么是动量法" class="headerlink" title="🎯什么是动量法"></a>🎯什么是动量法</h2><blockquote><p><strong>动量法（momentum method）是另外一个可以对抗鞍点或局部最小值的方法。</strong></p><p><img src="/img/downloaded/aHR0cHM6_bd3fa1b6cffc471bb731b04959f956d3.png" alt="在这里插入图片描述"></p></blockquote><blockquote><p>但是在物理的世界里，一个球如果从高处滚下来，就算滚到鞍点或鞍点，<strong>因为惯性</strong>的关系它还是会继续往前走。因此在物理的世界里面，一个球从高处滚下来的时候，它<strong>并不一定会被鞍点或局部最小值卡住，如果将其应用到梯度下降中，这就是动量。</strong></p></blockquote><h3 id="📌对比一般的梯度下降法和动量法"><a href="#📌对比一般的梯度下降法和动量法" class="headerlink" title="📌对比一般的梯度下降法和动量法"></a>📌对比一般的梯度下降法和动量法</h3><p><img src="/img/downloaded/aHR0cHM6_054bf06823ff4f3bad71c455e70d05e8.png" alt="在这里插入图片描述"></p><p><img src="/img/downloaded/aHR0cHM6_bca48a45e8f34bbe8514b794c6920a66.png" alt="在这里插入图片描述"></p><blockquote><p>引入动量后，每次在移动参数的时候，不是只往梯度的反方向来移动参数，而是<strong>根据梯度的反方向加上前一步移动的方向决定移动方向。</strong></p></blockquote><blockquote><p><strong>图 3.16 中红色虚线方向是梯度的反方向，蓝色虚线方向是前一次更新的方向，蓝色实线的方向是下一步要移动的方向。</strong> 把前一步指示的方向跟梯度指示的方向相加就是下一步的移动方向。</p></blockquote><p>动量法引入了动量的概念，通过累积之前的梯度信息来加速学习过程。<strong>动量法在更新参数时不仅考虑当前的梯度，还考虑了之前累积的梯度。</strong></p><h4 id="🔧动量法的主要优点"><a href="#🔧动量法的主要优点" class="headerlink" title="🔧动量法的主要优点"></a>🔧动量法的主要优点</h4><p>可以加速收敛速度，特别是在目标函数存在高度非均向性的情况下。<br>可以帮助跳出局部最小值，并具有一定的平滑效果。</p><h4 id="🔧动量法也存在一些缺点。"><a href="#🔧动量法也存在一些缺点。" class="headerlink" title="🔧动量法也存在一些缺点。"></a>🔧动量法也存在一些缺点。</h4><p>动量法引入了额外的超参数，需要人工调整。<br>如果动量系数设置过大，可能会导致震荡；如果设置过小，则可能会导致收敛速度变慢。</p><p><img src="/img/downloaded/aHR0cHM6_9f10f439e6a745eaafd49a3d5a497733.png" alt="在这里插入图片描述"></p><blockquote><p>动量的简单例子如图 3.17 所示。<strong>红色表示负梯度方向，蓝色虚线表示前一步的方向，蓝色实线表示真实的移动量。</strong> 一开始没有前一次更新的方向，完全按照梯度给指示往右移动参数。负梯度方向跟前一步移动的方向加起来，得到往右走的方向。一般梯度下降走到一个局部最小值或鞍点时，就被困住了。但有动量还是有办法继续走下去，因为动量不是只看梯度，还看前一步的方向。<strong>即使梯度方向往左走，但如果前一步的影响力比梯度要大，球还是有可能继续往右走</strong>，甚至翻过一个小丘，也许可以走到更好的局部最小值，这就是动量有可能带来的好处 。</p></blockquote><h1 id="🚩Task-2-1"><a href="#🚩Task-2-1" class="headerlink" title="🚩Task 2.1"></a>🚩Task 2.1</h1><h2 id="🎯什么是自适应学习率"><a href="#🎯什么是自适应学习率" class="headerlink" title="🎯什么是自适应学习率"></a>🎯什么是自适应学习率</h2><blockquote><p>临界点其实不一定是在训练一个网络的时候会遇到的最大的障碍。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_aa4761d1b98d42ebb39ed5783aacdcd6.png" alt="在这里插入图片描述"></p><blockquote><p>图 3.18中的横坐标代表<strong>参数更新的次数</strong>，竖坐标表示<strong>损失</strong>。</p></blockquote><blockquote><p><strong>一般在训练一个网络的时候，损失原来很大，随着参数不断的更新，损失会越来越小，最后就卡住了，损失不再下降。</strong></p></blockquote><p>到临界点损失不在下降。<br><img src="/img/downloaded/aHR0cHM6_81e4b491f7894b1badc43ab7b400c33a.png" alt="在这里插入图片描述"></p><blockquote><p>我们走到临界点的时候，意味着梯度非常小，但损失不再下降的时候，梯度并没有真的变得很小，图 3.19 给出了示例。</p></blockquote><blockquote><p>图 3.19 中横轴是<strong>迭代次数</strong>，竖轴是梯度的<strong>范数（norm）</strong>，即梯度这个向量的长度。<br><strong>随着迭代次数增多，虽然损失不再下降，但是梯度的范数并没有真的变得很小。</strong></p></blockquote><p>范数（norm）是 梯度这个向量的长度。<br><img src="/img/downloaded/aHR0cHM6_38d2774cb82042c3ba68617320ef6b9c.png" alt="在这里插入图片描述"></p><blockquote><p>图 3.20是误差表面，梯度在山谷的两个谷壁间，不断地<strong>来回“震荡”</strong>，这个时候<strong>损失不会再下降</strong>，它不是真的卡到了临界点，<strong>卡到了鞍点或局部最小值</strong>。<br>在局部最小值或鞍点，只是单纯的损失无法再下降。<br><strong>但它的梯度仍然很大，只是损失不一定再减小了</strong>。</p></blockquote><blockquote><p>我们可以试着把学习率设小一点</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_cb3681446a064d39946a9916f168da96.png" alt="在这里插入图片描述"></p><blockquote><p>调学习率从 10−2 调到 10−7 的结果如图 3.22(b)所示，参数不再“震荡”了。<strong>参数会滑到山谷底后左转，但是这个训练永远走不到终点，因为学习率已经太小了</strong>。</p></blockquote><blockquote><p>AB段的坡度很陡，梯度的值很大，还能够前进一点。左拐以后，BC 段的坡度已经非常平坦了，这种小的学习率无法再让训练前进。<br>事实上在 BC 段有 10 万个点（10 万次更新），但都<strong>无法靠近局部最小值</strong>，所以<strong>显然就算是一个凸的误差表面，梯度下降也很难训练</strong>。</p></blockquote><blockquote><p>在梯度下降里面，所有的参数都是设同样的学习率，这显然是不够的，应该要为每一个参数定制化学习率，即引入<strong>自适应学习率（adaptive learning rate）</strong> 的方法，给每一个参数不同的学习率。</p></blockquote><h2 id="🎯AdaGrad"><a href="#🎯AdaGrad" class="headerlink" title="🎯AdaGrad"></a>🎯AdaGrad</h2><blockquote><p><strong>AdaGrad（Adaptive Gradient）</strong> 是<strong>典型的自适应学习率方法</strong>，其能够根据梯度大小自动调整学习率。 <strong>AdaGrad可以做到梯度比较大的时候，学习率就减小，梯度比较小的时候，学习率就放大</strong>。</p></blockquote><h3 id="📌参数更新和学习率调整"><a href="#📌参数更新和学习率调整" class="headerlink" title="📌参数更新和学习率调整"></a>📌参数更新和学习率调整</h3><h4 id="🔧基本参数更新公式"><a href="#🔧基本参数更新公式" class="headerlink" title="🔧基本参数更新公式"></a>🔧基本参数更新公式</h4><p>在第$t$个迭代中，参数$\theta^i$的更新公式为：<br>$$<br>  \theta_{t+1}^i \leftarrow \theta_t^i \eta g_t^i \quad (3.14)<br>$$<br>  其中$g_t^i$是在$\theta &#x3D; \theta_t$时，参数$\theta^i$对损失$L$的微分。</p><h4 id="🔧梯度计算"><a href="#🔧梯度计算" class="headerlink" title="🔧梯度计算"></a>🔧梯度计算</h4><p>梯度$g_t^i$的计算公式为：<br>$$<br>  g_t^i &#x3D; \left.\frac{\partial L}{\partial \theta^i}\right|_{\theta&#x3D;\theta_t} \quad (3.15)<br>$$</p><h4 id="🔧定制化学习率"><a href="#🔧定制化学习率" class="headerlink" title="🔧定制化学习率"></a>🔧定制化学习率</h4><p>将学习率$\eta$调整为参数相关的学习率$\frac{\eta}{\sigma_t^i}$：<br>$$<br>  \theta_{t+1}^i \leftarrow \theta_t^i \frac{\eta}{\sigma_t^i} g_t^i \quad (3.16)<br>$$<br>  其中$\sigma_t^i$与参数$i$和迭代$t$相关。</p><h4 id="🔧梯度的均方根"><a href="#🔧梯度的均方根" class="headerlink" title="🔧梯度的均方根"></a>🔧梯度的均方根</h4><p>参数的更新过程，其中$\sigma_0^i$的计算为：<br>$$<br>  \sigma_0^i &#x3D; \sqrt{\left(g_0^i\right)^2} &#x3D; \left|g_0^i\right| \quad (3.18)<br>$$</p><h4 id="🔧参数更新的迭代过程"><a href="#🔧参数更新的迭代过程" class="headerlink" title="🔧参数更新的迭代过程"></a>🔧参数更新的迭代过程</h4><p>第二次参数更新：<br>$$<br>  \theta_2^i \leftarrow \theta_1^i \frac{\eta}{\sigma_1^i} g_1^i \quad (3.19)<br>$$<br>  其中$\sigma_1^i$是过去所有计算出来的梯度的平方的平均再开根号。</p><h4 id="🔧迭代更新公式"><a href="#🔧迭代更新公式" class="headerlink" title="🔧迭代更新公式"></a>🔧迭代更新公式</h4><p>第$t+1$次更新参数的公式为：<br>$$<br>  \theta_{t+1}^i \leftarrow \theta_t^i \frac{\eta}{\sigma_t^i} g_t^i \quad \sigma_t^i &#x3D; \sqrt{\frac{1}{t+1}\sum_{i&#x3D;0}^t\left(g_t^i\right)^2} \quad (3.22)<br>$$</p><h4 id="🔧参数更新的动态调整"><a href="#🔧参数更新的动态调整" class="headerlink" title="🔧参数更新的动态调整"></a>🔧参数更新的动态调整</h4><p>根据梯度的不同，每一个参数的梯度的不同，自动调整学习率的大小，使得参数更新更加有效。</p><h4 id="🔧参数更新的可视化"><a href="#🔧参数更新的可视化" class="headerlink" title="🔧参数更新的可视化"></a>🔧参数更新的可视化</h4><p>图 3.24 展示了两个参数$\theta^1$和$\theta^2$的更新情况，其中$\theta^1$坡度小，$\theta^2$坡度大。根据公式 (3.22)，<strong>不同的梯度大小导致不同的学习率调整，从而影响参数更新的步伐。</strong></p><p><img src="/img/downloaded/aHR0cHM6_e0c9ce493ab549ab873ca72f7375cde3.png" alt="在这里插入图片描述"></p><h3 id="📌AdaGrad算法的问题"><a href="#📌AdaGrad算法的问题" class="headerlink" title="📌AdaGrad算法的问题"></a>📌AdaGrad算法的问题</h3><p><img src="/img/downloaded/aHR0cHM6_b46b6b35f6024fd3a7d77c46487347e9.png" alt="在这里插入图片描述"><br><strong>当模型接近最优点时，由于在某些方向上梯度非常小，AdaGrad算法会导致学习率变得非常大，从而可能出现“爆炸”现象，使得模型突然偏离最优路径</strong>。累积的 $\sigma_t^i$值<strong>在梯度较小的方向上会变得非常大，导致学习步伐过大。</strong></p><h2 id="🎯RMSProp"><a href="#🎯RMSProp" class="headerlink" title="🎯RMSProp"></a>🎯RMSProp</h2><p><strong>RMSprop 是一种自适应学习率的优化算法</strong>，由 Geoffrey Hinton 在 Coursera 深度学习课程中提出。</p><h3 id="📌算法的步骤"><a href="#📌算法的步骤" class="headerlink" title="📌算法的步骤"></a>📌算法的步骤</h3><h4 id="🔧初始梯度的均方根"><a href="#🔧初始梯度的均方根" class="headerlink" title="🔧初始梯度的均方根"></a>🔧初始梯度的均方根</h4><p>RMSprop 的第一步与 Adagrad 相同，<strong>计算初始梯度的绝对值作为均方根</strong>：<br>$$<br>  \sigma_0^i &#x3D; \sqrt{\left(g_0^i\right)^2} &#x3D; \left|g_0^i\right| \quad (3.23)<br>$$</p><h3 id="📌参数更新公式"><a href="#📌参数更新公式" class="headerlink" title="📌参数更新公式"></a>📌参数更新公式</h3><p>第二次更新参数的公式，<strong>引入超参数 $\alpha$来调整梯度的重要性</strong>：<br>$$<br>  \theta_2^i \leftarrow \theta_1^i \frac{\eta}{\sigma_1^i} g_1^i \quad \sigma_1^i &#x3D; \sqrt{\alpha \left(\sigma_0^i\right)^2 + (1-\alpha) \left(g_1^i\right)^2} \quad (3.24)<br>$$<br>  其中 $0 &lt; \alpha &lt; 1$。</p><h4 id="🔧迭代更新过程"><a href="#🔧迭代更新过程" class="headerlink" title="🔧迭代更新过程"></a>🔧迭代更新过程</h4><p>后续的参数更新过程，<strong>通过递归方式计算 $\sigma_t^i$来动态调整学习率</strong>：<br>$$<br>  \begin{aligned}<br>  \theta_3^i &amp;\leftarrow \theta_2^i \frac{\eta}{\sigma_2^i} g_2^i \quad \sigma_2^i &#x3D; \sqrt{\alpha \left(\sigma_1^i\right)^2 + (1-\alpha) \left(g_2^i\right)^2} \<br>  \vdots \<br>  \theta_{t+1}^i &amp;\leftarrow \theta_t^i \frac{\eta}{\sigma_t^i} g_t^i \quad \sigma_t^i &#x3D; \sqrt{\alpha \left(\sigma_{t-1}^i\right)^2 + (1-\alpha) \left(g_t^i\right)^2}<br>  \end{aligned}<br>$$<br><img src="/img/downloaded/aHR0cHM6_cf67b006a5fc42629d9e68e9ac35cc37.png" alt="在这里插入图片描述"></p><h3 id="📌算法特性"><a href="#📌算法特性" class="headerlink" title="📌算法特性"></a>📌算法特性</h3><p>RMSprop <strong>通过超参数 $\alpha$来决定当前梯度 $g_t^i$相较于之前梯度</strong>的重要性。<strong>这使得算法能够快速响应梯度的变化，实现更灵活的参数更新。</strong><br>在误差表面的不同区域，例如从 A 到 B 的平坦区域，<strong>RMSprop 允许较大的学习步伐</strong>；而在 B 到 C 的陡峭区域，通过增加 $\alpha$值，可以<strong>快速减小学习步伐，实现“踩刹车”的效果。</strong></p><p><img src="/img/downloaded/aHR0cHM6_3f693ea3ebba414e83fcc79cd5d7df59.png" alt="在这里插入图片描述"></p><h2 id="🎯Adam"><a href="#🎯Adam" class="headerlink" title="🎯Adam"></a>🎯Adam</h2><blockquote><p><strong>最常用的优化的策略或者优化器（optimizer） 是Adam（Adaptive moment estimation）</strong> 。<br>Adam 可以看作 <strong>RMSprop 加上动量</strong>，其使用动量作为参数更新方向，并且能够自适应调整学习率。PyTorch 里面已经写好了 Adam 优化器。</p></blockquote><h2 id="🎯学习率调度"><a href="#🎯学习率调度" class="headerlink" title="🎯学习率调度"></a>🎯学习率调度</h2><p>学习率调度是一种策略，它使得学习率 $\eta$<strong>随着时间或训练的迭代次数逐渐减小</strong>。<strong>学习率衰减（learning rate decay）或学习率退火（learning rate annealing）是学习率调度中的一种常见策略</strong>。</p><h3 id="📌学习率衰减"><a href="#📌学习率衰减" class="headerlink" title="📌学习率衰减"></a>📌学习率衰减</h3><p>通过引入学习率衰减，可以<strong>避免在训练后期由于学习率过大导致的不稳定现象</strong>。学习率调度<strong>允许模型在训练初期快速收敛，在训练后期则通过减小学习率，使模型能够稳定地接近最优点</strong>。<br><img src="/img/downloaded/aHR0cHM6_1a64095d74924d7bb04096c9235d4a6b.png" alt="在这里插入图片描述"></p><h3 id="📌学习率调度的公式"><a href="#📌学习率调度的公式" class="headerlink" title="📌学习率调度的公式"></a>📌学习率调度的公式</h3><p>引入学习率调度后的参数更新公式为：<br>$$<br>\theta_{t+1}^i \leftarrow \theta_t^i \frac{\eta_t}{\sigma_t^i} g_t^i \quad (3.26)<br>$$<br>其中 $\eta_t$是随时间变化的学习率。</p><h3 id="📌预热"><a href="#📌预热" class="headerlink" title="📌预热"></a>📌预热</h3><blockquote><p>除了学习率下降以外，还有另外一个经典的学习率调度的方式———预热。</p></blockquote><blockquote><p><strong>预热的方法是让学习率先变大后变小</strong>，至于变到多大、变大的速度、变小的速度是超参数。<br>除了残差网络， <strong>BERT 和 Transformer 的训练也都使用了预<br>热</strong>。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_0c1596cc34d14a77833076d2db96d869.png" alt="在这里插入图片描述"></p><h3 id="📌RAdam"><a href="#📌RAdam" class="headerlink" title="📌RAdam"></a>📌RAdam</h3><blockquote><p>RAdam的应用场景非常广泛，<strong>尤其适用于那些对学习率预热敏感的模型和任务</strong>。<br>RAdam 是 Ranger 优化器的重要组成部分。Ranger 优化器结合了 RAdam 和 LookAhead，在深度学习中表现出色，能够提升模型的能力和收敛速度。</p></blockquote><h4 id="🔧无需预热"><a href="#🔧无需预热" class="headerlink" title="🔧无需预热"></a>🔧无需预热</h4><p>RAdam 无需预热，就能避免模型收敛至“局部最优解”。 </p><h4 id="🔧优于手动预热"><a href="#🔧优于手动预热" class="headerlink" title="🔧优于手动预热"></a>🔧优于手动预热</h4><p>RAdam 自动提供方差缩减，在各种预热长度和各种学习率下都优于传统的手动预热调整。 </p><h4 id="🔧RAdam与Adam性能对比"><a href="#🔧RAdam与Adam性能对比" class="headerlink" title="🔧RAdam与Adam性能对比"></a>🔧RAdam与Adam性能对比</h4><table><thead><tr><th>性能指标</th><th>RAdam</th><th>Adam</th></tr></thead><tbody><tr><td>收敛速度</td><td>有望为几乎所有 AI 应用提供更好的收敛速度。</td><td>在前期的表现一般不好，前期数据少，很难总结出一个靠谱的初始动量，也更容易陷入局部最优，所以一般需要几个 batch 的预热阶段让自适应动量更靠谱。</td></tr><tr><td>训练稳定性</td><td>对不同的学习速度具有鲁棒性，同时仍具有更好的训练稳定性（对选择的学习率不那么敏感）。</td><td>在没有预热的情况下使用时，在初始迭代期间，梯度具有较大的方差。这种较大的差异会导致最小值的过冲，从而导致较差的最优值。</td></tr><tr><td>准确性和泛化性</td><td>可立即提高 AI 准确度和泛化性。</td><td>存在很多问题，效果甚至没有简单的 SGD+Momentum 好。</td></tr><tr><td>以下是对您提供的文件内容的总结，使用Markdown格式：</td><td></td><td></td></tr></tbody></table><hr><h2 id="🎯学习率调度与优化器变形"><a href="#🎯学习率调度与优化器变形" class="headerlink" title="🎯学习率调度与优化器变形"></a>🎯学习率调度与优化器变形</h2><h3 id="📌动量与均方根的计算差异"><a href="#📌动量与均方根的计算差异" class="headerlink" title="📌动量与均方根的计算差异"></a>📌动量与均方根的计算差异</h3><p><strong>动量 $m_{t}^{i}$</strong>：<strong>考虑了过去所有梯度的方向和大小，通过将所有梯度直接相加来计算</strong>，因此保留了梯度的方向信息。<br><strong>均方根 $\sigma_{t}^{i}$</strong>：仅考虑了梯度的大小，<strong>通过计算梯度的平方和的平方根来得出，忽略了梯度的方向</strong>。</p><p>尽管 $m_{t}^{i}$ 和 $\sigma_{t}^{i}$ 都使用了过去所有的梯度，但由于<strong>计算方式的不同，它们并不会相互抵消</strong>。</p><h3 id="📌优化总结"><a href="#📌优化总结" class="headerlink" title="📌优化总结"></a>📌优化总结</h3><p>从最基本的梯度下降法演化至包含动量的优化版本，如式(3.27)所示：<br>  $$<br>  \theta_{t+1}^i \leftarrow \theta_t^i \frac{\eta_t}{\sigma_t^i} m_t^i \qquad (3.27)<br>  $$<br>  其中，$m_t^i$ 表示动量。</p><p>动量 $m_t^i$ 不仅考虑了某一时刻的梯度方向，而是<strong>对所有梯度方向进行了加权总和，作为参数更新的方向</strong>。<br><strong>更新步伐的大小</strong>由 $\frac{m_t^i}{\sigma_t^i}$ 决定。</p><h1 id="🚩Task-2-2"><a href="#🚩Task-2-2" class="headerlink" title="🚩Task 2.2"></a>🚩Task 2.2</h1><h2 id="🎯什么是分类"><a href="#🎯什么是分类" class="headerlink" title="🎯什么是分类"></a>🎯什么是分类</h2><blockquote><p><strong>分类与回归是深度学习最常见的两种问题</strong></p></blockquote><h2 id="🎯回归与分类的区别和联系"><a href="#🎯回归与分类的区别和联系" class="headerlink" title="🎯回归与分类的区别和联系"></a>🎯回归与分类的区别和联系</h2><blockquote><p>回归是输入一个向量 x，输出 yˆ，我们希望 yˆ 跟某一个标签 y 越接近越好， y 是要学习的目标。而分类可当作回归来看，输入 x 后，输出仍然是一个标量 yˆ，要让它跟正确答案的那个类越接近越好。 </p></blockquote><h3 id="📌回归"><a href="#📌回归" class="headerlink" title="📌回归"></a>📌回归</h3><p>回归任务涉及输入一个向量 $x$ 并预测一个连续值 $y$。<br>目标是使得预测值 $y$ 尽可能接近真实标签值。</p><h3 id="📌分类"><a href="#📌分类" class="headerlink" title="📌分类"></a>📌分类</h3><p>分类可以视为一种特殊的回归问题，其中输入 $x$ 后，输出是一个标量 $y$。<br>目的是让输出 $y$ 与正确类别的编号尽可能接近。</p><h2 id="🎯使用数字表示类别会出现的问题"><a href="#🎯使用数字表示类别会出现的问题" class="headerlink" title="🎯使用数字表示类别会出现的问题"></a>🎯使用数字表示类别会出现的问题</h2><pre><code>引出独热编码</code></pre><p><strong>直接使用数字来表示类别可能会导致问题，尤其是当类别之间存在某种关系时。</strong></p><blockquote><p>例如，根据身高和体重预测年级时，一年级和二年级在逻辑上比一年级和三年级更接近。</p></blockquote><h2 id="🎯什么是独热编码（One-Hot-Encoding）"><a href="#🎯什么是独热编码（One-Hot-Encoding）" class="headerlink" title="🎯什么是独热编码（One-Hot Encoding）"></a>🎯什么是独热编码（One-Hot Encoding）</h2><p><strong>当类别之间没有固有的顺序或数值关系时，使用独热编码来表示类别是一种常见做法。</strong><br>独热编码通过<strong>为每个类别分配一个唯一的二进制向量，避免了类别之间不恰当的数值关系。</strong><br><strong>在分类问题中尤其有用，因为它允许模型更准确地学习类别之间的关系。</strong></p><p><img src="/img/downloaded/aHR0cHM6_d14bc7f21bd8480684b1cbeba4820441.png" alt="在这里插入图片描述"></p><blockquote><p>图3.30展示了如何使用数字和独热编码来表示类别。类别编号（如1、2、3）可能暗示它们之间的某种关系，而独热编码则不包含这样的预设关系。</p></blockquote><blockquote><p><strong>如果用独热向量计算距离的话，类两两之间的距离都是一样的</strong><br>以下是对您提供的文件内容的总结：</p></blockquote><h3 id="📌多输出神经网络结构"><a href="#📌多输出神经网络结构" class="headerlink" title="📌多输出神经网络结构"></a>📌多输出神经网络结构</h3><p><img src="/img/downloaded/aHR0cHM6_6cd73e45d00c42f5b842704208c7e90a.png" alt="在这里插入图片描述"></p><p><strong>计算 $\hat{y}_1$</strong>:<br>将输入特征 $x_1$ 与权重相乘，加上偏置，得到 $a_1$。<br>将 $a_1$ 与另一组权重相乘，加上偏置，得到 $\hat{y}_1$。</p><p><strong>计算 $\hat{y}_2$</strong>:<br>将输入特征 $x_2$ 与权重相乘，加上偏置，得到 $a_2$。<br>将 $a_2$ 与另一组权重相乘，加上偏置，得到 $\hat{y}_2$。</p><p> <strong>计算 $\hat{y}_3$</strong>:<br>将输入特征 $x_3$ 与权重相乘，加上偏置，得到 $a_3$。<br> 将 $a_3$ 与另一组权重相乘，加上偏置，得到 $\hat{y}_3$。</p><p>每个输出 $\hat{y}$ 是通过对输入特征的不同线性组合并加上偏置来计算的。使得这些输出 $\hat{y}_1, \hat{y}_2, \hat{y}_3$ 尽可能接近它们各自的目标值。<br><strong>偏置使得这些输出尽可能接近它们的目标值，以实现最佳的预测性能。</strong></p><h2 id="🎯带有-softmax-的分类"><a href="#🎯带有-softmax-的分类" class="headerlink" title="🎯带有 softmax 的分类"></a>🎯带有 softmax 的分类</h2><blockquote><p>按照上述的设定，分类实际过程是：输入 x，乘上 W，加上 b，通过激活函数 σ，乘上W ′，再加上 b′ 得到向量 yˆ。<br>但实际做分类的时候，往往会把 yˆ 通过 softmax 函数得到 y′，才去计算 y′ 跟 yˆ 之间的距离。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_58a16b2b20d04e2ca70e7dbe121410e0.png" alt="在这里插入图片描述"></p><h3 id="📌为什么分类过程中要加上softmax函数"><a href="#📌为什么分类过程中要加上softmax函数" class="headerlink" title="📌为什么分类过程中要加上softmax函数"></a>📌为什么分类过程中要加上softmax函数</h3><p><img src="/img/downloaded/aHR0cHM6_d0aaab477265406899e7be95004fd606.png" alt="在这里插入图片描述"></p><blockquote><p>softmax 的计算如式 (3.28) 所示，先把所有的 y 取一个指数（负数取指数后也会变成正的），再对其做归一化（除掉所有 y 的指数值的和）得到 y′。</p></blockquote><h3 id="📌Softmax-函数及其特性"><a href="#📌Softmax-函数及其特性" class="headerlink" title="📌Softmax 函数及其特性"></a>📌Softmax 函数及其特性</h3><p><img src="/img/downloaded/aHR0cHM6_0d75ef9509af4272b2626f83b1d5379a.png" alt="在这里插入图片描述"><br>在考虑三个类别的情况下，Softmax 函数的应用(图3.33）</p><p><strong>Softmax 函数</strong> 用于将一个向量或一组实数转换成另一个向量，其中转换后的向量元素值在 0 到 1 之间，并且所有元素的和为 1。<br>公式为：<br>  $$<br>  y_i^{\prime} &#x3D; \frac{\exp\left(y_i\right)}{\sum_j \exp\left(y_i\right)} \qquad (3.28)<br>  $$<br>  其中$y_i$ 是输入向量中的第$i$ 个元素，$y_i^{\prime}$ 是输出向量中的第$i$ 个元素。</p><h4 id="🔧特性"><a href="#🔧特性" class="headerlink" title="🔧特性"></a>🔧特性</h4><ol><li><strong>Softmax 函数除了进行归一化，使得输出值在 0 到 1 之间并总和为 1 之外，还有将大数值与小数值的差距进一步拉大的效果</strong>。</li><li>输出值$y_i^{\prime}$ 满足$1 &gt; y_i^{\prime} &gt; 0$，并且所有输出值之和为 1。</li></ol><h3 id="📌Sigmoid-函数与-Softmax-函数的比较"><a href="#📌Sigmoid-函数与-Softmax-函数的比较" class="headerlink" title="📌Sigmoid 函数与 Softmax 函数的比较"></a>📌Sigmoid 函数与 Softmax 函数的比较</h3><h4 id="🔧两分类问题"><a href="#🔧两分类问题" class="headerlink" title="🔧两分类问题"></a>🔧两分类问题</h4><p>在处理两个类别的问题时，通常直接使用 <strong>Sigmoid 函数</strong> 而不是 Softmax。<br><strong>当只有两个类别时，Sigmoid 函数和 Softmax 函数是等价的</strong>。</p><h4 id="🔧多分类问题"><a href="#🔧多分类问题" class="headerlink" title="🔧多分类问题"></a>🔧多分类问题</h4><p><strong>在涉及三个或更多类别的情况下，Softmax 函数是首选</strong>，因为它可以处理多类别的输出，并保证输出值的总和为 1。</p><h2 id="🎯什么是分类损失"><a href="#🎯什么是分类损失" class="headerlink" title="🎯什么是分类损失"></a>🎯什么是分类损失</h2><h3 id="📌损失函数"><a href="#📌损失函数" class="headerlink" title="📌损失函数"></a>📌损失函数</h3><p>在分类问题中，损失函数用于衡量模型预测值$y’$ 与实际标签$y$ 之间的差异。</p><h3 id="📌均方误差-MSE"><a href="#📌均方误差-MSE" class="headerlink" title="📌均方误差 (MSE)"></a>📌均方误差 (MSE)</h3><p><strong>公式</strong>：<br>  $$<br>  e &#x3D; \sum_i \left(y_i y_i’\right)^2 \quad (3.29)<br>  $$<br><strong>计算预测值与实际值之间差的平方和。</strong></p><h3 id="📌交叉熵-Cross-Entropy"><a href="#📌交叉熵-Cross-Entropy" class="headerlink" title="📌交叉熵 (Cross-Entropy)"></a>📌交叉熵 (Cross-Entropy)</h3><p><strong>公式</strong>：<br>  $$<br>  e &#x3D; -\sum_i y_i \ln y_i’ \quad (3.30)<br>  $$<br><strong>衡量实际标签与通过 softmax 转换后的预测值之间的差异。</strong></p><p><strong>优点</strong>：当预测值与实际值相同时，交叉熵最小化，此时均方误差也最小。</p><h3 id="📌使用-softmax-的好处"><a href="#📌使用-softmax-的好处" class="headerlink" title="📌使用 softmax 的好处"></a>📌使用 softmax 的好处</h3><blockquote><p>如图 3.35 所示，有一个三类的分类，网络先输出 y1、 y2 和 y3，在通过 softmax 以后，产生 y1′ 、 y2′ 和 y3′ 。<br>假设正确答案是 [1, 0, 0]T，要计算 [1, 0, 0]T 跟 y1′ 、 y2′ 和 y3′ 之间的距离 e， e 可以是均方误差或交叉熵。<br>假设 y1 的变化是从-10 到 10， y2 的变化也是从-10 到 10， y3 就固定设成-1000。因为 y3 的值很小，通过 softmax 以后， y3′ 非常趋近于 0，它跟正确答案非常接近，且它对结果影响很少。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_139ec3c735a6474886cc99d4e3e1ff4e.png" alt="在这里插入图片描述"><br>Softmax 将网络输出转换为概率分布，使得每个类别的预测值在 0 到 1 之间，并且总和为 1。</p><h2 id="🎯损失函数的选择对优化的影响"><a href="#🎯损失函数的选择对优化的影响" class="headerlink" title="🎯损失函数的选择对优化的影响"></a>🎯损失函数的选择对优化的影响</h2><h3 id="📌交叉熵"><a href="#📌交叉熵" class="headerlink" title="📌交叉熵"></a>📌交叉熵</h3><ol><li><strong>优点</strong>：在分类问题中，交叉熵比均方误差更常用，因为它在优化过程中表现更好，尤其是在参数初始化远离最优值时。</li><li><strong>优化难度</strong>：使用交叉熵时，即使在损失较大的区域，梯度仍然存在，使得模型可以通过梯度下降法有效地优化。</li></ol><h3 id="📌均方误差"><a href="#📌均方误差" class="headerlink" title="📌均方误差"></a>📌均方误差</h3><ol><li><strong>缺点</strong>：在损失较大的区域，均方误差可能导致梯度非常小，使得梯度下降法难以优化。</li><li><strong>优化难度</strong>：如果没有好的优化器，使用均方误差可能导致模型训练困难。</li></ol><p><img src="/img/downloaded/aHR0cHM6_92f0eeeb07fc45e8a578459dfd39832f.png" alt="在这里插入图片描述"></p><p>图3.35比较了均方误差和交叉熵在损失表面上的差异，以及它们对优化过程的影响。</p><h3 id="📌总结"><a href="#📌总结" class="headerlink" title="📌总结"></a>📌总结</h3><ol><li>在分类问题中，交叉熵是首选的损失函数，因为它在优化过程中提供了更好的梯度信息。</li><li>均方误差可能在某些情况下导致优化困难，尤其是在模型初始化远离最优值时。</li><li>选择合适的损失函数对模型的训练效果和优化效率至关重要。</li></ol><h1 id="🚩Task-2-3"><a href="#🚩Task-2-3" class="headerlink" title="🚩Task 2.3"></a>🚩Task 2.3</h1><blockquote><p>（实践任务）：HW3(CNN)</p></blockquote><h2 id="🎯一键运行Notebook"><a href="#🎯一键运行Notebook" class="headerlink" title="🎯一键运行Notebook"></a>🎯一键运行Notebook</h2><blockquote><p>通过在卷积神经网络（CNN）模型的验证集上实现t-SNE（t分布随机邻域嵌入），可视化学习到的视觉表示，包括顶层和中间层的输出。<br>绘制特定类别的t-SNE可视化图</p></blockquote><h2 id="🎯实验结果"><a href="#🎯实验结果" class="headerlink" title="🎯实验结果"></a>🎯实验结果</h2><p><img src="/img/downloaded/aHR0cHM6_e380b21460ef4d5f9276a6d7432384bb.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_4986163e25cd4ae79d05633b94d84b39.png" alt="在这里插入图片描述"></p><h1 id="🚩-Task-3-1"><a href="#🚩-Task-3-1" class="headerlink" title="🚩 Task 3.1"></a>🚩 Task 3.1</h1><h2 id="🎯批量归一化（Batch-Normalization，-BN）"><a href="#🎯批量归一化（Batch-Normalization，-BN）" class="headerlink" title="🎯批量归一化（Batch Normalization， BN）"></a>🎯批量归一化（Batch Normalization， BN）</h2><p><strong>直接改误差表面的地貌，“把山铲平”，让它变得比较好训练</strong></p><blockquote><p><strong>一个“把山铲平”的想法</strong>。</p></blockquote><blockquote><p>不要小看优化这个问题，有时候就算误差表面是凸（convex）的，它就是一个碗的形状，都不一定很好训练。如图 3.37 所示，假设两个参数对损失的斜率差别非常大，在 w1 这个方向上面，斜率变化很小，在 w2 这个方向上面斜率变化很大。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_6b26886c33f5437da7d9e462d028a26c.png" alt="在这里插入图片描述"></p><h2 id="🎯学习率和误差表面优化"><a href="#🎯学习率和误差表面优化" class="headerlink" title="🎯学习率和误差表面优化"></a>🎯学习率和误差表面优化</h2><p>在机器学习模型训练中，<strong>固定的学习率可能导致难以获得理想的结果。为了解决这一问题，引入了自适应学习率和高级优化算法</strong>，如Adam，这些方法能够更好地调整学习率，从而优化训练过程。</p><h3 id="📌误差表面分析"><a href="#📌误差表面分析" class="headerlink" title="📌误差表面分析"></a>📌误差表面分析</h3><p><strong>误差表面可能因为参数$w_1$和$w_2$的斜率差异而变得难以优化。</strong><br><strong>通过修改误差表面，尝试使其更易于优化。</strong></p><h3 id="📌线性模型示例"><a href="#📌线性模型示例" class="headerlink" title="📌线性模型示例"></a>📌线性模型示例</h3><p>考虑一个简单的线性模型，输入为$x_1$和$x_2$，参数为$w_1$和$w_2$。<br>模型输出$\hat{y}$计算为$\hat{y} &#x3D; w_1 \cdot x_1 + w_2 \cdot x_2 + b$。<br>损失函数$L$定义为所有训练数据误差$e$的总和，即$L &#x3D; \sum e$，其中$e &#x3D; \hat{y} y$。</p><h2 id="🎯特征归一化的重要性"><a href="#🎯特征归一化的重要性" class="headerlink" title="🎯特征归一化的重要性"></a>🎯特征归一化的重要性</h2><p>在训练模型时，<strong>如果输入特征的数值范围差异很大，可能会导致难以训练的误差表面</strong>。为了解决这个问题，<strong>引入了特征归一化技术，如Z值归一化（也称为标准化），它有助于使误差表面更加平滑，从而优化训练过程</strong>。</p><h3 id="📌Z值归一化（标准化）"><a href="#📌Z值归一化（标准化）" class="headerlink" title="📌Z值归一化（标准化）"></a>📌Z值归一化（标准化）</h3><p>归一化处理通过计算每个特征维度的平均值$m_i$和标准差$\sigma_i$，然后应用以下公式进行归一化：<br>$$\tilde{x}_i^r \leftarrow \frac{x_i^r m_i}{\sigma_i}$$<br>归一化后，特征的平均值为0，方差为1，有助于梯度下降算法更有效地收敛。</p><h2 id="🎯深度学习中的特征归一化"><a href="#🎯深度学习中的特征归一化" class="headerlink" title="🎯深度学习中的特征归一化"></a>🎯深度学习中的特征归一化</h2><p><strong>在深度学习中，即使输入特征已经归一化</strong>，<strong>中间层的特征</strong>$z$<strong>也可能需要进一步的归一化处理，以确保模型训练的稳定性和效率</strong>。</p><h3 id="📌归一化中间层特征"><a href="#📌归一化中间层特征" class="headerlink" title="📌归一化中间层特征"></a>📌归一化中间层特征</h3><p>对于中间层的特征$z$，计算其平均值$\mu$和标准差$\sigma$，然后应用以下公式进行归一化：<br>$$\mu &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N z_i$$<br>$$\sigma &#x3D; \sqrt{\frac{1}{N} \sum_{i&#x3D;1}^N (z_i - \mu)^2}$$<br>$$\tilde{z}_i &#x3D; \frac{z_i - \mu}{\sigma}$$<br>归一化可以放在激活函数之前或之后，具体取决于所使用的激活函数类型。</p><p>通过这些方法，可以有效地优化深度学习模型的训练过程，提高模型的性能和泛化能力。</p><p><img src="/img/downloaded/aHR0cHM6_505f8d8aa22c4fe39bffa4d2ec923c63.png" alt="## 考虑深度学习"><br>其中，除号代表逐元素的除，即分子分母两个向量对应元素相除。</p><p><img src="/img/downloaded/aHR0cHM6_6578751fd45d475ab9ed1a60c18b844f.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_7a4c7c98a30f4460b319e836792a4a10.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_f8acc678b366409bb4a0913923d7ff4b.png" alt="在这里插入图片描述"></p><p><img src="/img/downloaded/aHR0cHM6_e3559848a8154d44bb9bce913c587bed.png" alt="在这里插入图片描述"></p><p>如果做归一化以后， z˜ 的平均值一定是 0，如果平均值是 0 的话，这会给网络一些限制，这个限制可能会带来负面的影响，所以需要<strong>把 β, γ 加回去，让网络隐藏层的输出平均值不是 0。让网络学习 β, γ 来调整一下输出的分布，从而来调整 zˆ 的分布</strong></p><blockquote><p><strong>以上说的都是训练的部分，测试有时候又称为推断（inference）</strong>。</p></blockquote><h2 id="🎯批量归一化（Batch-Normalization）在测试阶段的应用"><a href="#🎯批量归一化（Batch-Normalization）在测试阶段的应用" class="headerlink" title="🎯批量归一化（Batch Normalization）在测试阶段的应用"></a>🎯批量归一化（Batch Normalization）在测试阶段的应用</h2><h3 id="📌使用移动平均和方差"><a href="#📌使用移动平均和方差" class="headerlink" title="📌使用移动平均和方差"></a>📌使用移动平均和方差</h3><p>在训练阶段，批量归一化通过计算每个批次的均值和方差来归一化数据。在测试阶段，<strong>利用训练期间累积的移动平均均值和方差来处理测试数据，确保模型的稳定性</strong>。</p><p><img src="/img/downloaded/aHR0cHM6_e34f524966b14ad1a4b1e4c66c216ace.png" alt="在这里插入图片描述"><br>使用训练过程中计算的移动平均均值 $\mu_{\text{moving}}$ 和方差 $\sigma^2_{\text{moving}}$ 替代批次统计量：</p><p>$$<br>\hat{x}<em>{\text{test}} &#x3D; \frac{x \mu</em>{\text{moving}}}{\sqrt{\sigma^2_{\text{moving}} + \epsilon}}<br>$$</p><p>$$<br>y_{\text{test}} &#x3D; \gamma \hat{x}_{\text{test}} + \beta<br>$$</p><p>这样，即使在<strong>测试时单个样本的分布可能与训练时的批次分布不同，模型仍然能够以一种稳定的方式进行推理</strong>。</p><h4 id="🔧不依赖批次统计"><a href="#🔧不依赖批次统计" class="headerlink" title="🔧不依赖批次统计"></a>🔧不依赖批次统计</h4><p>测试阶段不计算新的统计量，而是<strong>直接使用训练阶段得到的全局均值和方差，独立处理每个测试样本</strong>。</p><h4 id="🔧减少内部协变量偏移"><a href="#🔧减少内部协变量偏移" class="headerlink" title="🔧减少内部协变量偏移"></a>🔧减少内部协变量偏移</h4><p>批量归一化通过<strong>使用固定的全局统计量</strong>，继续在测试阶段减少网络各层激活分布的变化，从而<strong>提高模型的稳定性</strong>。</p><h4 id="🔧提高泛化能力"><a href="#🔧提高泛化能力" class="headerlink" title="🔧提高泛化能力"></a>🔧提高泛化能力</h4><p>测试阶段应用批量归一化有助于<strong>提升模型对新数据的泛化能力</strong>，<strong>减少对训练数据特定特征的过度拟合</strong>。</p><h4 id="🔧无需调整学习率"><a href="#🔧无需调整学习率" class="headerlink" title="🔧无需调整学习率"></a>🔧无需调整学习率</h4><p><strong>由于测试阶段不涉及梯度更新，因此不需要调整学习率</strong>，简化了模型的应用过程。</p><h4 id="🔧计算效率"><a href="#🔧计算效率" class="headerlink" title="🔧计算效率"></a>🔧计算效率</h4><p><strong>在测试阶段，批量归一化避免了复杂的统计计算</strong>，从而提高了推理过程的计算效率。</p><h4 id="🔧模型部署"><a href="#🔧模型部署" class="headerlink" title="🔧模型部署"></a>🔧模型部署</h4><p>批量归一化在模型部署时作为一个固定步骤，确保了模型在不同环境中的一致性和可靠性。</p><h2 id="🎯内部协变量偏移"><a href="#🎯内部协变量偏移" class="headerlink" title="🎯内部协变量偏移"></a>🎯内部协变量偏移</h2><p><strong>批量归一化最初被提出来是为了解决神经网络中的内部协变量偏移问题</strong>。这个问题说的是，网络中每一层的输入数据分布会随着前面层的参数更新而变化，这可能会让训练过程变得不太稳定。<br><strong>批量归一化通过规范化层间的输出，减少这种分布变化，帮助训练过程更稳定。</strong></p><p><img src="/img/downloaded/aHR0cHM6_31171673034c427c8dc262d4922a7356.png" alt="在这里插入图片描述"></p><h3 id="📌对优化的帮助"><a href="#📌对优化的帮助" class="headerlink" title="📌对优化的帮助"></a>📌对优化的帮助</h3><p><strong>论文《How Does Batch Normalization Help Optimization?》提出了不同的看法，质疑内部协变量偏移是否真的是训练网络的主要障碍</strong>。研究发现，<strong>即使存在内部协变量偏移，也不一定会对训练产生负面影响</strong>。实验显示，无论是否使用批量归一化，网络层输出的分布变化对训练的影响都不大，梯度方向的变化也不显著。这表明<strong>批量归一化的有效性可能并非仅仅因为它解决了内部协变量偏移</strong>。</p><h3 id="📌误差表面平滑化"><a href="#📌误差表面平滑化" class="headerlink" title="📌误差表面平滑化"></a>📌误差表面平滑化</h3><p><strong>论文还提出了另一个观点，即批量归一化可能通过改变网络的误差表面，使其变得更加平滑，从而有助于优化过程。这个观点得到了理论和实验的支持</strong>。论文还指出还有其他方法也可以使误差表面平滑化，效果可能与批量归一化相似或更好。</p><h3 id="📌归一化方法的多样性"><a href="#📌归一化方法的多样性" class="headerlink" title="📌归一化方法的多样性"></a>📌归一化方法的多样性</h3><p><strong>批量归一化不是唯一的归一化技术。实际上，存在多种归一化方法，包括批量重归一化、层归一化、实例归一化、组归一化、权重归一化和谱归一化等</strong>。可以根据具体的需求和场景选择合适的方法。</p><h1 id="🚩-Task-3-2-Task-3-3"><a href="#🚩-Task-3-2-Task-3-3" class="headerlink" title="🚩 Task 3.2 &amp;&amp; Task 3.3"></a>🚩 Task 3.2 &amp;&amp; Task 3.3</h1><blockquote><p>卷积神经网络(CNN)</p></blockquote><h2 id="🎯如何把图像输入到计算机里面"><a href="#🎯如何把图像输入到计算机里面" class="headerlink" title="🎯如何把图像输入到计算机里面"></a>🎯如何把图像输入到计算机里面</h2><blockquote><p>一张图像是一个<strong>三维的张量</strong>，其中<strong>一维代表图像的宽，另外一维代表图像的高，还有一维代表图像的通道（channel） 的数目</strong>。</p></blockquote><h2 id="🎯什么是卷积神经网络架构"><a href="#🎯什么是卷积神经网络架构" class="headerlink" title="🎯什么是卷积神经网络架构"></a>🎯什么是卷积神经网络架构</h2><blockquote><p>卷积神经网络（CNN）是一种经典的网络架构，常用于图像处理等计算机视觉任务。</p></blockquote><p><strong>通过卷积层提取图像特征，实现图像识别</strong>。</p><h2 id="🎯图像表示"><a href="#🎯图像表示" class="headerlink" title="🎯图像表示"></a>🎯图像表示</h2><p><img src="/img/downloaded/aHR0cHM6_b77708ce050146eea74588d076ce5af4.png" alt="在这里插入图片描述"></p><p><strong>图像可以被机器识别，机器通过图像识别图中的对象</strong>（如狗、飞机、汽车等）。<br><strong>彩色图像由红色、绿色、蓝色三种颜色的组合构成，每种颜色的强度不同</strong>。</p><h2 id="🎯向量化处理"><a href="#🎯向量化处理" class="headerlink" title="🎯向量化处理"></a>🎯向量化处理</h2><p>网络处理时，需要<strong>将图像的三维数据（宽度、高度、颜色通道）拉直成一维向量</strong>。<br><strong>每个像素点的颜色值被展开成一个向量，作为网络的输入</strong>。</p><h2 id="🎯标准化处理"><a href="#🎯标准化处理" class="headerlink" title="🎯标准化处理"></a>🎯标准化处理</h2><p>不同图像大小不一，通常将所有图像调整为相同大小再输入网络。<br><strong>标准化处理有助于统一网络输入，简化图像识别过程</strong>。</p><h2 id="🎯卷积层的作用"><a href="#🎯卷积层的作用" class="headerlink" title="🎯卷积层的作用"></a>🎯卷积层的作用</h2><p>卷积层通过卷积操作提取图像特征。<br><strong>卷积层的输出是特征图，特征图上的每个点代表图像中某种特征的存在概率</strong>。</p><h2 id="🎯特征图的解释"><a href="#🎯特征图的解释" class="headerlink" title="🎯特征图的解释"></a>🎯特征图的解释</h2><p>特征图上的<strong>每个点（激活值）代表网络对输入图像中特定特征的响应</strong>。<br><strong>激活值高表示相应特征在图像中出现的可能性大</strong>。</p><h2 id="🎯目标检测"><a href="#🎯目标检测" class="headerlink" title="🎯目标检测"></a>🎯目标检测</h2><p><img src="/img/downloaded/aHR0cHM6_f61051d5d2c54f8da474201771a4aba2.png" alt="在这里插入图片描述"></p><p>卷积神经网络也可用于目标检测，即<strong>识别图像中是否存在特定对象</strong>。<br><strong>通过卷积层提取的特征，可以用于判断图像中是否包含某些特定模式或对象</strong>。</p><h2 id="🎯感受野"><a href="#🎯感受野" class="headerlink" title="🎯感受野"></a>🎯感受野</h2><p>感受野是指网络中每个神经元“关心”的输入图像区域大小。<br><img src="/img/downloaded/aHR0cHM6_05ade20ce2b74995a9e1d16df8810bb9.png" alt="在这里插入图片描述"><br>卷积层的神经元只关注输入图像的一小部分区域，通过这种方式提取局部特征。</p><p> <strong>感受野是输入图像中影响特定神经元输出的局部区域。</strong></p><p> 每个神经元<strong>只关注输入图像的一个特定区域，这个区域称为它的感受野。</strong></p><h3 id="📌神经元和权重"><a href="#📌神经元和权重" class="headerlink" title="📌神经元和权重"></a>📌神经元和权重</h3><p><strong>每个神经元接收一个多维输入向量，并对每个维度赋予权重</strong>。<br>例如，一个神经元可能有 $3 \times 3 \times 3 &#x3D; 27$个权重，对应于3x3x3的输入数据。<br><img src="/img/downloaded/aHR0cHM6_c3be881dad944c0086ff8bca71937633.png" alt="在这里插入图片描述"></p><h3 id="📌偏置（Bias）"><a href="#📌偏置（Bias）" class="headerlink" title="📌偏置（Bias）"></a>📌偏置（Bias）</h3><p><strong>神经元除了权重外，还有一个偏置项，用于调整输出。</strong></p><h3 id="📌感受野的重叠"><a href="#📌感受野的重叠" class="headerlink" title="📌感受野的重叠"></a>📌感受野的重叠</h3><p><strong>不同神经元的感受野可以重叠，允许多个神经元同时响应图像中的同一个局部区域</strong>。<br>重叠的感受野有助于网络捕捉图像中的复杂特征。</p><p><img src="/img/downloaded/aHR0cHM6_42e7293167fe4f4e9f4538f5d1e65bfb.png" alt="在这里插入图片描述"></p><h3 id="📌感受野的大小和形状"><a href="#📌感受野的大小和形状" class="headerlink" title="📌感受野的大小和形状"></a>📌感受野的大小和形状</h3><p><strong>感受野的大小可以根据需要调整，不仅限于正方形，也可以是长方形或其他形状</strong>。<br>有的模式可能在小范围内就能被检测到，而有的则需要更大的范围。</p><h3 id="📌通道的选择性"><a href="#📌通道的选择性" class="headerlink" title="📌通道的选择性"></a>📌通道的选择性</h3><p><strong>感受野不仅可以覆盖所有颜色通道（如RGB），也可以只关注特定的颜色通道</strong>。<br>这允许网络对某些颜色通道中的特征更加敏感。</p><h3 id="📌设计感受野"><a href="#📌设计感受野" class="headerlink" title="📌设计感受野"></a>📌设计感受野</h3><p>设计感受野时，可以根据任务的需求和图像的特性来决定其大小、形状和覆盖的通道。<br><strong>经典的感受野安排方式会考虑如何有效地覆盖和响应图像的不同区域</strong>。</p><h2 id="🎯卷积操作"><a href="#🎯卷积操作" class="headerlink" title="🎯卷积操作"></a>🎯卷积操作</h2><p><img src="/img/downloaded/aHR0cHM6_f87e535e84e04b14928b66f91fcc9f14.png" alt="在这里插入图片描述"></p><p>卷积操作通过滑动窗口（卷积核或滤波器）在图像上移动，计算窗口内像素与卷积核值的点积。</p><h3 id="📌步幅"><a href="#📌步幅" class="headerlink" title="📌步幅"></a>📌步幅</h3><p><img src="/img/downloaded/aHR0cHM6_f8afb1ce9b574f77867b34dc192fdd68.png" alt="在这里插入图片描述"></p><blockquote><p>我们把左上角的感受野往右移一个步幅，就制造出一个新的守备范围，即新的感受野。移动的量称为步幅（stride） ，图 4.9 中的这个例子里面，步幅就等于 2。</p></blockquote><p>感受野移动的距离</p><p><strong>每次移动的步长称为步幅，步幅影响感受野的重叠程度。</strong></p><h3 id="📌填充"><a href="#📌填充" class="headerlink" title="📌填充"></a>📌填充</h3><p>为了<strong>处理图像边缘，避免卷积后图像尺寸过小，可以在图像边缘添加填充（padding）</strong>。<br><strong>填充通常使用零值，也可以使用其他策略。</strong></p><p><img src="/img/downloaded/aHR0cHM6_65f7e2df7e5d439bbaf7a72525fa52b9.png" alt="在这里插入图片描述"></p><blockquote><p>如图 4.10 所示，超出范围就做填充（padding） ，填充就是补值，一般使用零填充（zero padding），超出范围就补 0，如果感受野有一部分超出图像的范围之外，就当做那个里面的值都是 0。其实也有别的补值的方法，比如补整张图像里面所有值的平均值或者把边界的这些数字拿出来补没有值的地方。</p></blockquote><blockquote><p>而感受野加上参数共享就是卷积层（convolutional layer），用到卷积层的网络就叫卷积神经网络。</p></blockquote><h3 id="📌卷积层的参数共享"><a href="#📌卷积层的参数共享" class="headerlink" title="📌卷积层的参数共享"></a>📌卷积层的参数共享</h3><blockquote><p>如果不同的守备范围都要有一个检测鸟嘴的神经元，参数量会太多了，因此需要做出相应的简化</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_f7fb8c83c2d14467a90efd3a6ff58881.png" alt="在这里插入图片描述"></p><blockquote><p>让不同感受野的神经元共享参数，也就是做<strong>参数共享（parameter sharing）</strong>，如图 4.13 所示。所谓参数共享就是两个神经元的权重完全是一样的。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_d5b91176e5bc43e79597eea40b46dd91.png" alt="在这里插入图片描述"></p><p>卷积层的参数（卷积核）在整个图像上共享，减少模型参数数量，提高训练效率。<br>参数共享使得网络能够学习到图像中普遍存在的模式。</p><h3 id="📌全连接层（Fully-Connected-Layer）"><a href="#📌全连接层（Fully-Connected-Layer）" class="headerlink" title="📌全连接层（Fully Connected Layer）"></a>📌全连接层（Fully Connected Layer）</h3><blockquote><p>拓展</p></blockquote><p>全连接层是神经网络中的一种层，其中每个神经元都与前一层的所有神经元相连。<br><strong>全连接层主要用于整合前一层的特征，进行最终的分类或回归分析。</strong><br>它们<strong>通常位于卷积神经网络的末尾，用于处理卷积层和池化层提取的特征</strong>。</p><p><strong>全连接层广泛应用于图像识别、语音处理和自然语言处理等多种任务中。<br>它们是构建深度学习模型的关键组件之一</strong>。</p><h4 id="🔧特点"><a href="#🔧特点" class="headerlink" title="🔧特点"></a>🔧特点</h4><p><strong>在全连接层中，每个神经元对所有输入数据进行加权求和，然后通过激活函数</strong>。</p><p><strong>这些层通常包含大量的参数，因为每个输入都与每个神经元相连。</strong></p><h4 id="🔧计算过程"><a href="#🔧计算过程" class="headerlink" title="🔧计算过程"></a>🔧计算过程</h4><p>每个神经元的输出计算公式为：$$\text{output} &#x3D; \text{activation}(\text{weights} \times \text{input} + \text{bias})$$<br>其中，weights 是权重矩阵，input 是前一层的输出，bias 是偏置项，activation 是激活函数。</p><h4 id="🔧激活函数"><a href="#🔧激活函数" class="headerlink" title="🔧激活函数"></a>🔧激活函数</h4><p><strong>激活函数用于引入非线性，使网络能够学习复杂的模式。</strong><br>常用的激活函数包括 <strong>ReLU、sigmoid 和 tanh。</strong></p><h4 id="🔧训练"><a href="#🔧训练" class="headerlink" title="🔧训练"></a>🔧训练</h4><p><strong>全连接层的权重和偏置通过反向传播算法和梯度下降进行优化。</strong><br>训练过程中，网络通过调整这些参数来最小化损失函数。</p><h4 id="🔧输出"><a href="#🔧输出" class="headerlink" title="🔧输出"></a>🔧输出</h4><p><strong>在分类任务中，全连接层的输出通常是一个概率分布，表示不同类别的预测概率。<br>在回归任务中，全连接层可能只有一个输出节点，直接预测连续值。</strong></p><p><img src="/img/downloaded/aHR0cHM6_09043dd87ad44ba983a100f8a07232d7.png" alt="在这里插入图片描述"></p><h3 id="📌特征映射"><a href="#📌特征映射" class="headerlink" title="📌特征映射"></a>📌特征映射</h3><p><img src="/img/downloaded/aHR0cHM6_fb4f563f365641ec981ed5682de92c22.png" alt="在这里插入图片描述"></p><blockquote><p>如果有 64 个滤波器，就可以得到 64 组的数字。这组数字称为<strong>特征映射（feature map） 。当一张图像通过一个卷积层里面一堆滤波器的时候，就会产生一个特征映射</strong>。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_5169beb0ddfe4b61a157b23c22e69a44.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_4df27931c9eb4473ad3f2c20e5994bd3.png" alt="在这里插入图片描述"></p><h3 id="📌多卷积核"><a href="#📌多卷积核" class="headerlink" title="📌多卷积核"></a>📌多卷积核</h3><p><strong>卷积层通常包含多个卷积核，每个卷积核负责提取图像中的不同特征。</strong><br>多个卷积核的输出可以组合成新的特征图，提供更丰富的图像表示。<br><img src="/img/downloaded/aHR0cHM6_f3addfe5f8e346dfb674ef225e61882e.png" alt="在这里插入图片描述"></p><blockquote><p>如图 4.22 所示，第 2 层的卷积里面也有一堆的滤波器，每个滤波器的大小设成 3 × 3。<strong>其高度必须设为 64，因为滤波器的高度就是它要处理的图像的通道</strong>。如果输入的图像是黑白的，通道是 1，滤波器的高度就是 1。</p></blockquote><blockquote><p><strong>而共享权重其实就是用滤波器扫过一张图像，这个过程就是卷积</strong>。这就是卷积层名字的由来。把滤波器扫过图像就相当于不同的感受野神经元可以共用参数，这组共用的参数就叫做一个滤波器。</p></blockquote><h3 id="📌采样"><a href="#📌采样" class="headerlink" title="📌采样"></a>📌采样</h3><blockquote><p>把一张比较大的图像做下采样（downsampling），把图像偶数的列都拿掉，奇数的行都拿掉，图像变成为原来的 1&#x2F;4，但是不会影响里面是什么东西。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_b9534762754e4a06b55b63892a438da3.png" alt="在这里插入图片描述"></p><h3 id="📌汇聚"><a href="#📌汇聚" class="headerlink" title="📌汇聚"></a>📌汇聚</h3><blockquote><p><strong>做完卷积以后，往往后面还会搭配汇聚</strong>。汇聚就是把图像变小。做完卷积以后会得到一张图像，这张图像里面有很多的通道。做完汇聚以后，这张图像的通道不变。</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_50148c5c6437431b9e25f402d3f803b4.png" alt="在这里插入图片描述"></p><blockquote><p>图 4.27 中的例子是 2 × 2 个一组。汇聚有很多不同的版本，以最大汇聚（max pooling） 为例。<strong>最大汇聚在每一组里面选一个代表，选的代表就是最大的一个</strong>，如图 4.28 所示。<strong>除了最大汇聚，还有平均汇聚（mean pooling），平均汇聚是取每一组的平均值</strong>。</p></blockquote><p><strong>汇聚可能会对模型的性能造成一定的损害。</strong><br><strong>特别是在检测非常细微的特征时，进行下采样可能会使性能稍微降低</strong>。</p><h4 id="🔧全卷积网络的趋势"><a href="#🔧全卷积网络的趋势" class="headerlink" title="🔧全卷积网络的趋势"></a>🔧全卷积网络的趋势</h4><p>近年来，图像网络设计趋向于舍弃汇聚层，转而使用全卷积网络。全卷积网络中整个网络结构都是卷积层，不使用汇聚层，这种设计可以保持更多的空间信息，有助于特征的提取。</p><h4 id="🔧汇聚的主要作用"><a href="#🔧汇聚的主要作用" class="headerlink" title="🔧汇聚的主要作用"></a>🔧汇聚的主要作用</h4><p><strong>汇聚的主要作用是减少运算量。</strong> 通过下采样缩小图像尺寸，从而减少计算量，这在<strong>资源有限的情况下非常有用</strong>。</p><h4 id="🔧运算能力的提升"><a href="#🔧运算能力的提升" class="headerlink" title="🔧运算能力的提升"></a>🔧运算能力的提升</h4><p>随着运算能力的提升，如果有足够的运算资源，<strong>很多网络架构设计选择不使用汇聚</strong>。<strong>采用全卷积设计</strong>，从开始到结束都使用卷积层，探索是否可以取得更好的效果。</p><h4 id="🔧一般网络架构"><a href="#🔧一般网络架构" class="headerlink" title="🔧一般网络架构"></a>🔧一般网络架构</h4><p><strong>传统的网络架构通常包括卷积层和汇聚层。汇聚层是可有可无的，许多设计选择不使用汇聚层，以避免可能的性能损失。</strong></p><h4 id="🔧架构示例"><a href="#🔧架构示例" class="headerlink" title="🔧架构示例"></a>🔧架构示例</h4><p><strong>在完成卷积和汇聚后，通常将汇聚的输出扁平化，形成一维向量。然后将这个向量输入到全连接层中，最终通过 softmax 层得到图像识别的结果</strong>。<br><img src="/img/downloaded/aHR0cHM6_9917eead742f4276987292fbbe7a1862.png" alt="在这里插入图片描述"><br>这是一个经典的图像识别网络，包括卷积层、汇聚层、扁平化处理，以及全连接层或 softmax 层。</p><h2 id="🎯卷积神经网络的应用"><a href="#🎯卷积神经网络的应用" class="headerlink" title="🎯卷积神经网络的应用"></a>🎯卷积神经网络的应用</h2><p>卷积神经网络广泛应用于图像识别、目标检测等领域。<br>通过学习图像特征，卷积神经网络能够识别和分类图像中的不同对象。</p><h2 id="🎯围棋落子预测"><a href="#🎯围棋落子预测" class="headerlink" title="🎯围棋落子预测"></a>🎯围棋落子预测</h2><p>卷积神经网络也可用于围棋等策略游戏，预测下一步最佳落子位置。<br>通过分析棋盘状态，网络可以评估每个位置的重要性，指导决策。</p><h1 id="🚩自注意力机制"><a href="#🚩自注意力机制" class="headerlink" title="🚩自注意力机制"></a>🚩自注意力机制</h1><h2 id="🎯自注意力模型（Self-Attention-Model）"><a href="#🎯自注意力模型（Self-Attention-Model）" class="headerlink" title="🎯自注意力模型（Self-Attention Model）"></a>🎯自注意力模型（Self-Attention Model）</h2><blockquote><p>自注意力模型是深度学习中处理序列数据的一种重要架构，尤其适用于处理输入序列长度可变的问题。</p></blockquote><h3 id="📌输入与输出"><a href="#📌输入与输出" class="headerlink" title="📌输入与输出"></a>📌输入与输出</h3><p><img src="/img/downloaded/aHR0cHM6_9e2d9e86cb494283bff6748c3fd9494b.png" alt="在这里插入图片描述"></p><p><strong>输入通常是向量序列，输出可以是标量、类别或另一个向量序列。</strong></p><p>自注意力模型能够处理输入序列长度不一的情况，适用于文本、语音、图数据等多种序列任务。</p><h3 id="📌序列处理的挑战"><a href="#📌序列处理的挑战" class="headerlink" title="📌序列处理的挑战"></a>📌序列处理的挑战</h3><p>传统的卷积或全连接网络在处理序列数据时，可能<strong>因固定窗口大小或不考虑序列间长距离依赖而受限</strong>。</p><h3 id="📌自注意力机制"><a href="#📌自注意力机制" class="headerlink" title="📌自注意力机制"></a>📌自注意力机制</h3><p><strong>自注意力模型通过计算序列中每个元素对其他所有元素的关联程度（注意力分数），来捕捉序列内的长距离依赖关系</strong>。</p><p>模型不需要预设固定大小的窗口，能够动态地关注序列中任意距离的依赖。</p><h3 id="📌独热编码与词嵌入"><a href="#📌独热编码与词嵌入" class="headerlink" title="📌独热编码与词嵌入"></a>📌独热编码与词嵌入</h3><p><strong>独热编码是一种将词汇表示为向量的方法，但这种方法无法表达词汇之间的语义关系</strong>。</p><p><strong>词嵌入（Word Embedding）通过将词汇映射到包含语义信息的向量空间，能够更好地捕捉词汇之间的关系</strong>。</p><h3 id="📌序列到序列的任务"><a href="#📌序列到序列的任务" class="headerlink" title="📌序列到序列的任务"></a>📌序列到序列的任务</h3><p>一些任务如机器翻译，输入和输出序列的长度可能不同，自注意力模型能够灵活处理这类序列到序列的任务。</p><h3 id="📌注意力分数的计算"><a href="#📌注意力分数的计算" class="headerlink" title="📌注意力分数的计算"></a>📌注意力分数的计算</h3><p><img src="/img/downloaded/aHR0cHM6_5e66d30130d64898bd5b22a77df6763e.png" alt="在这里插入图片描述"></p><p><strong>注意力分数通过查询（Query）、键（Key）和值（Value）的机制计算得出。</strong></p><p><img src="/img/downloaded/aHR0cHM6_9846e5485ece4f7aacf74e1b9f4d264f.png" alt="在这里插入图片描述"></p><p><strong>常见的计算方法包括点积（Dot Product）和相加（Additive）等</strong>。</p><h3 id="📌多头注意力"><a href="#📌多头注意力" class="headerlink" title="📌多头注意力"></a>📌多头注意力</h3><p><strong>多头注意力（Multi-Head Attention）是自注意力的一种扩展，它将输入向量分割成多个头，每个头计算不同的注意力，最终再将结果合并，以捕获不同子空间的信息</strong>。</p><h3 id="📌Transformer-架构"><a href="#📌Transformer-架构" class="headerlink" title="📌Transformer 架构"></a>📌Transformer 架构</h3><p>Transformer 是一种<strong>完全基于自注意力机制的网络架构，广泛应用于自然语言处理任务</strong>。<br>Transformer 通过<strong>堆叠多个自注意力层和前馈神经网络层，并通过残差连接和层归一化来提高训练效率和性能</strong>。</p><h3 id="📌应用实例"><a href="#📌应用实例" class="headerlink" title="📌应用实例"></a>📌应用实例</h3><p><strong>文本处理：如情感分析、词性标注、机器翻译。<br>语音处理：如语音识别、语音合成。<br>图数据：如社交网络分析、药物分子发现。</strong></p><blockquote><p><strong>自注意力模型通过其灵活的注意力机制，为深度学习在序列数据处理方面提供了强大的工具，推动了多个领域的发展。</strong></p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>408数据结构考研大纲详解</title>
      <link href="/2025/03/10/408%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%80%83%E7%A0%94%E5%A4%A7%E7%BA%B2%E8%AF%A6%E8%A7%A3/"/>
      <url>/2025/03/10/408%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%80%83%E7%A0%94%E5%A4%A7%E7%BA%B2%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="408数据结构考研大纲详解"><a href="#408数据结构考研大纲详解" class="headerlink" title="408数据结构考研大纲详解"></a>408数据结构考研大纲详解</h1><p>本文根据计算机专业考研408数据结构大纲，系统地整理了数据结构的核心知识点，包括基本概念、线性表、栈与队列、树与二叉树、图、查找和排序等内容。每个部分都包含了定义、性质、基本操作及其算法实现、时间复杂度分析和典型应用场景，帮助考生全面掌握数据结构的重要知识点。</p><h2 id="一、绪论"><a href="#一、绪论" class="headerlink" title="一、绪论"></a>一、绪论</h2><h3 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h3><p><strong>数据结构</strong>是计算机存储、组织数据的方式。数据结构是指相互之间存在一种或多种特定关系的数据元素的集合。</p><p><strong>基本术语</strong>：</p><ul><li>数据：描述客观事物的符号，是计算机中可以操作的对象</li><li>数据元素：数据的基本单位</li><li>数据项：构成数据元素的不可分割的最小单位</li><li>数据对象：性质相同的数据元素的集合</li><li>数据类型：一组性质相同的值的集合及定义在此集合上的一组操作</li><li>抽象数据类型(ADT)：一个数学模型及定义在该模型上的一组操作</li></ul><h3 id="2-算法与算法评价"><a href="#2-算法与算法评价" class="headerlink" title="2. 算法与算法评价"></a>2. 算法与算法评价</h3><p><strong>算法</strong>是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列。</p><p><strong>算法特性</strong>：</p><ul><li>有穷性：算法必须在有限步骤内结束</li><li>确定性：每一步骤都有明确的定义</li><li>可行性：每一步都必须是可行的</li><li>输入：有零个或多个输入</li><li>输出：有一个或多个输出</li></ul><p><strong>算法评价</strong>：</p><ul><li>时间复杂度：算法执行所需的时间</li><li>空间复杂度：算法执行所需的存储空间</li></ul><p><strong>常见的时间复杂度</strong>：</p><ul><li>O(1)：常数阶</li><li>O(log n)：对数阶</li><li>O(n)：线性阶</li><li>O(n log n)：线性对数阶</li><li>O(n²)：平方阶</li><li>O(n³)：立方阶</li><li>O(2ⁿ)：指数阶</li></ul><h2 id="二、线性表"><a href="#二、线性表" class="headerlink" title="二、线性表"></a>二、线性表</h2><h3 id="1-线性表的定义与基本操作"><a href="#1-线性表的定义与基本操作" class="headerlink" title="1. 线性表的定义与基本操作"></a>1. 线性表的定义与基本操作</h3><p><strong>线性表</strong>是具有相同数据类型的n个数据元素的有限序列，其中n≥0。</p><p><strong>基本操作</strong>：</p><ul><li>InitList(&amp;L)：初始化线性表</li><li>Length(L)：返回线性表长度</li><li>LocateElem(L, e)：查找元素</li><li>GetElem(L, i)：获取指定位置的元素</li><li>ListInsert(&amp;L, i, e)：插入元素</li><li>ListDelete(&amp;L, i, &amp;e)：删除元素</li><li>PrintList(L)：输出线性表</li><li>Empty(L)：判断线性表是否为空</li><li>DestroyList(&amp;L)：销毁线性表</li></ul><h3 id="2-线性表的顺序存储"><a href="#2-线性表的顺序存储" class="headerlink" title="2. 线性表的顺序存储"></a>2. 线性表的顺序存储</h3><p><strong>顺序表</strong>是用一段地址连续的存储单元依次存储线性表的数据元素。</p><p><strong>特点</strong>：</p><ul><li>随机访问，时间复杂度O(1)</li><li>插入和删除需要移动元素，时间复杂度O(n)</li><li>存储密度高</li></ul><p><strong>基本操作实现</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 顺序表的结构定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    ElemType *elem;  <span class="comment">// 存储空间基址</span></span><br><span class="line">    <span class="type">int</span> length;      <span class="comment">// 当前长度</span></span><br><span class="line">    <span class="type">int</span> size;        <span class="comment">// 总容量</span></span><br><span class="line">&#125; SqList;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化顺序表</span></span><br><span class="line">Status <span class="title function_">InitList</span><span class="params">(SqList &amp;L)</span> &#123;</span><br><span class="line">    L.elem = new ElemType[MAXSIZE];</span><br><span class="line">    <span class="keyword">if</span> (!L.elem) <span class="keyword">return</span> ERROR;</span><br><span class="line">    L.length = <span class="number">0</span>;</span><br><span class="line">    L.size = MAXSIZE;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 插入操作</span></span><br><span class="line">Status <span class="title function_">ListInsert</span><span class="params">(SqList &amp;L, <span class="type">int</span> i, ElemType e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (i &lt; <span class="number">1</span> || i &gt; L.length + <span class="number">1</span>) <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">if</span> (L.length &gt;= L.size) <span class="keyword">return</span> ERROR;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = L.length; j &gt;= i; j--)</span><br><span class="line">        L.elem[j] = L.elem[j<span class="number">-1</span>];</span><br><span class="line">    </span><br><span class="line">    L.elem[i<span class="number">-1</span>] = e;</span><br><span class="line">    L.length++;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删除操作</span></span><br><span class="line">Status <span class="title function_">ListDelete</span><span class="params">(SqList &amp;L, <span class="type">int</span> i, ElemType &amp;e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (i &lt; <span class="number">1</span> || i &gt; L.length) <span class="keyword">return</span> ERROR;</span><br><span class="line">    </span><br><span class="line">    e = L.elem[i<span class="number">-1</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = i; j &lt; L.length; j++)</span><br><span class="line">        L.elem[j<span class="number">-1</span>] = L.elem[j];</span><br><span class="line">    </span><br><span class="line">    L.length--;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-线性表的链式存储"><a href="#3-线性表的链式存储" class="headerlink" title="3. 线性表的链式存储"></a>3. 线性表的链式存储</h3><p><strong>链表</strong>是用一组任意的存储单元存储线性表的数据元素，这组存储单元可以是连续的，也可以是不连续的。</p><p><strong>单链表</strong>：</p><ul><li>每个节点包含数据域和指针域</li><li>节点的存储地址是任意的</li><li>查找元素需要遍历，时间复杂度O(n)</li><li>插入和删除操作简单，时间复杂度O(1)（不考虑查找时间）</li></ul><p><strong>基本操作实现</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 单链表节点定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">LNode</span> &#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">LNode</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; LNode, *LinkList;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化单链表（带头结点）</span></span><br><span class="line">Status <span class="title function_">InitList</span><span class="params">(LinkList &amp;L)</span> &#123;</span><br><span class="line">    L = new LNode;</span><br><span class="line">    L-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 插入操作</span></span><br><span class="line">Status <span class="title function_">ListInsert</span><span class="params">(LinkList &amp;L, <span class="type">int</span> i, ElemType e)</span> &#123;</span><br><span class="line">    LNode *p = L;</span><br><span class="line">    <span class="type">int</span> j = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (p &amp;&amp; j &lt; i<span class="number">-1</span>) &#123;</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">        j++;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (!p || j &gt; i<span class="number">-1</span>) <span class="keyword">return</span> ERROR;</span><br><span class="line">    </span><br><span class="line">    LNode *s = new LNode;</span><br><span class="line">    s-&gt;data = e;</span><br><span class="line">    s-&gt;next = p-&gt;next;</span><br><span class="line">    p-&gt;next = s;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删除操作</span></span><br><span class="line">Status <span class="title function_">ListDelete</span><span class="params">(LinkList &amp;L, <span class="type">int</span> i, ElemType &amp;e)</span> &#123;</span><br><span class="line">    LNode *p = L;</span><br><span class="line">    <span class="type">int</span> j = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (p-&gt;next &amp;&amp; j &lt; i<span class="number">-1</span>) &#123;</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">        j++;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (!p-&gt;next || j &gt; i<span class="number">-1</span>) <span class="keyword">return</span> ERROR;</span><br><span class="line">    </span><br><span class="line">    LNode *q = p-&gt;next;</span><br><span class="line">    p-&gt;next = q-&gt;next;</span><br><span class="line">    e = q-&gt;data;</span><br><span class="line">    delete q;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>双链表</strong>：</p><ul><li>每个节点有两个指针域，分别指向前驱和后继节点</li><li>可以双向遍历</li><li>删除和插入操作更加灵活</li></ul><p><strong>循环链表</strong>：</p><ul><li>尾节点的指针指向头节点，形成一个环</li><li>可以从任意节点出发遍历整个链表</li></ul><h2 id="三、栈与队列"><a href="#三、栈与队列" class="headerlink" title="三、栈与队列"></a>三、栈与队列</h2><h3 id="1-栈"><a href="#1-栈" class="headerlink" title="1. 栈"></a>1. 栈</h3><p><strong>栈</strong>是一种只允许在一端（栈顶）进行插入和删除操作的线性表，遵循后进先出(LIFO)原则。</p><p><strong>基本操作</strong>：</p><ul><li>InitStack(&amp;S)：初始化栈</li><li>Push(&amp;S, e)：入栈</li><li>Pop(&amp;S, &amp;e)：出栈</li><li>GetTop(S, &amp;e)：获取栈顶元素</li><li>StackEmpty(S)：判断栈是否为空</li></ul><p><strong>顺序栈实现</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 顺序栈结构定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    ElemType *base;</span><br><span class="line">    ElemType *top;</span><br><span class="line">    <span class="type">int</span> stacksize;</span><br><span class="line">&#125; SqStack;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化顺序栈</span></span><br><span class="line">Status <span class="title function_">InitStack</span><span class="params">(SqStack &amp;S)</span> &#123;</span><br><span class="line">    S.base = new ElemType[MAXSIZE];</span><br><span class="line">    <span class="keyword">if</span> (!S.base) <span class="keyword">return</span> ERROR;</span><br><span class="line">    S.top = S.base;</span><br><span class="line">    S.stacksize = MAXSIZE;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 入栈操作</span></span><br><span class="line">Status <span class="title function_">Push</span><span class="params">(SqStack &amp;S, ElemType e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (S.top - S.base &gt;= S.stacksize) <span class="keyword">return</span> ERROR;</span><br><span class="line">    *S.top++ = e;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出栈操作</span></span><br><span class="line">Status <span class="title function_">Pop</span><span class="params">(SqStack &amp;S, ElemType &amp;e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (S.top == S.base) <span class="keyword">return</span> ERROR;</span><br><span class="line">    e = *--S.top;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>链栈实现</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 链栈节点定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">StackNode</span> &#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">StackNode</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; StackNode, *LinkStack;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化链栈</span></span><br><span class="line">Status <span class="title function_">InitStack</span><span class="params">(LinkStack &amp;S)</span> &#123;</span><br><span class="line">    S = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 入栈操作</span></span><br><span class="line">Status <span class="title function_">Push</span><span class="params">(LinkStack &amp;S, ElemType e)</span> &#123;</span><br><span class="line">    StackNode *p = new StackNode;</span><br><span class="line">    p-&gt;data = e;</span><br><span class="line">    p-&gt;next = S;</span><br><span class="line">    S = p;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出栈操作</span></span><br><span class="line">Status <span class="title function_">Pop</span><span class="params">(LinkStack &amp;S, ElemType &amp;e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (S == <span class="literal">NULL</span>) <span class="keyword">return</span> ERROR;</span><br><span class="line">    e = S-&gt;data;</span><br><span class="line">    StackNode *p = S;</span><br><span class="line">    S = S-&gt;next;</span><br><span class="line">    delete p;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>栈的应用</strong>：</p><ul><li>表达式求值</li><li>括号匹配</li><li>函数调用</li><li>递归实现</li><li>中缀表达式转后缀表达式</li></ul><h3 id="2-队列"><a href="#2-队列" class="headerlink" title="2. 队列"></a>2. 队列</h3><p><strong>队列</strong>是一种只允许在一端（队尾）进行插入操作，在另一端（队头）进行删除操作的线性表，遵循先进先出(FIFO)原则。</p><p><strong>基本操作</strong>：</p><ul><li>InitQueue(&amp;Q)：初始化队列</li><li>EnQueue(&amp;Q, e)：入队</li><li>DeQueue(&amp;Q, &amp;e)：出队</li><li>GetHead(Q, &amp;e)：获取队头元素</li><li>QueueEmpty(Q)：判断队列是否为空</li></ul><p><strong>循环队列实现</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 循环队列结构定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    ElemType *base;</span><br><span class="line">    <span class="type">int</span> front;</span><br><span class="line">    <span class="type">int</span> rear;</span><br><span class="line">&#125; SqQueue;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化循环队列</span></span><br><span class="line">Status <span class="title function_">InitQueue</span><span class="params">(SqQueue &amp;Q)</span> &#123;</span><br><span class="line">    Q.base = new ElemType[MAXSIZE];</span><br><span class="line">    <span class="keyword">if</span> (!Q.base) <span class="keyword">return</span> ERROR;</span><br><span class="line">    Q.front = Q.rear = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 入队操作</span></span><br><span class="line">Status <span class="title function_">EnQueue</span><span class="params">(SqQueue &amp;Q, ElemType e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> ((Q.rear + <span class="number">1</span>) % MAXSIZE == Q.front) <span class="keyword">return</span> ERROR;</span><br><span class="line">    Q.base[Q.rear] = e;</span><br><span class="line">    Q.rear = (Q.rear + <span class="number">1</span>) % MAXSIZE;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出队操作</span></span><br><span class="line">Status <span class="title function_">DeQueue</span><span class="params">(SqQueue &amp;Q, ElemType &amp;e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (Q.front == Q.rear) <span class="keyword">return</span> ERROR;</span><br><span class="line">    e = Q.base[Q.front];</span><br><span class="line">    Q.front = (Q.front + <span class="number">1</span>) % MAXSIZE;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>链队列实现</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 链队列节点定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">QNode</span> &#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">QNode</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; QNode, *QueuePtr;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 链队列结构定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    QueuePtr front;</span><br><span class="line">    QueuePtr rear;</span><br><span class="line">&#125; LinkQueue;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化链队列</span></span><br><span class="line">Status <span class="title function_">InitQueue</span><span class="params">(LinkQueue &amp;Q)</span> &#123;</span><br><span class="line">    Q.front = Q.rear = new QNode;</span><br><span class="line">    Q.front-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 入队操作</span></span><br><span class="line">Status <span class="title function_">EnQueue</span><span class="params">(LinkQueue &amp;Q, ElemType e)</span> &#123;</span><br><span class="line">    QNode *p = new QNode;</span><br><span class="line">    p-&gt;data = e;</span><br><span class="line">    p-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    Q.rear-&gt;next = p;</span><br><span class="line">    Q.rear = p;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出队操作</span></span><br><span class="line">Status <span class="title function_">DeQueue</span><span class="params">(LinkQueue &amp;Q, ElemType &amp;e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (Q.front == Q.rear) <span class="keyword">return</span> ERROR;</span><br><span class="line">    QNode *p = Q.front-&gt;next;</span><br><span class="line">    e = p-&gt;data;</span><br><span class="line">    Q.front-&gt;next = p-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (Q.rear == p) Q.rear = Q.front;</span><br><span class="line">    delete p;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>队列的应用</strong>：</p><ul><li>广度优先搜索</li><li>操作系统中的作业调度</li><li>打印机任务队列</li><li>消息缓冲区</li></ul><h2 id="四、树与二叉树"><a href="#四、树与二叉树" class="headerlink" title="四、树与二叉树"></a>四、树与二叉树</h2><h3 id="1-树的基本概念"><a href="#1-树的基本概念" class="headerlink" title="1. 树的基本概念"></a>1. 树的基本概念</h3><p><strong>树</strong>是n(n≥0)个结点的有限集合，当n&#x3D;0时称为空树，否则树满足：有且仅有一个特定的称为根的结点，其余结点可分为m(m≥0)个互不相交的有限集，每个集合本身又是一棵树，称为根的子树。</p><p><strong>基本术语</strong>：</p><ul><li>结点的度：结点拥有的子树数</li><li>树的度：树中结点的最大度数</li><li>叶子结点：度为0的结点</li><li>分支结点：度不为0的结点</li><li>结点的层次：根结点为第1层，其子结点为第2层，以此类推</li><li>树的高度：树中结点的最大层次</li><li>森林：m(m≥0)棵互不相交的树的集合</li></ul><h3 id="2-二叉树的定义与性质"><a href="#2-二叉树的定义与性质" class="headerlink" title="2. 二叉树的定义与性质"></a>2. 二叉树的定义与性质</h3><p><strong>二叉树</strong>是n(n≥0)个结点的有限集合，它或者是空集(n&#x3D;0)，或者由一个根结点及两棵互不相交的分别称为左子树和右子树的二叉树组成。</p><p><strong>二叉树的性质</strong>：</p><ul><li>第i层上至多有2^(i-1)个结点</li><li>高度为h的二叉树至多有2^h-1个结点</li><li>对任何一棵二叉树，若叶子结点数为n0，度为2的结点数为n2，则n0&#x3D;n2+1</li></ul><p><strong>满二叉树</strong>：一棵高度为h且含有2^h-1个结点的二叉树</p><p><strong>完全二叉树</strong>：一棵高度为h的二叉树，其第1层到第h-1层的结点都达到最大个数，第h层的结点都连续集中在最左边</p><h3 id="3-二叉树的存储结构"><a href="#3-二叉树的存储结构" class="headerlink" title="3. 二叉树的存储结构"></a>3. 二叉树的存储结构</h3><p><strong>顺序存储</strong>：</p><ul><li>适用于完全二叉树</li><li>按层次顺序存储</li><li>对于结点i，其左孩子为2i，右孩子为2i+1，父结点为⌊i&#x2F;2⌋</li></ul><p><strong>链式存储</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 二叉树结点定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">BiTNode</span> &#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">BiTNode</span> *<span class="title">lchild</span>, *<span class="title">rchild</span>;</span></span><br><span class="line">&#125; BiTNode, *BiTree;</span><br></pre></td></tr></table></figure><h3 id="4-二叉树的遍历"><a href="#4-二叉树的遍历" class="headerlink" title="4. 二叉树的遍历"></a>4. 二叉树的遍历</h3><p><strong>先序遍历</strong>：根-&gt;左-&gt;右</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">PreOrder</span><span class="params">(BiTree T)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (T != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        Visit(T);           <span class="comment">// 访问根结点</span></span><br><span class="line">        PreOrder(T-&gt;lchild); <span class="comment">// 先序遍历左子树</span></span><br><span class="line">        PreOrder(T-&gt;rchild); <span class="comment">// 先序遍历右子树</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>中序遍历</strong>：左-&gt;根-&gt;右</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">InOrder</span><span class="params">(BiTree T)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (T != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        InOrder(T-&gt;lchild);  <span class="comment">// 中序遍历左子树</span></span><br><span class="line">        Visit(T);            <span class="comment">// 访问根结点</span></span><br><span class="line">        InOrder(T-&gt;rchild);  <span class="comment">// 中序遍历右子树</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>后序遍历</strong>：左-&gt;右-&gt;根</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">PostOrder</span><span class="params">(BiTree T)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (T != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        PostOrder(T-&gt;lchild); <span class="comment">// 后序遍历左子树</span></span><br><span class="line">        PostOrder(T-&gt;rchild); <span class="comment">// 后序遍历右子树</span></span><br><span class="line">        Visit(T);             <span class="comment">// 访问根结点</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>层次遍历</strong>：按层次从上到下，从左到右访问所有结点</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LevelOrder</span><span class="params">(BiTree T)</span> &#123;</span><br><span class="line">    InitQueue(Q);       <span class="comment">// 初始化辅助队列</span></span><br><span class="line">    BiTree p;</span><br><span class="line">    EnQueue(Q, T);     <span class="comment">// 根结点入队</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (!QueueEmpty(Q)) &#123;</span><br><span class="line">        DeQueue(Q, p);  <span class="comment">// 队头结点出队</span></span><br><span class="line">        Visit(p);      <span class="comment">// 访问出队结点</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (p-&gt;lchild != <span class="literal">NULL</span>)</span><br><span class="line">            EnQueue(Q, p-&gt;lchild); <span class="comment">// 左子树根结点入队</span></span><br><span class="line">        <span class="keyword">if</span> (p-&gt;rchild != <span class="literal">NULL</span>)</span><br><span class="line">            EnQueue(Q, p-&gt;rchild); <span class="comment">// 右子树根结点入队</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-线索二叉树"><a href="#5-线索二叉树" class="headerlink" title="5. 线索二叉树"></a>5. 线索二叉树</h3><p><strong>线索二叉树</strong>是一种利用二叉树中空指针域的存储结构，将二叉树中的结点按某种遍历方式的前驱和后继关系记录在空指针域中。</p><p><strong>结点结构</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ThreadNode</span> &#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ThreadNode</span> *<span class="title">lchild</span>, *<span class="title">rchild</span>;</span></span><br><span class="line">    <span class="type">int</span> ltag, rtag;  <span class="comment">// 标志位，0表示指针指向孩子，1表示指针是线索</span></span><br><span class="line">&#125; ThreadNode, *ThreadTree;</span><br></pre></td></tr></table></figure><h3 id="6-树与森林"><a href="#6-树与森林" class="headerlink" title="6. 树与森林"></a>6. 树与森林</h3><p><strong>树的存储结构</strong>：</p><ul><li>双亲表示法：每个结点中保存其双亲结点的位置</li><li>孩子表示法：每个结点中保存其所有孩子结点的指针</li><li>孩子兄弟表示法：每个结点保存指向第一个孩子和下一个兄弟的指针</li></ul><p><strong>树与二叉树的转换</strong>：</p><ul><li>树转换为二叉树：每个结点的左指针指向第一个孩子，右指针指向下一个兄弟</li><li>森林转换为二叉树：先将森林中每棵树转换为二叉树，然后将每棵二叉树的根结点看作兄弟，用右指针连接</li></ul><h3 id="7-哈夫曼树与哈夫曼编码"><a href="#7-哈夫曼树与哈夫曼编码" class="headerlink" title="7. 哈夫曼树与哈夫曼编码"></a>7. 哈夫曼树与哈夫曼编码</h3><p><strong>哈夫曼树</strong>是一种带权路径长度最短的二叉树，也称为最优二叉树。</p><p><strong>构造方法</strong>：</p><ol><li>将所有结点看作独立的树，构成森林</li><li>选择森林中权值最小的两棵树，作为新树的左右子树，新树的权值为两棵子树权值之和</li><li>从森林中删除这两棵树，将新树加入森林</li><li>重复步骤2和3，直到森林中只剩一棵树</li></ol><p><strong>哈夫曼编码</strong>是一种前缀编码，用于数据压缩，具有最优性。</p><h2 id="五、图"><a href="#五、图" class="headerlink" title="五、图"></a>五、图</h2><h3 id="1-图的基本概念"><a href="#1-图的基本概念" class="headerlink" title="1. 图的基本概念"></a>1. 图的基本概念</h3><p><strong>图</strong>是由顶点集V和边集E组成的，记为G&#x3D;(V,E)，其中V是非空集合，E是V中顶点的有序对或无序对集合。</p><p><strong>基本术语</strong>：</p><ul><li>有向图：边有方向</li><li>无向图：边无方向</li><li>完全图：任意两个顶点之间都有边</li><li>连通图：任意两个顶点之间都有路径</li><li>连通分量：无向图的极大连通子图</li><li>强连通图：有向图中任意两个顶点之间都有路径</li><li>强连通分量：有向图的极大强连通子图</li><li>生成树：包含图中所有顶点的一棵树</li><li>生成森林：非连通图的生成树集合</li></ul><h3 id="2-图的存储结构"><a href="#2-图的存储结构" class="headerlink" title="2. 图的存储结构"></a>2. 图的存储结构</h3><p><strong>邻接矩阵</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    VertexType vex[MAX_VERTEX_NUM];      <span class="comment">// 顶点表</span></span><br><span class="line">    EdgeType arc[MAX_VERTEX_NUM][MAX_VERTEX_NUM]; <span class="comment">// 邻接矩阵</span></span><br><span class="line">    <span class="type">int</span> vexnum, arcnum;                  <span class="comment">// 顶点数和边数</span></span><br><span class="line">&#125; MGraph;</span><br></pre></td></tr></table></figure><p><strong>邻接表</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ArcNode</span> &#123;</span>    <span class="comment">// 边表结点</span></span><br><span class="line">    <span class="type">int</span> adjvex;             <span class="comment">// 该边所指向的顶点的位置</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ArcNode</span> *<span class="title">next</span>;</span>   <span class="comment">// 指向下一条边的指针</span></span><br><span class="line">    InfoType *info;         <span class="comment">// 边权值等信息</span></span><br><span class="line">&#125; ArcNode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">VNode</span> &#123;</span>      <span class="comment">// 顶点表结点</span></span><br><span class="line">    VertexType data;        <span class="comment">// 顶点信息</span></span><br><span class="line">    ArcNode *first;         <span class="comment">// 指向第一条依附该顶点的边的指针</span></span><br><span class="line">&#125; VNode, AdjList[MAX_VERTEX_NUM];</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    AdjList vertices;       <span class="comment">// 邻接表</span></span><br><span class="line">    <span class="type">int</span> vexnum, arcnum;     <span class="comment">// 顶点数和边数</span></span><br><span class="line">&#125; ALGraph;</span><br></pre></td></tr></table></figure><h3 id="3-图的遍历"><a href="#3-图的遍历" class="headerlink" title="3. 图的遍历"></a>3. 图的遍历</h3><p><strong>深度优先搜索(DFS)</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">DFS</span><span class="params">(Graph G, <span class="type">int</span> v)</span> &#123;</span><br><span class="line">    visited[v] = TRUE;       <span class="comment">// 标记v已访问</span></span><br><span class="line">    Visit(v);               <span class="comment">// 访问顶点v</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (w = FirstNeighbor(G, v); w &gt;= <span class="number">0</span>; w = NextNeighbor(G, v, w))</span><br><span class="line">        <span class="keyword">if</span> (!visited[w])</span><br><span class="line">            DFS(G, w);      <span class="comment">// 递归访问v的未访问邻接点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>广度优先搜索(BFS)</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">BFS</span><span class="params">(Graph G, <span class="type">int</span> v)</span> &#123;</span><br><span class="line">    visited[v] = TRUE;       <span class="comment">// 标记v已访问</span></span><br><span class="line">    Visit(v);               <span class="comment">// 访问顶点v</span></span><br><span class="line">    InitQueue(Q);           <span class="comment">// 初始化辅助队列</span></span><br><span class="line">    EnQueue(Q, v);          <span class="comment">// v入队</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (!QueueEmpty(Q)) &#123;</span><br><span class="line">        DeQueue(Q, v);       <span class="comment">// 队头元素出队</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (w = FirstNeighbor(G, v); w &gt;= <span class="number">0</span>; w = NextNeighbor(G, v, w))</span><br><span class="line">            <span class="keyword">if</span> (!visited[w]) &#123;</span><br><span class="line">                visited[w] = TRUE;</span><br><span class="line">                Visit(w);</span><br><span class="line">                EnQueue(Q, w);</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-最小生成树"><a href="#4-最小生成树" class="headerlink" title="4. 最小生成树"></a>4. 最小生成树</h3><p><strong>Prim算法</strong>：</p><ol><li>从图中任选一个顶点加入树T</li><li>在所有与树T中顶点相邻的边中，选择权值最小的边(u,v)，其中u在T中，v不在T中</li><li>将顶点v和边(u,v)加入树T</li><li>重复步骤2和3，直到所有顶点都在T中</li></ol><p><strong>Kruskal算法</strong>：</p><ol><li>将图中所有边按权值从小到大排序</li><li>从权值最小的边开始，如果该边不会与已选边构成回路，则选择该边</li><li>重复步骤2，直到选择了n-1条边（n为顶点数）</li></ol><h3 id="5-最短路径"><a href="#5-最短路径" class="headerlink" title="5. 最短路径"></a>5. 最短路径</h3><p><strong>Dijkstra算法</strong>：求单源最短路径</p><ol><li>初始化：S&#x3D;{源点s}，对所有顶点v，若v与s直接相邻，则dist[v]&#x3D;边(s,v)的权值，否则dist[v]&#x3D;∞</li><li>从未标记的顶点中选择dist值最小的顶点u，标记u</li><li>更新所有与u相邻的未标记顶点v的dist值：dist[v]&#x3D;min{dist[v], dist[u]+边(u,v)的权值}</li><li>重复步骤2和3，直到所有顶点都被标记</li></ol><p><strong>Floyd算法</strong>：求所有顶点对之间的最短路径</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">Floyd</span><span class="params">(Graph G)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; G.vexnum; i++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; G.vexnum; j++)</span><br><span class="line">            D[i][j] = G.arc[i][j];    <span class="comment">// 初始化D矩阵</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; G.vexnum; k++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; G.vexnum; i++)</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; G.vexnum; j++)</span><br><span class="line">                <span class="keyword">if</span> (D[i][j] &gt; D[i][k] + D[k][j])</span><br><span class="line">                    D[i][j] = D[i][k] + D[k][j];  <span class="comment">// 更新最短路径</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="6-拓扑排序"><a href="#6-拓扑排序" class="headerlink" title="6. 拓扑排序"></a>6. 拓扑排序</h3><p><strong>拓扑排序</strong>是将有向无环图中的顶点排成一个线性序列，使得图中任意一对顶点u和v，若存在边&lt;u,v&gt;，则u在线性序列中出现在v之前。</p><p><strong>算法步骤</strong>：</p><ol><li>从图中选择一个没有前驱的顶点并输出</li><li>从图中删除该顶点和所有以它为起点的边</li><li>重复步骤1和2，直到图为空或图中不存在无前驱的顶点</li></ol><h3 id="7-关键路径"><a href="#7-关键路径" class="headerlink" title="7. 关键路径"></a>7. 关键路径</h3><p><strong>关键路径</strong>是指在带权有向无环图中，从源点到汇点的路径中，具有最大路径长度的路径，这条路径上的活动称为关键活动。</p><p><strong>算法步骤</strong>：</p><ol><li>求各顶点的最早发生时间ve</li><li>求各顶点的最迟发生时间vl</li><li>求各活动的最早开始时间e</li><li>求各活动的最迟开始时间l</li><li>求各活动的时间余量l-e，时间余量为0的活动即为关键活动</li></ol><h2 id="六、查找"><a href="#六、查找" class="headerlink" title="六、查找"></a>六、查找</h2><h3 id="1-查找的基本概念"><a href="#1-查找的基本概念" class="headerlink" title="1. 查找的基本概念"></a>1. 查找的基本概念</h3><p><strong>查找</strong>是在数据集合中寻找满足条件的特定数据元素的过程。</p><p><strong>查找的衡量指标</strong>：</p><ul><li>平均查找长度（ASL）：需要比较的关键字次数的期望值</li></ul><h3 id="2-顺序查找"><a href="#2-顺序查找" class="headerlink" title="2. 顺序查找"></a>2. 顺序查找</h3><p><strong>顺序查找</strong>是从表的一端开始，逐个检查关键字是否匹配。</p><p><strong>算法实现</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">SeqSearch</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        <span class="keyword">if</span> (a[i] == key)</span><br><span class="line">            <span class="keyword">return</span> i;  <span class="comment">// 查找成功，返回位置</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;         <span class="comment">// 查找失败</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>平均查找长度</strong>：</p><ul><li>查找成功：(n+1)&#x2F;2</li><li>查找失败：n</li></ul><h3 id="3-二分查找"><a href="#3-二分查找" class="headerlink" title="3. 二分查找"></a>3. 二分查找</h3><p><strong>二分查找</strong>适用于有序表，每次将查找区间缩小一半。</p><p><strong>算法实现</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">BinarySearch</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">    <span class="type">int</span> low = <span class="number">0</span>, high = n - <span class="number">1</span>, mid;</span><br><span class="line">    <span class="keyword">while</span> (low &lt;= high) &#123;</span><br><span class="line">        mid = (low + high) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (a[mid] == key)</span><br><span class="line">            <span class="keyword">return</span> mid;      <span class="comment">// 查找成功</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (a[mid] &gt; key)</span><br><span class="line">            high = mid - <span class="number">1</span>;  <span class="comment">// 在左半区间查找</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            low = mid + <span class="number">1</span>;   <span class="comment">// 在右半区间查找</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;              <span class="comment">// 查找失败</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>平均查找长度</strong>：O(log₂n)</p><h3 id="4-二叉排序树"><a href="#4-二叉排序树" class="headerlink" title="4. 二叉排序树"></a>4. 二叉排序树</h3><p><strong>二叉排序树</strong>（二叉搜索树）是一种特殊的二叉树，满足以下性质：</p><ul><li>若左子树不为空，则左子树上所有结点的值均小于根结点的值</li><li>若右子树不为空，则右子树上所有结点的值均大于根结点的值</li><li>左、右子树也分别为二叉排序树</li></ul><p><strong>查找操作</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">BiTree <span class="title function_">SearchBST</span><span class="params">(BiTree T, KeyType key)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!T || key == T-&gt;data.key)</span><br><span class="line">        <span class="keyword">return</span> T;</span><br><span class="line">    <span class="keyword">if</span> (key &lt; T-&gt;data.key)</span><br><span class="line">        <span class="keyword">return</span> SearchBST(T-&gt;lchild, key);  <span class="comment">// 在左子树中查找</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> SearchBST(T-&gt;rchild, key);  <span class="comment">// 在右子树中查找</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>插入操作</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Status <span class="title function_">InsertBST</span><span class="params">(BiTree &amp;T, ElemType e)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!T) &#123;  <span class="comment">// 树为空，创建新结点</span></span><br><span class="line">        T = new BiTNode;</span><br><span class="line">        T-&gt;data = e;</span><br><span class="line">        T-&gt;lchild = T-&gt;rchild = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">return</span> TRUE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (e.key == T-&gt;data.key)  <span class="comment">// 关键字已存在</span></span><br><span class="line">        <span class="keyword">return</span> FALSE;</span><br><span class="line">    <span class="keyword">if</span> (e.key &lt; T-&gt;data.key)</span><br><span class="line">        <span class="keyword">return</span> InsertBST(T-&gt;lchild, e);  <span class="comment">// 在左子树中插入</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> InsertBST(T-&gt;rchild, e);  <span class="comment">// 在右子树中插入</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>删除操作</strong>：</p><ol><li>若被删结点是叶子结点，直接删除</li><li>若被删结点只有左子树或右子树，用子树替代被删结点</li><li>若被删结点有左右子树，用直接后继（右子树中最小的结点）或直接前驱（左子树中最大的结点）替代被删结点</li></ol><h3 id="5-平衡二叉树"><a href="#5-平衡二叉树" class="headerlink" title="5. 平衡二叉树"></a>5. 平衡二叉树</h3><p><strong>平衡二叉树</strong>（AVL树）是一种特殊的二叉排序树，任意结点的左右子树高度差不超过1。</p><p><strong>平衡因子</strong>：结点的左子树高度减去右子树高度</p><p><strong>旋转操作</strong>：</p><ul><li>LL型：右旋</li><li>RR型：左旋</li><li>LR型：先左旋后右旋</li><li>RL型：先右旋后左旋</li></ul><h3 id="6-B树和B-树"><a href="#6-B树和B-树" class="headerlink" title="6. B树和B+树"></a>6. B树和B+树</h3><p><strong>B树</strong>是一种多路平衡查找树，常用于文件系统和数据库索引。</p><p><strong>B树的性质</strong>：</p><ul><li>每个结点最多有m个子树</li><li>除根结点和叶子结点外，其他结点至少有⌈m&#x2F;2⌉个子树</li><li>所有叶子结点都在同一层</li></ul><p><strong>B+树</strong>是B树的变种，有以下特点：</p><ul><li>非叶子结点只存储索引，不存储数据</li><li>所有数据都存储在叶子结点中</li><li>叶子结点之间用指针连接，形成有序链表</li></ul><h3 id="7-散列表"><a href="#7-散列表" class="headerlink" title="7. 散列表"></a>7. 散列表</h3><p><strong>散列表</strong>（哈希表）是一种根据关键字直接访问数据的数据结构。</p><p><strong>散列函数</strong>：将关键字映射到散列表地址的函数</p><p><strong>处理冲突的方法</strong>：</p><ul><li>开放定址法：线性探测、二次探测、双散列</li><li>链地址法：将同一地址的冲突元素用链表连接</li><li>再散列法：使用另一个散列函数</li><li>建立公共溢出区</li></ul><p><strong>散列查找的平均查找长度</strong>：与装填因子α有关，α越大，平均查找长度越长</p><h2 id="七、排序"><a href="#七、排序" class="headerlink" title="七、排序"></a>七、排序</h2><h3 id="1-排序的基本概念"><a href="#1-排序的基本概念" class="headerlink" title="1. 排序的基本概念"></a>1. 排序的基本概念</h3><p><strong>排序</strong>是将一组数据按照特定的顺序重新排列的过程。</p><p><strong>排序的稳定性</strong>：相同关键字的元素在排序前后相对位置不变，则称排序算法是稳定的</p><p><strong>内部排序</strong>：数据全部存放在内存中进行排序</p><p><strong>外部排序</strong>：数据太大，无法全部放入内存，需要借助外存进行排序</p><h3 id="2-插入排序"><a href="#2-插入排序" class="headerlink" title="2. 插入排序"></a>2. 插入排序</h3><p><strong>直接插入排序</strong>：将一个元素插入到已排序的序列中的适当位置</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">InsertSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, j, temp;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (a[i] &lt; a[i<span class="number">-1</span>]) &#123;  <span class="comment">// 若第i个元素小于前一个元素</span></span><br><span class="line">            temp = a[i];      <span class="comment">// 暂存a[i]</span></span><br><span class="line">            <span class="keyword">for</span> (j = i<span class="number">-1</span>; j &gt;= <span class="number">0</span> &amp;&amp; a[j] &gt; temp; j--)</span><br><span class="line">                a[j+<span class="number">1</span>] = a[j];  <span class="comment">// 后移元素</span></span><br><span class="line">            a[j+<span class="number">1</span>] = temp;      <span class="comment">// 插入到正确位置</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：O(n²)</p><p><strong>空间复杂度</strong>：O(1)</p><p><strong>稳定性</strong>：稳定</p><p><strong>希尔排序</strong>：将序列分成若干子序列，对每个子序列进行直接插入排序</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">ShellSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, j, d, temp;</span><br><span class="line">    <span class="keyword">for</span> (d = n/<span class="number">2</span>; d &gt;= <span class="number">1</span>; d = d/<span class="number">2</span>) &#123;  <span class="comment">// 步长序列</span></span><br><span class="line">        <span class="keyword">for</span> (i = d; i &lt; n; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (a[i] &lt; a[i-d]) &#123;</span><br><span class="line">                temp = a[i];</span><br><span class="line">                <span class="keyword">for</span> (j = i-d; j &gt;= <span class="number">0</span> &amp;&amp; a[j] &gt; temp; j -= d)</span><br><span class="line">                    a[j+d] = a[j];</span><br><span class="line">                a[j+d] = temp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：与步长序列有关，平均为O(n^1.3)</p><p><strong>空间复杂度</strong>：O(1)</p><p><strong>稳定性</strong>：不稳定</p><h3 id="3-交换排序"><a href="#3-交换排序" class="headerlink" title="3. 交换排序"></a>3. 交换排序</h3><p><strong>冒泡排序</strong>：相邻元素两两比较，将最大的元素逐渐”冒”到序列的末尾</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">BubbleSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, j, temp, flag;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n<span class="number">-1</span>; i++) &#123;</span><br><span class="line">        flag = <span class="number">0</span>;  <span class="comment">// 标记本轮是否发生交换</span></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n<span class="number">-1</span>-i; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (a[j] &gt; a[j+<span class="number">1</span>]) &#123;</span><br><span class="line">                temp = a[j];</span><br><span class="line">                a[j] = a[j+<span class="number">1</span>];</span><br><span class="line">                a[j+<span class="number">1</span>] = temp;</span><br><span class="line">                flag = <span class="number">1</span>;  <span class="comment">// 发生了交换</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (flag == <span class="number">0</span>)  <span class="comment">// 如果没有发生交换，说明已经有序</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：O(n²)</p><p><strong>空间复杂度</strong>：O(1)</p><p><strong>稳定性</strong>：稳定</p><p><strong>快速排序</strong>：选择一个基准元素，将序列分为两部分，一部分小于基准，一部分大于基准</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">Partition</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> low, <span class="type">int</span> high)</span> &#123;</span><br><span class="line">    <span class="type">int</span> pivot = a[low];  <span class="comment">// 选择第一个元素作为基准</span></span><br><span class="line">    <span class="keyword">while</span> (low &lt; high) &#123;</span><br><span class="line">        <span class="keyword">while</span> (low &lt; high &amp;&amp; a[high] &gt;= pivot)</span><br><span class="line">            high--;</span><br><span class="line">        a[low] = a[high];  <span class="comment">// 将比基准小的元素移到左边</span></span><br><span class="line">        <span class="keyword">while</span> (low &lt; high &amp;&amp; a[low] &lt;= pivot)</span><br><span class="line">            low++;</span><br><span class="line">        a[high] = a[low];  <span class="comment">// 将比基准大的元素移到右边</span></span><br><span class="line">    &#125;</span><br><span class="line">    a[low] = pivot;  <span class="comment">// 基准元素放到最终位置</span></span><br><span class="line">    <span class="keyword">return</span> low;       <span class="comment">// 返回基准元素的位置</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">QuickSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> low, <span class="type">int</span> high)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (low &lt; high) &#123;</span><br><span class="line">        <span class="type">int</span> pivotpos = Partition(a, low, high);</span><br><span class="line">        QuickSort(a, low, pivotpos<span class="number">-1</span>);   <span class="comment">// 排序左子序列</span></span><br><span class="line">        QuickSort(a, pivotpos+<span class="number">1</span>, high);  <span class="comment">// 排序右子序列</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：平均O(n log n)，最坏O(n²)</p><p><strong>空间复杂度</strong>：O(log n)</p><p><strong>稳定性</strong>：不稳定</p><h3 id="4-选择排序"><a href="#4-选择排序" class="headerlink" title="4. 选择排序"></a>4. 选择排序</h3><p><strong>简单选择排序</strong>：每次从未排序序列中选择最小的元素放到已排序序列的末尾</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">SelectSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, j, min, temp;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n<span class="number">-1</span>; i++) &#123;</span><br><span class="line">        min = i;  <span class="comment">// 记录最小元素位置</span></span><br><span class="line">        <span class="keyword">for</span> (j = i+<span class="number">1</span>; j &lt; n; j++)</span><br><span class="line">            <span class="keyword">if</span> (a[j] &lt; a[min])</span><br><span class="line">                min = j;  <span class="comment">// 更新最小元素位置</span></span><br><span class="line">        <span class="keyword">if</span> (min != i) &#123;   <span class="comment">// 交换a[i]和a[min]</span></span><br><span class="line">            temp = a[i];</span><br><span class="line">            a[i] = a[min];</span><br><span class="line">            a[min] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：O(n²)</p><p><strong>空间复杂度</strong>：O(1)</p><p><strong>稳定性</strong>：不稳定</p><p><strong>堆排序</strong>：利用堆的性质进行排序</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 调整以k为根的子树为大根堆</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">HeapAdjust</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> k, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, temp = a[k];</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">2</span>*k+<span class="number">1</span>; i &lt; n; i = <span class="number">2</span>*i+<span class="number">1</span>) &#123;  <span class="comment">// i为k的左孩子</span></span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span> &lt; n &amp;&amp; a[i] &lt; a[i+<span class="number">1</span>])    <span class="comment">// 取左右孩子中较大者</span></span><br><span class="line">            i++;</span><br><span class="line">        <span class="keyword">if</span> (temp &gt;= a[i])  <span class="comment">// 根结点已是最大</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        a[k] = a[i];       <span class="comment">// 将较大的孩子上移</span></span><br><span class="line">        k = i;             <span class="comment">// 继续向下调整</span></span><br><span class="line">    &#125;</span><br><span class="line">    a[k] = temp;          <span class="comment">// 放入最终位置</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">HeapSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, temp;</span><br><span class="line">    <span class="comment">// 建立大根堆</span></span><br><span class="line">    <span class="keyword">for</span> (i = n/<span class="number">2</span><span class="number">-1</span>; i &gt;= <span class="number">0</span>; i--)</span><br><span class="line">        HeapAdjust(a, i, n);</span><br><span class="line">    <span class="comment">// 排序</span></span><br><span class="line">    <span class="keyword">for</span> (i = n<span class="number">-1</span>; i &gt; <span class="number">0</span>; i--) &#123;</span><br><span class="line">        temp = a[<span class="number">0</span>];       <span class="comment">// 堆顶元素与最后一个元素交换</span></span><br><span class="line">        a[<span class="number">0</span>] = a[i];</span><br><span class="line">        a[i] = temp;</span><br><span class="line">        HeapAdjust(a, <span class="number">0</span>, i);  <span class="comment">// 重新调整堆</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：O(n log n)</p><p><strong>空间复杂度</strong>：O(1)</p><p><strong>稳定性</strong>：不稳定</p><h3 id="5-归并排序"><a href="#5-归并排序" class="headerlink" title="5. 归并排序"></a>5. 归并排序</h3><p><strong>归并排序</strong>：将两个或多个有序序列合并成一个有序序列</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 合并两个有序序列</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Merge</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> low, <span class="type">int</span> mid, <span class="type">int</span> high)</span> &#123;</span><br><span class="line">    <span class="type">int</span> *temp = new <span class="type">int</span>[high-low+<span class="number">1</span>];  <span class="comment">// 辅助数组</span></span><br><span class="line">    <span class="type">int</span> i = low, j = mid + <span class="number">1</span>, k = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= high) &#123;  <span class="comment">// 比较两个子序列的元素</span></span><br><span class="line">        <span class="keyword">if</span> (a[i] &lt;= a[j])</span><br><span class="line">            temp[k++] = a[i++];</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            temp[k++] = a[j++];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (i &lt;= mid)   <span class="comment">// 复制剩余元素</span></span><br><span class="line">        temp[k++] = a[i++];</span><br><span class="line">    <span class="keyword">while</span> (j &lt;= high)</span><br><span class="line">        temp[k++] = a[j++];</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; k; i++)  <span class="comment">// 将temp中的元素复制回a</span></span><br><span class="line">        a[low+i] = temp[i];</span><br><span class="line">    </span><br><span class="line">    delete[] temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">MergeSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> low, <span class="type">int</span> high)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (low &lt; high) &#123;</span><br><span class="line">        <span class="type">int</span> mid = (low + high) / <span class="number">2</span>;</span><br><span class="line">        MergeSort(a, low, mid);      <span class="comment">// 排序左半部分</span></span><br><span class="line">        MergeSort(a, mid+<span class="number">1</span>, high);   <span class="comment">// 排序右半部分</span></span><br><span class="line">        Merge(a, low, mid, high);    <span class="comment">// 合并两部分</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：O(n log n)</p><p><strong>空间复杂度</strong>：O(n)</p><p><strong>稳定性</strong>：稳定</p><h3 id="6-基数排序"><a href="#6-基数排序" class="headerlink" title="6. 基数排序"></a>6. 基数排序</h3><p><strong>基数排序</strong>：按照关键字的位数进行排序，从低位到高位或从高位到低位</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">RadixSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n, <span class="type">int</span> d)</span> &#123;  <span class="comment">// d为最大位数</span></span><br><span class="line">    <span class="type">int</span> *temp = new <span class="type">int</span>[n];</span><br><span class="line">    <span class="type">int</span> *count = new <span class="type">int</span>[<span class="number">10</span>];  <span class="comment">// 计数器</span></span><br><span class="line">    <span class="type">int</span> i, j, k;</span><br><span class="line">    <span class="type">int</span> radix = <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= d; i++) &#123;  <span class="comment">// 从低位到高位</span></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; <span class="number">10</span>; j++)</span><br><span class="line">            count[j] = <span class="number">0</span>;  <span class="comment">// 计数器清零</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">            k = (a[j] / radix) % <span class="number">10</span>;  <span class="comment">// 获取当前位的数字</span></span><br><span class="line">            count[k]++;  <span class="comment">// 统计每个数字出现的次数</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">1</span>; j &lt; <span class="number">10</span>; j++)</span><br><span class="line">            count[j] += count[j<span class="number">-1</span>];  <span class="comment">// 将count转换为位置索引</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (j = n<span class="number">-1</span>; j &gt;= <span class="number">0</span>; j--) &#123;  <span class="comment">// 从后向前遍历，保证稳定性</span></span><br><span class="line">            k = (a[j] / radix) % <span class="number">10</span>;</span><br><span class="line">            temp[count[k]<span class="number">-1</span>] = a[j];  <span class="comment">// 放入对应位置</span></span><br><span class="line">            count[k]--;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">            a[j] = temp[j];  <span class="comment">// 将临时数组复制回原数组</span></span><br><span class="line">        </span><br><span class="line">        radix *= <span class="number">10</span>;  <span class="comment">// 处理下一位</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    delete[] temp;</span><br><span class="line">    delete[] count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：O(d(n+r))，其中d为位数，r为基数（这里为10）</p><p><strong>空间复杂度</strong>：O(n+r)</p><p><strong>稳定性</strong>：稳定</p><h3 id="7-各种排序算法的比较"><a href="#7-各种排序算法的比较" class="headerlink" title="7. 各种排序算法的比较"></a>7. 各种排序算法的比较</h3><table><thead><tr><th>排序算法</th><th>平均时间复杂度</th><th>最坏时间复杂度</th><th>空间复杂度</th><th>稳定性</th></tr></thead><tbody><tr><td>直接插入排序</td><td>O(n²)</td><td>O(n²)</td><td>O(1)</td><td>稳定</td></tr><tr><td>希尔排序</td><td>O(n^1.3)</td><td>O(n²)</td><td>O(1)</td><td>不稳定</td></tr><tr><td>冒泡排序</td><td>O(n²)</td><td>O(n²)</td><td>O(1)</td><td>稳定</td></tr><tr><td>快速排序</td><td>O(n log n)</td><td>O(n²)</td><td>O(log n)</td><td>不稳定</td></tr><tr><td>简单选择排序</td><td>O(n²)</td><td>O(n²)</td><td>O(1)</td><td>不稳定</td></tr><tr><td>堆排序</td><td>O(n log n)</td><td>O(n log n)</td><td>O(1)</td><td>不稳定</td></tr><tr><td>归并排序</td><td>O(n log n)</td><td>O(n log n)</td><td>O(n)</td><td>稳定</td></tr><tr><td>基数排序</td><td>O(d(n+r))</td><td>O(d(n+r))</td><td>O(n+r)</td><td>稳定</td></tr></tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文系统地整理了408数据结构考研大纲的核心知识点，包括基本概念、线性表、栈与队列、树与二叉树、图、查找和排序等内容。每个部分都包含了定义、性质、基本操作及其算法实现、时间复杂度分析和典型应用场景，帮助考生全面掌握数据结构的重要知识点。</p><p>数据结构是计算机科学的基础，也是408考研的重点科目之一。掌握好数据结构不仅对考研有帮助，对未来的学习和工作也有很大的益处。希望本文能够帮助考生系统地复习数据结构，取得好成绩。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 考研 </tag>
            
            <tag> 408 </tag>
            
            <tag> 计算机基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零入门 AI for Science（AI+药物) 笔记</title>
      <link href="/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/"/>
      <url>/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="使用平台"><a href="#使用平台" class="headerlink" title="使用平台"></a>使用平台</h1><p><a href="https://modelscope.cn/my/mynotebook/preset">我的Notebook · 魔搭社区 https://modelscope.cn/my/mynotebook/preset </a>.</p><blockquote><p>魔搭高峰期打不开Task3又换回飞桨了 吧torch 架构换成了 飞桨的paddle </p></blockquote><p><a href="https://aistudio.baidu.com/projectdetail/8191835?contributionType=1">飞桨AI Studio星河社区-人工智能学习与实训社区<br>https://aistudio.baidu.com/projectdetail/8191835?contributionType=1</a></p><h2 id="主要操作"><a href="#主要操作" class="headerlink" title="主要操作"></a>主要操作</h2><ol><li><p>运行实例，如果有时长尽量选择方式二（<strong>以下操作基于方式二的实例实现</strong>）<br><img src="/img/downloaded/aHR0cHM6_92e7fdf7158644d28c6c0e3b62aff0b9.png" alt="在这里插入图片描述"></p></li><li><p>创建文件夹，并重命名为  <strong>2.3siRNA</strong> </p></li><li><p>上传两个文件<img src="/img/downloaded/aHR0cHM6_41268aec0e374679b7216b239d101ff4.png" alt="在这里插入图片描述"><br>到文件夹， 这里面的第三个按钮是上传<img src="/img/downloaded/aHR0cHM6_fc198bfaeb75475b9cbac58e5cf1fc7e.png" alt="在这里插入图片描述"></p></li><li><p>在当前文件夹打开终端（如图示意打开终端）并输入解压命令<br><img src="/img/downloaded/aHR0cHM6_086901afd6a349a5bfb06ab4536adf46.png" alt="在这里插入图片描述"></p></li></ol><p>注意：如果你的压缩包名字不是这个请将“siRNA_0715.zip” 换成你的压缩文件的名字“xxx.zip”(xxx为文件名)<br>（方便复制）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip siRNA_0715.zip </span><br></pre></td></tr></table></figure><pre><code>到这里准备工作可以了，如果解压出问题了，可以重新上传一下，然后重复解压的操作</code></pre><h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p><img src="/img/downloaded/aHR0cHM6_ec1ffa1535df433d9866dae1ce51808e.png" alt="在这里插入图片描述"></p><p><a href="https://blog.csdn.net/qq_23311271/article/details/140357529"> 详细可以参考这篇 </a></p><h1 id="参赛平台"><a href="#参赛平台" class="headerlink" title="参赛平台"></a>参赛平台</h1><p><a href="http://competition.sais.com.cn/competitionDetail/532230/format"> 上海科学智能研究院 </a></p><h1 id="Task-1-跑通基线"><a href="#Task-1-跑通基线" class="headerlink" title="Task 1 跑通基线"></a>Task 1 跑通基线</h1><blockquote><p><strong>baseline</strong></p></blockquote><ol><li>运行笔记本<blockquote><p>2.3siRNA&#x2F;task3.2_siRNA.ipynb<br><img src="/img/downloaded/aHR0cHM6_eb0ba47957fd4bf2aad2d33e633b2b16.png" alt="在这里插入图片描述"><br>就是这个橙不溜秋的书签，双击运行</p></blockquote></li><li>运行笔记本中的所有代码<br><img src="/img/downloaded/aHR0cHM6_ee4bb5641c0b436faffe246b30265603.png" alt="在这里插入图片描述"></li><li>等待结果出来<br><img src="/img/downloaded/aHR0cHM6_21c0df2a98f545b29c1d63ead8a5875f.png" alt="在这里插入图片描述"><br>可以看到多了一个文件夹和文件<blockquote><p>右键下载<strong>result&#x2F;submission.csv</strong>文件（<strong>download</strong>）</p></blockquote></li></ol><p><img src="/img/downloaded/aHR0cHM6_62f2ab77362b42bc9f367cc35b494ac8.png" alt="在这里插入图片描述"></p><h4 id="注意用完平台记得关闭实例（右上角）"><a href="#注意用完平台记得关闭实例（右上角）" class="headerlink" title="注意用完平台记得关闭实例（右上角）!!!"></a><font color="red" size = "1" >注意用完平台记得关闭实例（右上角）!!!</font></h4><h4 id="注意用完平台记得关闭实例（右上角）-1"><a href="#注意用完平台记得关闭实例（右上角）-1" class="headerlink" title="注意用完平台记得关闭实例（右上角）!!!"></a><font color="red" size = "2" >注意用完平台记得关闭实例（右上角）!!!</font></h4><h4 id="注意用完平台记得关闭实例（右上角）-2"><a href="#注意用完平台记得关闭实例（右上角）-2" class="headerlink" title="注意用完平台记得关闭实例（右上角）!!! "></a><font color="red" size = "3" >注意用完平台记得关闭实例（右上角）!!! </font></h4><p><img src="/img/downloaded/aHR0cHM6_00d5071a6a4f47ca960e424701f6ee83.png" alt="在这里插入图片描述"><br>tips: 算力充足可以当我没说,不关的话时长会一直使用</p><h2 id="提交文件获得第一个分数"><a href="#提交文件获得第一个分数" class="headerlink" title="提交文件获得第一个分数"></a>提交文件获得第一个分数</h2><p>平台：<a href="http://competition.sais.com.cn/competitionDetail/532230/format"> 上海科学智能研究院 </a></p><blockquote><p>注册和实名制略过</p></blockquote><h3 id="点击提交结果和选中刚刚下载的文件等待上传"><a href="#点击提交结果和选中刚刚下载的文件等待上传" class="headerlink" title="点击提交结果和选中刚刚下载的文件等待上传"></a>点击提交结果和选中刚刚下载的文件等待上传</h3><p><img src="/img/downloaded/aHR0cHM6_244591e9908741fea87392f2f0b922dd.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_31f7f73a377a4c258dcc762529a674ba.png" alt="在这里插入图片描述"></p><h3 id="点击我的成绩查看分数"><a href="#点击我的成绩查看分数" class="headerlink" title="点击我的成绩查看分数"></a>点击我的成绩查看分数</h3><p><img src="/img/downloaded/aHR0cHM6_efc7fa8898c945a68fa54f42e5207e63.png" alt="在这里插入图片描述"><br>其中task1中只选择了部分作为特征值，可以将全部的有效数据转换成特征值，必涨点。<br><img src="/img/downloaded/aHR0cHM6_add42f7cd5224b7bb3c98235ac281141.png" alt="在这里插入图片描述"></p><h3 id="训练数据表头说明"><a href="#训练数据表头说明" class="headerlink" title="训练数据表头说明"></a>训练数据表头说明</h3><blockquote><p>数据来源于官网</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_a59fef77e4c14944adf799a4de3ebb0c.png" alt="在这里插入图片描述"></p><h4 id="特征的分析总结"><a href="#特征的分析总结" class="headerlink" title="特征的分析总结"></a>特征的分析总结</h4><table><thead><tr><th>特征类别</th><th>特征字段名称</th><th>特征描述</th><th>分析目的</th></tr></thead><tbody><tr><td>基因特异性</td><td>gene_target_symbol_name</td><td>靶基因符号名称</td><td>研究不同基因名称对siRNA设计的影响</td></tr><tr><td></td><td>gene_target_ncbi_id</td><td>靶基因的NCBI标识</td><td>研究不同NCBI ID对siRNA设计的影响</td></tr><tr><td></td><td>gene_target_species</td><td>靶基因参考序列的物种</td><td>研究不同物种对siRNA沉默效率的影响</td></tr><tr><td>siRNA序列特征</td><td>siRNA_sense_seq</td><td>siRNA的sense序列</td><td>分析sense序列设计对沉默效率的影响</td></tr><tr><td></td><td>siRNA_antisense_seq</td><td>siRNA的antisense序列</td><td>分析antisense序列设计对沉默效率的影响</td></tr><tr><td></td><td>modified_siRNA_sense_seq</td><td>带修饰的siRNA的sense序列</td><td>分析修饰对siRNA功能的影响</td></tr><tr><td></td><td>modified_siRNA_antisense_seq</td><td>带修饰的siRNA的antisense序列</td><td>分析修饰对siRNA功能的影响</td></tr><tr><td>siRNA浓度和单位</td><td>siRNA_concentration</td><td>实验使用的siRNA浓度</td><td>研究不同浓度对沉默效率的影响</td></tr><tr><td></td><td>concentration_unit</td><td>siRNA浓度单位</td><td>研究不同单位对siRNA浓度影响的理解</td></tr><tr><td>转染方法</td><td>Transfection_method</td><td>转染方法</td><td>分析不同转染技术对siRNA传递和沉默效果的影响</td></tr><tr><td>转染后持续时间</td><td>Duration_after_transfection_h</td><td>转染后持续时间</td><td>了解转染后不同时间点的沉默效果</td></tr><tr><td>序列分解列表</td><td>modified_siRNA_sense_seq_list</td><td>带修饰的siRNA的sense序列分解列表</td><td>识别关键核苷酸位点，优化siRNA设计</td></tr><tr><td></td><td>modified_siRNA_antisense_seq_list</td><td>带修饰的siRNA的antisense序列分解列表</td><td>识别关键核苷酸位点，优化siRNA设计</td></tr><tr><td>靶基因序列</td><td>gene_target_seq</td><td>靶基因的参考序列</td><td>分析siRNA与靶基因序列匹配程度对沉默效率的影响</td></tr><tr><td>沉默效率</td><td>mRNA_remaining_pct</td><td>实验后mRNA的剩余百分比</td><td>评估不同条件下siRNA沉默效率的直接指标</td></tr></tbody></table><blockquote><p>目前尝试了 计算序列的长度 、计算序列的熵值、序列中腺嘌呤（A）、胸腺嘧啶（T）、胞嘧啶（C）和鸟嘌呤（G）的数目、GC含量、序列的熵值</p></blockquote><p>创建了两个函数作为特征</p><ol><li><p><code>calculate_sequence_features</code> 函数：</p><ul><li>它首先计算序列的长度。</li><li>然后计算序列中腺嘌呤（A）、胸腺嘧啶（T）、胞嘧啶（C）和鸟嘌呤（G）的数目，并由此计算出它们的相对频率。</li><li>接着计算GC含量，即序列中G和C的比例，这是影响DNA稳定性的一个重要因素。</li><li>计算序列的熵值，熵是一个度量序列随机性或复杂性的指标。熵越高，表示序列的多样性越高，没有明显的偏好性。</li></ul></li><li><p><code>calculate_entropy</code> 函数：</p><ul><li>计算序列中每个核苷酸（A、C、G、T）的数目。</li><li>用一个字典来存储每个核苷酸的计数。</li><li>遍历这个字典，对每个非零计数的核苷酸，使用公式 $-p \log_2(p)$  来计算其对熵的贡献。</li></ul></li></ol><p>（比赛原因先不贴代码）</p><blockquote><p>至此Task1 baseline 任务完成 </p></blockquote><h2 id="Task1-知识点终结"><a href="#Task1-知识点终结" class="headerlink" title="Task1 知识点终结"></a>Task1 知识点终结</h2><h3 id="基因组分词器类"><a href="#基因组分词器类" class="headerlink" title="基因组分词器类"></a>基因组分词器类</h3><p>基因组分词器的目的是将基因组序列分割成固定长度的n-gram片段。这是为了进一步处理或分析基因组数据时的需要。</p><p><strong>基因组数据通常是由ACGT四个字母（腺嘌呤、胞嘧啶、鸟嘌呤和胸腺嘧啶）组成的序列。</strong> </p><h4 id="n-gram"><a href="#n-gram" class="headerlink" title="n-gram"></a>n-gram</h4><blockquote><p>指由n个连续字母构成的片段。将基因组序列分割成n-gram片段可以帮助我们理解基因组的结构和功能。</p></blockquote><p>基因组分词器将基因组序列分割成固定长度的n-gram片段可以用于以下应用：</p><ul><li><strong>基因组注释</strong>：通过分析n-gram片段可以识别基因、启动子、转录因子结合位点等功能区域。</li><li><strong>基因组比对</strong>：将n-gram片段与已知的基因组序列进行比对，可以找到相似的片段并识别基因的同源性。</li><li><strong>基因组序列分类</strong>：通过分析n-gram片段可以将不同物种的基因组序列进行分类。</li></ul><h3 id="GRU的神经网络模型"><a href="#GRU的神经网络模型" class="headerlink" title="GRU的神经网络模型"></a>GRU的神经网络模型</h3><blockquote><p>GRU是一种循环神经网络（RNN）模型，全称为Gated Recurrent Unit。它是一种改进的RNN架构，用于处理序列数据，尤其在自然语言处理和语音识别等任务中表现出色。</p></blockquote><p>GRU通过<strong>引入门控机制来解决传统RNN存在的短期记忆和长期记忆不平衡的问题</strong>。它具有两个门控单元：<strong>重置门（reset gate）和更新门（update gate）</strong>。重置门控制了当前状态如何与先前状态相结合，而更新门控制了用于传递信息的新状态的计算。</p><blockquote><p>GRU单元结构如下图所示<br><img src="/img/downloaded/aHR0cHM6_e5feeae81be9445ca8263ebf1a870248.png" alt="在这里插入图片描述"><br>GRU是Ilya Sutskever和Oriol Vinyals等人在2014年提出的一种改进的RNN单元，它旨在解决传统RNN在处理长序列时出现的梯度消失或梯度爆炸问题。</p></blockquote><p>GRU的核心思想是引入两个门控机制：<strong>更新门（Update Gate）和重置门（Reset Gate）。<strong>这两个门控机制允许模型</strong>动态地决定在每个时间步上应该保留多少之前的信息，以及应该更新多少当前的信息</strong>。这使得GRU能够更好地捕捉长距离依赖关系。</p><h4 id="GRU的数学模型"><a href="#GRU的数学模型" class="headerlink" title="GRU的数学模型"></a>GRU的数学模型</h4><h5 id="更新门（Update-Gate）"><a href="#更新门（Update-Gate）" class="headerlink" title="更新门（Update Gate）"></a>更新门（Update Gate）</h5><p>更新门决定了在当前时间步应该保留多少之前的隐藏状态。更新门的公式如下：</p><p>$$<br>z_t &#x3D; \sigma(W_z \cdot [h_{t-1}, x_t])<br>$$</p><p>其中，$z_t$ 是更新门的输出，$W_z$ 是更新门的权重矩阵，$\sigma$ 是<strong>sigmoid函数</strong>（不懂的后面有讲 sigmoid函数）。</p><h5 id="重置门（Reset-Gate）"><a href="#重置门（Reset-Gate）" class="headerlink" title="重置门（Reset Gate）"></a>重置门（Reset Gate）</h5><p>重置门决定了在当前时间步应该忽略多少之前的隐藏状态。重置门的公式如下：</p><p>$$<br>r_t &#x3D; \sigma(W_r \cdot [h_{t-1}, x_t])<br>$$</p><p>其中，$r_t$ 是重置门的输出，$W_r$ 是重置门的权重矩阵。</p><h5 id="候选隐藏状态（Candidate-Hidden-State）"><a href="#候选隐藏状态（Candidate-Hidden-State）" class="headerlink" title="候选隐藏状态（Candidate Hidden State）"></a>候选隐藏状态（Candidate Hidden State）</h5><p>候选隐藏状态是当前时间步的新信息，其公式如下：</p><p>$$<br>\tilde{h}<em>t &#x3D; \tanh(W \cdot [r_t \odot h</em>{t-1}, x_t])<br>$$</p><p>其中，$\tilde{h}_t$ 是候选隐藏状态，$W$ 是候选隐藏状态的权重矩阵，$\odot$ 表示<strong>Hadamard乘积</strong>(不懂的后面有讲 Hadamard乘积)。</p><h5 id="最终隐藏状态（Final-Hidden-State）"><a href="#最终隐藏状态（Final-Hidden-State）" class="headerlink" title="最终隐藏状态（Final Hidden State）"></a>最终隐藏状态（Final Hidden State）</h5><p>最终隐藏状态结合了之前保留的信息和当前的新信息，其公式如下：</p><p>$$<br>h_t &#x3D; (1 - z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t<br>$$</p><p>其中，$h_t$ 是最终的隐藏状态。　</p><p><strong>GRU在自然语言处理、语音识别和时间序列预测等领域有着广泛的应用</strong>。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p><strong>相比于普通的RNN模型，GRU具有更好的记忆能力和更强的建模能力，同时减少了参数数量，使得训练过程更加高效。</strong> 由于其优秀的性能和实用性，GRU已经成为经典的循环神经网络模型之一，并被广泛应用于各种序列数据分析任务中。</p><h3 id="学科知识"><a href="#学科知识" class="headerlink" title="学科知识"></a>学科知识</h3><h4 id="RNA干扰（RNAi）"><a href="#RNA干扰（RNAi）" class="headerlink" title="RNA干扰（RNAi）"></a>RNA干扰（RNAi）</h4><blockquote><p><strong>RNA干扰（RNAi）是一种细胞内的基因调控机制，通过通过RNA分子的干扰来抑制特定基因的表达。</strong></p></blockquote><p>RNAi在细胞内通过两种途径实现：<strong>小干扰RNA（siRNA） 和微小RNA（miRNA）</strong>。</p><p>在RNAi中，基因表达的抑制通常发生在转录后水平。当特定基因的DNA序列转录成RNA时，RNA聚合酶将生成多个复制的RNA分子。<strong>这些RNA分子中的一部分可以通过Dicer酶切割成长度约为21-23个核苷酸的小片段，即siRNA或miRNA</strong>。这些小片段与蛋白质复合物<strong>形成RNA-诱导沉默复合物（RISC），并通过与靶标mRNA相互作用来抑制其翻译或引起其降解</strong>。</p><p><strong>siRNA是通过外源性引入细胞的siRNA分子，通过与特定基因的mRNA相互作用来抑制其表达。</strong><br><strong>miRNA是内在于细胞的小RNA分子，能够识别并与多个基因的mRNA结合，从而调节多个基因的表达。</strong></p><p>RNAi在生物学研究中被广泛应用。可以<strong>用于研究基因功能，筛选潜在药物靶点，开发基因治疗方法等</strong>。<strong>还有潜力成为治疗疾病的方法，包括癌症、病毒感染和遗传疾病等</strong>。</p><h4 id="Dicer-酶"><a href="#Dicer-酶" class="headerlink" title="Dicer 酶"></a>Dicer 酶</h4><blockquote><p>RNA 干扰（RNAi）过程中的一个关键酶。它是一种 RNase III 家族的内切酶，在 RNAi 过程中起着重要的作用。</p></blockquote><p>Dicer 酶能够识别和切割双链 RNA（dsRNA）分子，将其切割成短的双链小干扰 RNA（siRNA）。</p><h4 id="RNAi作用机制"><a href="#RNAi作用机制" class="headerlink" title="RNAi作用机制"></a>RNAi作用机制</h4><blockquote><p>文档内容里面的这个讲的很详细我啃臭cv一份</p></blockquote><p>生物体内，RNAi首先将较长的双链RNA加工和切割成 siRNA，通常在每条链的3’末端带有2个核苷酸突出端。负责这种加工的酶是一种RNase III样酶，称为Dicer。形成后，siRNA与一种称为RNA诱导的沉默复合物（RNAinduced silencing complex, RISC）的多蛋白组分复合物结合。在RISC复合物中，siRNA链被分离，具有更稳定的5′末端的链通常被整合到活性RISC复合物中。然后，反义单链siRNA组分引导并排列在靶mRNA上，并通过催化RISC蛋白（Argonaute family（Ago2））的作用，mRNA被切割，即对应基因被沉默，表达蛋白能力削弱。<br><img src="/img/downloaded/aHR0cHM6_87da9c44cd4a49e493ce7ccd5998c7c7.png" alt="在这里插入图片描述"><br>传统siRNA设计原则与知识<br>  siRNA的沉默效率与众多因素相关，例如siRNA的稳定性、修饰、转染方法等。一些经验的生物知识可用于特征构建和AI模型的设计。</p><p>在siRNA一般设计过程中有以下知识和原则：</p><blockquote><ol><li>siRNA序列（一般为反义链）与靶向RNA互补。</li><li>siRNA序列长度一般在19～29nt之间。研究表明21nt相比27nt对靶基因的最大抑制率更容易达到。</li><li>一般来说，从靶基因起始密码子AUG下游50～100个核苷酸，或位于终止密码子50-100个核苷酸范围内的序列（确保转录基因为沉默状态）搜寻理想的siRNA序列，越靠近靶基因的3′端，其基因沉默效果可能越好。</li><li>一般设计好的潜在siRNA序列，会在GenBank数据库进行BLAST，去掉其他基因有显著同源性的靶序列（错误靶向）。</li><li>具体序列而言，最好为AA+(Nn)UU(N代表任意碱基，n为碱基数目)，其次是NA(Nn)UU和NA(Nn)NN。</li><li>一般情况下，siRNA的稳定性直接影响其最终在细胞中的敲低效率。在siRNA的反义链5’端第一个碱基尽量可能是为A或U; siRNA正义链的5’端第一个碱基尽量为G或C。</li><li>一般情况下，3′端的2个碱基使用突出的dTdT（deoxythymidine dinucleotide）取代，能够增强siRNA 双链复合体的稳定性，进而增加siRNA的敲低效率。</li><li>G&#x2F;C含量在30%～52%的siRNA序列，其沉默基因效果较好。研究表明40–55％ GC的含量敲低效率高于GC含量高于55%的。</li><li>一般来说，siRNA序列中连续2个及以上G&#x2F;C能够降低双链RNA内在稳定性，从而降低siRNA在细胞中的敲低效率；而连续3个以上的A和U可能终止由RNA Polymerase III介导的转录作用。siRNA序列中的重复序列或回文结构可能形成发夹状结构，这种结构的存在可以降低siRNA敲低效率。</li></ol></blockquote><h4 id="化学修饰siRNA"><a href="#化学修饰siRNA" class="headerlink" title="化学修饰siRNA"></a>化学修饰siRNA</h4><p>化学修饰siRNA是指通过<strong>在siRNA分子上引入化学修饰基团，改变其结构或性质的方法</strong>。这种修饰<strong>可以增强siRNA的稳定性、增加其目标特异性、改善细胞内进入能力</strong>等。</p><blockquote><p>常用的siRNA化学修饰包括以下几种:</p><ol><li>2’-氧甲基（2’-O-Me）修饰：这种修饰是将2’-羟基上的氧原子替换为甲基基团。它可以增加siRNA的稳定性，提高RNA酶的抵抗性。</li><li>2’-氟（2’-F）修饰：这种修饰是将2’-羟基上的氧原子替换为氟原子。它可以提高siRNA的稳定性和特异性，减少对非特定靶标的作用。</li><li>磷酸甲酯（PS）修饰：这种修饰是在磷酸二酯桥上引入甲酯基团。它可以增强siRNA的稳定性和细胞内进入能力。</li><li>枝状修饰：这种修饰是在siRNA分子上引入枝状结构，增加其稳定性和亲水性。</li><li>核苷酸修饰：这种修饰是在siRNA的碱基上引入修饰基团，例如甲基化、二硫苷化等。它可以改变siRNA与靶标RNA的配对能力和稳定性。</li></ol></blockquote><p>化学修饰siRNA可以<strong>优化其性能和提高其在RNAi研究和治疗中的应用潜力</strong>。但化学修饰可能会<strong>对siRNA的活性和毒性产生影响</strong>，因此在设计和选择修饰方案时需要进行<strong>全面的评估和优化</strong>。</p><h3 id="机器学习知识点"><a href="#机器学习知识点" class="headerlink" title="机器学习知识点"></a>机器学习知识点</h3><h4 id="MAE-Mean-Absolute-Error"><a href="#MAE-Mean-Absolute-Error" class="headerlink" title="MAE (Mean Absolute Error)"></a>MAE (Mean Absolute Error)</h4><blockquote><p><strong>表示预测值与真实值之间的平均绝对误差。</strong></p></blockquote><p>它计算每个样本的预测值与真实值之间的差值的绝对值，然后对所有样本取平均。</p><h4 id="召回率（Recall）"><a href="#召回率（Recall）" class="headerlink" title="召回率（Recall）"></a>召回率（Recall）</h4><blockquote><p><strong>表示所有真正例中被正确预测为正例的比例。</strong></p></blockquote><p>召回率可以衡量模型对正例的覆盖程度，即模型有多少能够找到真正例。</p><h4 id="F1得分"><a href="#F1得分" class="headerlink" title="F1得分"></a>F1得分</h4><blockquote><p><strong>精确度和召回率的调和平均值。</strong></p></blockquote><p>F1得分的取值范围为0到1，其中1表示最佳性能，0表示最差性能。</p><h4 id="精确度（Precision）"><a href="#精确度（Precision）" class="headerlink" title="精确度（Precision）"></a>精确度（Precision）</h4><blockquote><p><strong>表示被预测为正例中实际为正例的比例。</strong></p></blockquote><p>精确度可以衡量模型的准确性，即模型有多少预测为正例的样本真正是正例。</p><h5 id="赛题评分代码"><a href="#赛题评分代码" class="headerlink" title="赛题评分代码"></a>赛题评分代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># score = 50% × (1−MAE/100) + 50% × F1 × (1−Range-MAE/100)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_metrics</span>(<span class="params">y_true, y_pred, threshold=<span class="number">30</span></span>):</span><br><span class="line">    <span class="comment"># 计算平均绝对误差（MAE）</span></span><br><span class="line">    mae = np.mean(np.<span class="built_in">abs</span>(y_true - y_pred))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将真实值和预测值转换为二值标签，根据阈值进行分类</span></span><br><span class="line">    y_true_binary = (y_true &lt; threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">    y_pred_binary = (y_pred &lt; threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 阈值（30）</span></span><br><span class="line">    <span class="comment"># 创建一个掩码，用于将预测值限制在指定范围内</span></span><br><span class="line">    mask = (y_pred &gt;= <span class="number">0</span>) &amp; (y_pred &lt;= threshold)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在掩码范围内计算平均绝对误差（MAE）</span></span><br><span class="line">    range_mae = mean_absolute_error(y_true[mask], y_pred[mask]) <span class="keyword">if</span> mask.<span class="built_in">sum</span>() &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算精确度、召回率和F1分数</span></span><br><span class="line">    precision = precision_score(y_true_binary, y_pred_binary, average=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    recall = recall_score(y_true_binary, y_pred_binary, average=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    f1 = <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算综合评分</span></span><br><span class="line">    score = (<span class="number">1</span> - mae / <span class="number">100</span>) * <span class="number">0.5</span> + (<span class="number">1</span> - range_mae / <span class="number">100</span>) * f1 * <span class="number">0.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> score </span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="综合评分"><a href="#综合评分" class="headerlink" title="综合评分"></a>综合评分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score = (<span class="number">1</span> - mae / <span class="number">100</span>) * <span class="number">0.5</span> + (<span class="number">1</span> - range_mae / <span class="number">100</span>) * f1 * <span class="number">0.5</span></span><br></pre></td></tr></table></figure><blockquote><p>最终的评分是根据模型在三个方面的表现进行计算的。</p><ol><li>通过计算平均绝对误差（MAE）来衡量模型的整体预测精度，MAE越小，表明模型的预测误差越小，得分越高。</li><li>通过计算在指定范围内的平均绝对误差（Range MAE），来衡量模型对于特定范围内的预测的准确性，Range MAE越小，表明模型在该范围内的预测误差越小，得分越高。</li><li>计算模型的分类性能，即精确度、召回率和F1得分。F1得分越高，表明模型在分类任务上的性能越好，得分越高。最终的评分是这几个值的加权平均数，其中MAE和Range MAE各占50%权重。<br>综合考虑这些因素，可以得出模型的总体表现得分。</li></ol></blockquote><h5 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h5><p><strong>在分类问题中，精确度和召回率是互相影响的指标</strong>。高精确度可能意味着模型只预测那些非常确信的正例，导致召回率较低。相反，高召回率可能意味着模型会将更多样本预测为正例，导致精确度较低。因此，F1得分作为精确度和召回率的综合指标，可以平衡这两个指标的表现。<strong>在评估模型性能时，通常会综合考虑精确度、召回率和F1得分。</strong></p><h4 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h4><blockquote><p>一种常用的激活函数，用于在神经网络中引入非线性。</p></blockquote><p>它的数学表达式如下：</p><p>$$<br>sigmoid(x) &#x3D; 1 &#x2F; (1 + exp(-x))<br>$$</p><p>其中，$exp(-x)$表示e的-x次方，e是自然常数。</p><p><strong>Sigmoid函数的输出值范围在0到1之间，通常用于将输入值映射到一个概率分布，或者作为二分类问题中的激活函数。</strong></p><p>在GRU单元中，Sigmoid函数被用于计算两个门控向量：更新门（update gate）和重置门（reset gate）。这两个门控向量通过Sigmoid函数将输入向量和先前的隐藏状态向量映射到0到1之间的值，以控制它们对更新和重置操作的贡献。</p><p><strong>更新门决定了先前的隐藏状态应该如何被保留或更新，而重置门决定了先前的隐藏状态如何与当前输入进行组合。<br>Sigmoid函数在GRU单元中通过限制门控向量的取值范围，使得GRU单元能够自适应地更新和遗忘信息，并有效地处理输入序列数据。</strong></p><h4 id="Hadamard乘积"><a href="#Hadamard乘积" class="headerlink" title="Hadamard乘积"></a>Hadamard乘积</h4><blockquote><p>也称为元素级乘积或逐元素乘积，是一种运算，用来<strong>对两个具有相同维度的向量、矩阵或张量进行逐元素的相乘</strong>。</p></blockquote><p>对于两个维度相同的向量 A 和 B，Hadamard乘积的运算规则为：<br>$$<br>C &#x3D; A ⊙ B<br>$$<br>其中 ⊙ 表示Hadamard乘积运算，C 是结果向量，C 的每个元素都等于 A 和 B 对应位置元素的乘积。</p><p>对于矩阵和张量，Hadamard乘积的运算规则与向量相同，只不过是在对应位置的元素进行相乘。<br><strong>Hadamard乘积通常用于逐元素操作，如逐元素乘法、逐元素加法等。</strong><br>它与矩阵乘法或点积运算不同，<strong>矩阵乘法是对应位置元素的乘积再求和</strong>，<br>而<strong>Hadamard乘积是对应位置元素直接相乘。</strong><br>Hadamard乘积<strong>在深度学习中经常用于一些操作，如逐元素激活函数、逐元素损失函数、逐元素操作的正则化等</strong>。它可以帮助模型学习非线性关系，同时保持数据的维度不变。</p><h1 id="Task2"><a href="#Task2" class="headerlink" title="Task2"></a>Task2</h1><blockquote><p>前面了解了赛题，这个主要讲baseline代码，入门RNN和特征工程</p></blockquote><h2 id="解读官方baseline"><a href="#解读官方baseline" class="headerlink" title="解读官方baseline"></a>解读官方baseline</h2><h2 id="set-random-seed"><a href="#set-random-seed" class="headerlink" title="set_random_seed"></a>set_random_seed</h2><blockquote><p>统一设置随机种子</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">set_random_seed</span>(<span class="params">seed</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    设置随机种子，确保结果可复现。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        seed (int): 随机种子值。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        无</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    np.random.seed(seed)  <span class="comment"># 设置NumPy的随机种子</span></span><br><span class="line">    random.seed(seed)  <span class="comment"># 设置Python内置的随机数生成器的种子</span></span><br><span class="line">    torch.manual_seed(seed)  <span class="comment"># 设置PyTorch的随机种子</span></span><br><span class="line">    torch.cuda.manual_seed(seed)  <span class="comment"># 设置CUDA的随机种子</span></span><br><span class="line">    torch.cuda.manual_seed_all(seed)  <span class="comment"># 设置所有CUDA设备的随机种子</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span>  <span class="comment"># 确保每次卷积算法选择都是确定的</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span>  <span class="comment"># 关闭CuDNN自动优化功能，确保结果可复现</span></span><br></pre></td></tr></table></figure><blockquote><p>这里做了这些操作</p></blockquote><ol><li>设置NumPy的随机种子 </li><li>设置Python内置的随机数生成器的种子 </li><li>设置PyTorch的随机种子 </li><li>设置CUDA的随机种子</li><li>设置所有CUDA设备的随机种子 </li><li>确保每次卷积算法选择是确定的 </li><li>关闭CuDNN自动优化功能</li></ol><p><strong>就是把每一个自动优化或随机种子的选项都关掉了，然后确保结果不会因为自动优化或随机数而改变,因而可以复现结果。</strong></p><h2 id="SiRNADataset"><a href="#SiRNADataset" class="headerlink" title="SiRNADataset"></a>SiRNADataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SiRNADataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, df, columns, vocab, tokenizer, max_len, is_test=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化SiRNADataset类</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            df (DataFrame): 包含数据的数据框</span></span><br><span class="line"><span class="string">            columns (list): 包含序列的列名列表</span></span><br><span class="line"><span class="string">            vocab (Vocab): 词汇表</span></span><br><span class="line"><span class="string">            tokenizer (Tokenizer): 分词器</span></span><br><span class="line"><span class="string">            max_len (int): 最大序列长度</span></span><br><span class="line"><span class="string">            is_test (bool, optional): 是否是测试集，默认为False</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.df = df</span><br><span class="line">        <span class="variable language_">self</span>.columns = columns</span><br><span class="line">        <span class="variable language_">self</span>.vocab = vocab</span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = tokenizer</span><br><span class="line">        <span class="variable language_">self</span>.max_len = max_len</span><br><span class="line">        <span class="variable language_">self</span>.is_test = is_test</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        返回数据集的长度</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.df)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        获取数据集中的第idx个样本</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            idx (int): 样本索引</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            seqs (list): 编码后的序列列表</span></span><br><span class="line"><span class="string">            target (tensor): 目标值张量（仅在非测试集模式下）</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        row = <span class="variable language_">self</span>.df.iloc[idx]</span><br><span class="line">        seqs = [<span class="variable language_">self</span>.tokenize_and_encode(row[col]) <span class="keyword">for</span> col <span class="keyword">in</span> <span class="variable language_">self</span>.columns]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_test:</span><br><span class="line">            <span class="keyword">return</span> seqs</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            target = torch.tensor(row[<span class="string">&#x27;mRNA_remaining_pct&#x27;</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            <span class="keyword">return</span> seqs, target</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tokenize_and_encode</span>(<span class="params">self, seq</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对序列进行分词和编码</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            seq (str): 待处理的序列</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            encoded_seq (tensor): 编码后的序列张量</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">in</span> seq:</span><br><span class="line">            tokens = seq.split()  <span class="comment"># 如果序列中包含空格，则按空格分词</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tokens = <span class="variable language_">self</span>.tokenizer.tokenize(seq)  <span class="comment"># 否则使用分词器进行分词</span></span><br><span class="line">        encoded = [<span class="variable language_">self</span>.vocab.stoi.get(token, <span class="number">0</span>) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]  <span class="comment"># 将分词后的每个词编码为对应的索引</span></span><br><span class="line">        padded = encoded + [<span class="number">0</span>] * (<span class="variable language_">self</span>.max_len - <span class="built_in">len</span>(encoded))  <span class="comment"># 将序列补齐到最大长度</span></span><br><span class="line">        <span class="keyword">return</span> torch.tensor(padded[:<span class="variable language_">self</span>.max_len], dtype=torch.long)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>定义了一个<strong>SiRNADataset类来创建一个自定义的PyTorch数据集对象</strong>。</p><p><strong>目的是将输入的数据框（df）中的序列数据分词、编码和填充，并返回编码后的序列和目标值</strong>。</p><h3 id="SiRNADataset类的方法"><a href="#SiRNADataset类的方法" class="headerlink" title="SiRNADataset类的方法"></a>SiRNADataset类的方法</h3><h4 id="初始化方法："><a href="#初始化方法：" class="headerlink" title="初始化方法："></a>初始化方法：</h4><blockquote><p>接受数据并处理成对象属性</p></blockquote><p>接收了下面这些数据并保存为对象的属性：</p><p> <strong>1. 接收数据框（df）<br> 2. 包含序列的列名（columns）<br> 3. 词汇表（vocab）<br> 4. 分词器（tokenizer）<br> 5. 最大序列长度（max_len）<br> 6. 否为测试集（is_test)</strong></p><h4 id="len-方法"><a href="#len-方法" class="headerlink" title="__len__方法"></a>__len__方法</h4><blockquote><p>返回数据框中的样本数量。</p></blockquote><h4 id="getitem-方法"><a href="#getitem-方法" class="headerlink" title="__getitem__方法"></a>__getitem__方法</h4><blockquote><p>根据给定的索引（idx），获取数据集中的第idx个样本。</p></blockquote><p>首先根据索引获取数据框中的一行数据，然后对每一列的序列数据进行分词和编码。</p><ul><li>如果是测试集模式（is_test为True），则返回编码后的序列。</li><li>如果不是测试集模式，则将目标值转换为张量，并返回编码后的序列和目标值。</li></ul><h4 id="tokenize-and-encode方法"><a href="#tokenize-and-encode方法" class="headerlink" title="tokenize_and_encode方法"></a>tokenize_and_encode方法</h4><blockquote><p>接收一个序列（seq，这个就是我们要处理的序列）作为输入，根据序列是否包含空格，选择不同的方式分词。</p></blockquote><p>这里有两种分词方法:</p><ul><li>包含空格的序列，将其按空格进行分词；  （这个就是对<strong>modified_siRNA_antisense_seq_list(modified_xxxx)</strong> 的数据，它本身已经根据空格分好了）</li><li>常规序列，使用指定的分词器进行分词。</li></ul><p>然后，将分词后的token转换为词汇表中对应的索引，未知的token使用索引0（代表$<pad>$）。最后将编码后的序列填充到最大长度，返回张量格式的序列。</p><h2 id="SiRNAModel-类"><a href="#SiRNAModel-类" class="headerlink" title="SiRNAModel 类"></a>SiRNAModel 类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SiRNAModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_dim=<span class="number">200</span>, hidden_dim=<span class="number">256</span>, n_layers=<span class="number">3</span>, dropout=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化SiRNA模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            vocab_size (int): 词汇表大小</span></span><br><span class="line"><span class="string">            embed_dim (int): 嵌入维度 (默认值: 200)</span></span><br><span class="line"><span class="string">            hidden_dim (int): 隐藏层维度 (默认值: 256)</span></span><br><span class="line"><span class="string">            n_layers (int): GRU层的层数 (默认值: 3)</span></span><br><span class="line"><span class="string">            dropout (float): Dropout层的丢弃率 (默认值: 0.5)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(SiRNAModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=<span class="number">0</span>)  <span class="comment"># 初始化嵌入层</span></span><br><span class="line">        <span class="variable language_">self</span>.gru = nn.GRU(embed_dim, hidden_dim, n_layers, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>, dropout=dropout)  <span class="comment"># 初始化GRU层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(hidden_dim * <span class="number">4</span>, <span class="number">1</span>)  <span class="comment"># 初始化全连接层</span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)  <span class="comment"># 初始化Dropout层</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向传播函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            x (List[Tensor]): 输入序列列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">            Tensor: 模型的输出张量</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        embedded = [<span class="variable language_">self</span>.embedding(seq) <span class="keyword">for</span> seq <span class="keyword">in</span> x]  <span class="comment"># 将输入序列传入嵌入层</span></span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> embed <span class="keyword">in</span> embedded:</span><br><span class="line">            x, _ = <span class="variable language_">self</span>.gru(embed)  <span class="comment"># 传入GRU层</span></span><br><span class="line">            x = <span class="variable language_">self</span>.dropout(x[:, -<span class="number">1</span>, :])  <span class="comment"># 取最后一个隐藏状态，并进行dropout处理</span></span><br><span class="line">            outputs.append(x)</span><br><span class="line"></span><br><span class="line">        x = torch.cat(outputs, dim=<span class="number">1</span>)  <span class="comment"># 将所有序列的输出拼接起来</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)  <span class="comment"># 传入全连接层</span></span><br><span class="line">        <span class="keyword">return</span> x.squeeze()  <span class="comment"># 返回结果</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这个类继承自nn.Module类，用来处理RNA序列。</p><ol><li><strong>先将输入序列列表x传入嵌入层</strong>，</li><li>然后通过<strong>循环将每个序列的嵌入向量传入双向GRU层</strong>，<strong>取最后一个隐藏状态</strong>，<strong>并进行dropout处理</strong>。</li><li>最后，<strong>将所有序列的输出拼接起来，并传入一个全连接层，输出一个标量结果</strong>。</li></ol><h3 id="nn-Module类"><a href="#nn-Module类" class="headerlink" title="nn.Module类"></a>nn.Module类</h3><p><strong>nn.Module类是PyTorch中所有神经网络模型的基类</strong>，提供了一些<strong>基本的功能和方法，用于定义和管理神经网络模型的结构和参数</strong>。</p><h4 id="nn-Module类的作用有："><a href="#nn-Module类的作用有：" class="headerlink" title="nn.Module类的作用有："></a>nn.Module类的作用有：</h4><h5 id="定义模型的结构"><a href="#定义模型的结构" class="headerlink" title="定义模型的结构"></a>定义模型的结构</h5><blockquote><p><strong>通过__init__方法中定义各个层和模块，可以将不同的层组合在一起，构建出模型的结构。</strong></p></blockquote><h5 id="前向传播函数"><a href="#前向传播函数" class="headerlink" title="前向传播函数"></a>前向传播函数</h5><blockquote><p>通过forward方法中<strong>定义前向传播的过程</strong>，可以<strong>将输入数据在模型中传递，计算输出结果</strong>。</p></blockquote><h5 id="参数管理"><a href="#参数管理" class="headerlink" title="参数管理"></a>参数管理</h5><p>nn.Module类提供了一些方法，如<code>parameters()</code>和<code>named_parameters()</code>，可以自动追踪模型中所有的可学习参数，可以方便地进行参数的访问和管理。</p><h6 id="parameters"><a href="#parameters" class="headerlink" title="parameters()"></a><code>parameters()</code></h6><blockquote><p><code>parameters()</code>方法返回一个迭代器，该迭代器会遍历模型中的所有可学习参数。</p></blockquote><p>可学习参数是指那些需要在训练过程中进行优化调整的参数，例如神经网络中的权重和偏置项。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = SiRNAModel(...)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure><h6 id="named-parameters"><a href="#named-parameters" class="headerlink" title="named_parameters()"></a><code>named_parameters()</code></h6><blockquote><p><code>named_parameters()</code>方法返回一个迭代器，该迭代器会遍历模型中的所有可学习参数，并为每个参数附上一个名称。</p></blockquote><p>这个方法<strong>在调试和模型分析时常见</strong>，可以方便地<strong>查看每个参数的名称和对应的数值</strong>。也<strong>可以利用这个方法来选择性地冻结或更新某些参数。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;embedding&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        param.requires_grad = <span class="literal">False</span>  <span class="comment"># 冻结嵌入层的参数</span></span><br></pre></td></tr></table></figure><h5 id="模型保存和加载"><a href="#模型保存和加载" class="headerlink" title="模型保存和加载"></a>模型保存和加载</h5><blockquote><p>nn.Module类提供了方法，如<code>state_dict()</code>和<code>load_state_dict()</code>，可以方便地保存模型的状态和加载已保存的状态。</p></blockquote><p><strong>继承自nn.Module类的子类可以自由定义自己的网络结构，并且可以利用nn.Module提供的方法和功能来管理参数和实现前向传播过程。</strong><br>还可以<strong>与优化器、损失函数、数据加载器</strong>等，<strong>进一步提升模型的训练和使用效果</strong>。</p><h5 id="state-dict"><a href="#state-dict" class="headerlink" title="state_dict()"></a><code>state_dict()</code></h5><blockquote><p><code>state_dict()</code>(状态字典)是一个Python字典对象，其中包含了模型的所有可学习参数的名称和对应的张量值。</p></blockquote><p><code>state_dict()</code>方法返回模型的状态字典，可以将其保存到文件中，以便在之后的时间点恢复模型的状态。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = SiRNAModel(...)</span><br><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;model.pth&#x27;</span>)</span><br></pre></td></tr></table></figure><h5 id="load-state-dict"><a href="#load-state-dict" class="headerlink" title="load_state_dict()"></a><code>load_state_dict()</code></h5><blockquote><p>用于加载之前保存的模型的状态字典。可以将保存的状态字典加载到同一类别的模型对象中，以便恢复模型的参数。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = SiRNAModel(...)</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;model.pth&#x27;</span>))</span><br></pre></td></tr></table></figure><p>通过<code>state_dict()</code>和<code>load_state_dict()</code>方法，可以方便地保存和加载模型的参数状态，以便进行模型的训练和推理。这些方法在迁移学习、继续训练以及模型部署等场景中常见。</p><h2 id="如何将序列转换成张量输入到模型里"><a href="#如何将序列转换成张量输入到模型里" class="headerlink" title="如何将序列转换成张量输入到模型里"></a>如何将序列转换成张量输入到模型里</h2><blockquote><p>关键代码是在<code>forward()</code>方法<br>方法: <code>forward(self, x)</code><br>参数: x (List[Tensor]): 输入序列列表</p></blockquote><p>   发现输入的是这个x，x又是输入的序列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> inputs,target <span class="keyword">in</span> train_loader:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;len(inputs):\n &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(inputs)))</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;inputs[0].shape:\n &#123;0&#125; &quot;</span>.<span class="built_in">format</span>(inputs[<span class="number">0</span>].shape))</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;intputs[0][0]:\n &#123;0&#125; &quot;</span>.<span class="built_in">format</span>(inputs[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;traget.shape:\n &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(target.shape))</span><br><span class="line">  <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p><img src="/img/downloaded/aHR0cHM6_91e9abd4fcdb4caa81d99e2e2132da2f.png" alt="在这里插入图片描述"><br>在处理siRNA序列数据时，我们首先注意到输入数据inputs包含两个元素，每个元素的尺寸为64×25。<br>这里的64表示批量处理的大小，而25代表每个序列的长度。通过观察inputs[0][0]，我们可以了解到siRNA的反义链序列（siRNA_antisense_seq）在经过向量化处理后的表现。在这里，<strong>序列的前7位是非零值，这些非零值代表了序列编码中每个字符的唯一标识符。</strong></p><blockquote><p>在这个模型的嵌入层初始化时我们做了这样一个操作，<br><img src="/img/downloaded/aHR0cHM6_965bd3ff86014a3986bcb223777759b1.png" alt="在这里插入图片描述"><br>其中<br><strong>vocab_size表示词汇表的大小<br>embed_dim表示嵌入向量的维度<br>padding_idx&#x3D;0表示对应的填充符号的索引。</strong></p></blockquote><p>为了使RNN模型能够有效处理这些数据，需要保证每个输入样本的长度一致，在创建模型时采取了<strong>填充（padding）策略</strong>（上方引用）。<br><strong>如果某个序列编码后的长度小于最大长度，我们会在其后补零，以确保所有序列在输入到RNN模型时具有统一的长度</strong>。<br>这里把所有序列都被填充至25位，来满足模型的输入要求。</p><h2 id="如何为siRNA序列分配唯一标识符"><a href="#如何为siRNA序列分配唯一标识符" class="headerlink" title="如何为siRNA序列分配唯一标识符"></a>如何为siRNA序列分配唯一标识符</h2><h3 id="首先进行分词处理"><a href="#首先进行分词处理" class="headerlink" title="首先进行分词处理"></a>首先进行分词处理</h3><h4 id="对于未格式化的siRNA-antisense-seq等序列"><a href="#对于未格式化的siRNA-antisense-seq等序列" class="headerlink" title="对于未格式化的siRNA_antisense_seq等序列"></a>对于未格式化的siRNA_antisense_seq等序列</h4><blockquote><p>使用GenomicTokenizer实现</p></blockquote><p>siRNA_antisense_seq序列通过每3个核苷酸一组划分，使用GenomicTokenizer实现，其中ngram和stride均设为3。</p><p>例如序列”AGCCGAGAU”，分词后得到[“AGC”, “CGA”, “GAU”]。</p><h4 id="对于格式化的modified-siRNA-antisense-seq-list等序列"><a href="#对于格式化的modified-siRNA-antisense-seq-list等序列" class="headerlink" title="对于格式化的modified_siRNA_antisense_seq_list等序列"></a>对于格式化的modified_siRNA_antisense_seq_list等序列</h4><blockquote><p>modified_siRNA_antisense_seq_list序列根据空格已分词。</p></blockquote><h3 id="基于数据集中所有token构建词汇表。"><a href="#基于数据集中所有token构建词汇表。" class="headerlink" title="基于数据集中所有token构建词汇表。"></a>基于数据集中所有token构建词汇表。</h3><blockquote><p>该词汇表映射token至唯一标识符，即索引。映射过程确保RNN模型接收数值形式输入，同时学习序列中不同token间关系。</p></blockquote><p>使用<code>GenomicVocab.create</code>方法基于<code>tokens</code>创建基因词汇表。</p><h3 id="创建基因词汇表代码"><a href="#创建基因词汇表代码" class="headerlink" title="创建基因词汇表代码"></a>创建基因词汇表代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建分词器</span></span><br><span class="line">```python</span><br><span class="line">tokenizer = GenomicTokenizer(ngram=<span class="number">3</span>, stride=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建词汇表</span></span><br><span class="line">all_tokens = []  <span class="comment"># 用于存储所有的tokens</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:  <span class="comment"># 遍历每一列</span></span><br><span class="line">    <span class="keyword">for</span> seq <span class="keyword">in</span> train_data[col]:  <span class="comment"># 遍历每个序列</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">in</span> seq:  <span class="comment"># 如果序列中包含空格，则说明是修改过的序列</span></span><br><span class="line">            all_tokens.extend(seq.split())  <span class="comment"># 将序列按空格进行切分，并添加到all_tokens中</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 如果序列中不包含空格，则使用tokenizer对序列进行分词</span></span><br><span class="line">            all_tokens.extend(tokenizer.tokenize(seq))  <span class="comment"># 将分词后的结果添加到all_tokens中</span></span><br><span class="line"></span><br><span class="line">vocab = GenomicVocab.create(all_tokens, max_vocab=<span class="number">10000</span>, min_freq=<span class="number">1</span>)  <span class="comment"># 使用all_tokens创建基因词汇表，设定最大词汇量为10000，词频阈值为1</span></span><br></pre></td></tr></table></figure><ol><li>先创建一个<code>GenomicTokenizer</code>对象，用于对序列进行分词。</li><li>然后遍历数据集中的每个序列，如果序列中包含空格，则说明是修改过的序列，直接按空格切分并添加到<code>all_tokens</code>中；</li><li>如果序列中不包含空格，则使用分词器<code>tokenizer</code>对序列进行分词，并将结果添加到<code>all_tokens</code>中。</li><li>最后使用<code>GenomicVocab.create</code>方法基于<code>all_tokens</code>创建基因词汇表，设定最大词汇量为10000，词频阈值为1。</li></ol><h4 id="来获得序列的最大长度"><a href="#来获得序列的最大长度" class="headerlink" title="来获得序列的最大长度"></a>来获得序列的最大长度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于计算训练数据中每列数据最大长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先使用嵌套的生成器表达式，遍历训练数据中的每一列</span></span><br><span class="line"><span class="comment"># 在内部生成器中，首先检查当前列的每个样本，判断是否包含空格</span></span><br><span class="line"><span class="comment"># 如果包含空格，则使用split()方法将字符串拆分成单词，并返回拆分后的单词个数</span></span><br><span class="line"><span class="comment"># 如果不包含空格，则使用tokenizer.tokenize()将字符串拆分成单词，并返回拆分后的单词个数</span></span><br><span class="line"><span class="comment"># 通过max函数将每列中的最大长度取出，并使用嵌套的生成器表达式再次计算所有列中的最大长度</span></span><br><span class="line">max_len = <span class="built_in">max</span>(</span><br><span class="line">    <span class="built_in">max</span>(</span><br><span class="line">        <span class="built_in">len</span>(seq.split()) <span class="keyword">if</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">in</span> seq <span class="keyword">else</span> <span class="built_in">len</span>(tokenizer.tokenize(seq))</span><br><span class="line">        <span class="keyword">for</span> seq <span class="keyword">in</span> train_data[col]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> columns</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="SiRNADataset类"><a href="#SiRNADataset类" class="headerlink" title="SiRNADataset类"></a>SiRNADataset类</h3><blockquote><p>完成上面的操作之后，在loader获取样本的时候把token转为索引，即我们通过转换成SiRNADataset类的过程中，让数据转换成索引</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SiRNADataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, df, columns, vocab, tokenizer, max_len, is_test=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化SiRNADataset类</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">        - df：包含数据的DataFrame</span></span><br><span class="line"><span class="string">        - columns：包含序列的列名</span></span><br><span class="line"><span class="string">        - vocab：词汇表</span></span><br><span class="line"><span class="string">        - tokenizer：分词器</span></span><br><span class="line"><span class="string">        - max_len：最大序列长度</span></span><br><span class="line"><span class="string">        - is_test：指示是否是测试集</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.df = df  <span class="comment"># 数据框</span></span><br><span class="line">        <span class="variable language_">self</span>.columns = columns  <span class="comment"># 包含序列的列名</span></span><br><span class="line">        <span class="variable language_">self</span>.vocab = vocab  <span class="comment"># 词汇表</span></span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = tokenizer  <span class="comment"># 分词器</span></span><br><span class="line">        <span class="variable language_">self</span>.max_len = max_len  <span class="comment"># 最大序列长度</span></span><br><span class="line">        <span class="variable language_">self</span>.is_test = is_test  <span class="comment"># 指示是否是测试集</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        获取数据集的长度</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回值：</span></span><br><span class="line"><span class="string">        - 数据集的长度</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.df)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        获取数据集中的第idx个样本</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">        - idx：样本索引</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回值：</span></span><br><span class="line"><span class="string">        - 如果是测试集模式，返回编码后的序列</span></span><br><span class="line"><span class="string">        - 如果是训练集模式，返回编码后的序列和对应的目标值</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        row = <span class="variable language_">self</span>.df.iloc[idx]  <span class="comment"># 获取第idx行数据</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对每一列进行分词和编码</span></span><br><span class="line">        seqs = [<span class="variable language_">self</span>.tokenize_and_encode(row[col]) <span class="keyword">for</span> col <span class="keyword">in</span> <span class="variable language_">self</span>.columns]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_test:</span><br><span class="line">            <span class="comment"># 仅返回编码后的序列（测试集模式）</span></span><br><span class="line">            <span class="keyword">return</span> seqs</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 获取目标值并转换为张量（训练集模式）</span></span><br><span class="line">            target = torch.tensor(row[<span class="string">&#x27;mRNA_remaining_pct&#x27;</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            <span class="comment"># 返回编码后的序列和目标值</span></span><br><span class="line">            <span class="keyword">return</span> seqs, target</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tokenize_and_encode</span>(<span class="params">self, seq</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对序列进行分词和编码</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">        - seq：输入的序列</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回值：</span></span><br><span class="line"><span class="string">        - 编码后的序列</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">in</span> seq:</span><br><span class="line">            <span class="comment"># 修改过的序列，按空格分词</span></span><br><span class="line">            tokens = seq.split()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 常规序列，使用分词器分词</span></span><br><span class="line">            tokens = <span class="variable language_">self</span>.tokenizer.tokenize(seq)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将token转换为索引，未知token使用0（&lt;pad&gt;）</span></span><br><span class="line">        encoded = [<span class="variable language_">self</span>.vocab.stoi.get(token, <span class="number">0</span>) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]</span><br><span class="line">        <span class="comment"># 将序列填充到最大长度</span></span><br><span class="line">        padded = encoded + [<span class="number">0</span>] * (<span class="variable language_">self</span>.max_len - <span class="built_in">len</span>(encoded))</span><br><span class="line">        <span class="comment"># 返回张量格式的序列</span></span><br><span class="line">        <span class="keyword">return</span> torch.tensor(padded[:<span class="variable language_">self</span>.max_len], dtype=torch.long)</span><br></pre></td></tr></table></figure><p>这个类继承自<strong>PyTorch的Dataset类</strong>，用于加载数据并将其传递给模型进行训练或预测。</p><p>在<code>__getitem__</code>方法中，根据索引idx获取对应的数据行。然后<strong>针对每个包含序列的列，调用<code>tokenize_and_encode</code>方法对序列进行分词和编码。</strong> 如果是测试集模式，直接返回编码后的序列；如果是训练集模式，还需获取目标值并将其转换为张量。然后，<code>tokenize_and_encode</code>方法用于对序列进行分词和编码。<strong>对于常规序列，使用传入的分词器对其进行分词；对于修改过的序列，直接按空格进行分词。然后将分词后的token转换为词汇表中的索引，未知token使用索引0表示。最后将序列填充到最大长度，并返回张量格式的序列。</strong></p><h4 id="Dataset类"><a href="#Dataset类" class="headerlink" title="Dataset类"></a>Dataset类</h4><blockquote><p>它是一个数据集的抽象接口，可以根据需要自定义数据集的读取和处理方式。</p></blockquote><p>在<strong>使用PyTorch进行训练和预测</strong>时，需要将<strong>数据加载到Dataset对象中</strong>，并<strong>通过DataLoader对象对数据进行批处理和数据加载</strong>。<br><strong>通过继承Dataset类，我们可以自定义数据集的处理逻辑，包括数据读取、数据预处理、数据转换等。</strong></p><p>我们需要实现__len__和__getitem__方法，分别用于获取数据集的长度和获取指定索引位置的样本。</p><p><strong>可以自定义Dataset类来灵活地处理不同类型的数据集，并将其传递给模型进行训练或预测。</strong></p><p>关于训练的模型前面在<code>SiRNAModel 类</code>时讲过，就不再重述</p><p>我们首先进行索引嵌入处理，即<strong>将离散的符号（例如单词、字符或基因序列片段）转换成连续的向量形式</strong>。过程中涉及<strong>将高维的稀疏表示（如独热编码）转换为低维的密集向量</strong>，以使得<strong>语义相近的符号在向量空间中的相对位置更接近</strong>。<br>转换后，嵌入向量的维度将从BatchSize * Length扩展为BatchSize * Length * EmbeddingSize，其中EmbeddingSize，也就是嵌入维度embed_dim，被设定为200。</p><h3 id="RNN（递归神经网络）知识点"><a href="#RNN（递归神经网络）知识点" class="headerlink" title="RNN（递归神经网络）知识点"></a>RNN（递归神经网络）知识点</h3><blockquote><p>一种专门用于处理序列数据的神经网络模型。<br>与传统的前馈神经网络不同，RNN具有反馈连接，可以将前面的输出作为后续输入的一部分，使其具有记忆性。</p></blockquote><p>RNN的基本结构是一个单元（cell）或节点，其中包含一个输入层、一个隐藏层和一个输出层。隐藏层中的神经元通过时间反馈连接，使得信息可以在不同时间步之间传递和共享。这种结构使得RNN能够处理任意长度的序列数据，并且能够捕捉到序列中的上下文信息。</p><blockquote><p>RNN的架构示意图<br><img src="/img/downloaded/aHR0cHM6_f48dc300b4e84e29aa59b0553582be4d.png" alt="在这里插入图片描述"><br>RNN，即循环神经网络（Recurrent Neural Network），是一种适合于序列数据的深度学习模型。它与传统的前馈神经网络（如多层感知机）不同，RNN 能够处理序列中的动态特征，即能够捕捉时间序列中的动态依赖关系。</p></blockquote><p>RNN的数学表达可以简化为以下形式：<br>$$<br> h_t &#x3D; f(W_{hh} h_{t-1} + W_{xh} x_t + b_h)<br>$$<br>$$<br>y_t &#x3D; f(W_{hy} h_t + b_y)<br>$$</p><p>其中，<br>$h_t$是时间步$t$的隐藏状态。<br>$x_t$是时间步$t$的输入向量。<br>$W_{hh}$和$W_{xh}$分别是从上一个时间步的隐藏状态到当前隐藏状态、从当前时间步的输入到当前隐藏状态的权重矩阵。<br>$b_h$是隐藏层的偏置项。<br>$W_{hy}$是从隐藏状态到输出的权重矩阵。<br>$b_y$是输出层的偏置项。<br>$f$是激活函数。</p><h4 id="RNN的训练过程"><a href="#RNN的训练过程" class="headerlink" title="RNN的训练过程"></a>RNN的训练过程</h4><p>在RNN中，<strong>每个时间步都有一个输入和一个输出</strong>。输入可以是任意维度的向量，而输出通常是一个固定大小的向量或者是一个标量。RNN通过学习一组可学习的权重参数来对输入序列进行处理，并输出相应的预测结果。</p><p><strong>RNN的训练过程通常是使用反向传播算法来优化模型的权重参数。</strong> 由于反向传播算法的梯度消失问题，在处理长序列时RNN往往会出现难以学习到长期依赖关系的情况。为了解决这个问题，一种<strong>常用的改进版本是长短期记忆网络（LSTM）和门控循环单元（GRU），它们能够更有效地捕捉和利用序列中的长期依赖关系。</strong> </p><h4 id="RNN-的特点"><a href="#RNN-的特点" class="headerlink" title="RNN 的特点"></a>RNN 的特点</h4><ul><li><strong>循环连接</strong>：RNN的每个神经元不仅与下一层的神经元相连，而且与同一层的下一个时间步的神经元相连，形成了一个循环结构。    </li><li><strong>时间步</strong>：RNN在序列的每个时间步上都会进行计算，每个时间步的输出不仅依赖于当前的输入，还依赖于前一个时间步的输出。</li><li><strong>隐藏状态</strong>：RNN通过隐藏状态（hidden state）来传递之前时间步的信息。隐藏状态可以看作是网络对之前序列信息的总结。  </li><li><strong>参数共享</strong>：在RNN中，同一网络参数在每个时间步上都会被重复使用，这简化了模型结构，但同时也带来了一些挑战，如梯度消失或梯度爆炸问题。</li><li><strong>长短期记忆（LSTM）和门控循环单元（GRU）</strong>：这两种网络结构是对传统RNN的改进，它们通过引入门控机制来解决梯度消失问题，使得网络能够学习长期依赖关系。</li><li><strong>应用领域</strong>：RNN广泛应用于自然语言处理（NLP）、语音识别、时间序列预测等领域，特别是在需要处理序列数据和捕捉时间依赖性的任务中。</li><li><strong>训练挑战</strong>：RNN的训练可能面临梯度消失或梯度爆炸的问题，这使得训练过程可能不稳定。现代优化技术如梯度裁剪或使用更高级的优化器（如Adam）可以帮助缓解这些问题。</li><li><strong>变长序列处理</strong>：RNN能够处理不同长度的序列，但需要通过填充（padding）或截断来保证输入序列具有相同的长度。</li></ul><h2 id="数据的特征工程-（EDA）"><a href="#数据的特征工程-（EDA）" class="headerlink" title="数据的特征工程 （EDA）"></a>数据的特征工程 （EDA）</h2><p>在官方baseline中，得分较低可能是由于数据特征简单、序列特征构造粗糙以及数据量不足等原因。为了解决序列特征问题，可以将其转化为表格问题并进行特征工程。</p><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><h4 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h4><p>检查数据是否存在缺失值，并根据具体情况决定如何处理缺失值，如删除、填充等。</p><h4 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h4><p>检测和处理数据中的异常值，包括通过可视化和统计学方法识别异常值，并根据业务逻辑进行处理。</p><h3 id="处理类别型变量"><a href="#处理类别型变量" class="headerlink" title="处理类别型变量"></a>处理类别型变量</h3><h4 id="统计唯一值"><a href="#统计唯一值" class="headerlink" title="统计唯一值"></a>统计唯一值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.gene_target_symbol_name.nunique()</span><br></pre></td></tr></table></figure><blockquote><p>计算DataFrame（df）中某一列（gene_target_symbol_name）中唯一值（unique value）的数量（nunique）。也就是统计该列中有多少不重复的值。</p></blockquote><h5 id="nunique"><a href="#nunique" class="headerlink" title="nunique()"></a><code>nunique()</code></h5><p><code>nunique()</code>函数是<strong>pandas库</strong>中的一个方法，用于<strong>计算一个序列（Series）或数据框（DataFrame）中唯一值的数量</strong>。<br>语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Series.nunique(dropna=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line"></span><br><span class="line">DataFrame.nunique(axis=<span class="number">0</span>, dropna=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li><code>dropna</code>：是否排除缺失值，默认为True，即排除缺失值。</li><li><code>axis</code>：对于数据框，可以指定按行（axis&#x3D;0）或按列（axis&#x3D;1）计算唯一值的数量。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">data = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">unique_count = data.nunique()</span><br><span class="line"><span class="built_in">print</span>(unique_count)  <span class="comment"># 输出：5</span></span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;B&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">unique_count_col = df.nunique(axis=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(unique_count_col)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="comment"># A    3</span></span><br><span class="line"><span class="comment"># B    2</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure><h3 id="统计每个值的频率分布"><a href="#统计每个值的频率分布" class="headerlink" title="统计每个值的频率分布"></a>统计每个值的频率分布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.gene_target_symbol_name.value_counts()</span><br></pre></td></tr></table></figure><blockquote><p>这段代码是用来计算DataFrame（df）中某一列（gene_target_symbol_name）中每个唯一值（unique value）出现的次数（count）。它会返回一个Series对象，其中索引是唯一值，值是对应唯一值的出现次数。通过这个可以快速了解该列中每个值的频率分布。</p></blockquote><h4 id="value-counts"><a href="#value-counts" class="headerlink" title="value_counts()"></a><code>value_counts()</code></h4><p><code>value_counts()</code>函数是<strong>pandas库</strong>中的一个方法，用于<strong>计算一个序列（Series）中每个唯一值的数量。</strong></p><p>语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Series.value_counts(normalize=<span class="literal">False</span>, sort=<span class="literal">True</span>, ascending=<span class="literal">False</span>, bins=<span class="literal">None</span>, dropna=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li><code>normalize</code>：是否返回相对频率，默认为False，即返回唯一值的数量。</li><li><code>sort</code>：是否按值进行排序，默认为True，即按值进行排序。</li><li><code>ascending</code>：是否按升序排列，默认为False，即按降序排列。</li><li><code>bins</code>：指定柱状图的箱数。</li><li><code>dropna</code>：是否排除缺失值，默认为True，即排除缺失值。</li></ul><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">value_count = data.value_counts()</span><br><span class="line"><span class="built_in">print</span>(value_count)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="comment"># 2    3</span></span><br><span class="line"><span class="comment"># 1    2</span></span><br><span class="line"><span class="comment"># 3    2</span></span><br><span class="line"><span class="comment"># 5    1</span></span><br><span class="line"><span class="comment"># 4    1</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure><p>以上<code>value_counts()</code>方法计算了序列<code>data</code>中每个唯一值出现的次数，按降序排列输出。</p><h3 id="one-hot特征的构造"><a href="#one-hot特征的构造" class="headerlink" title="one-hot特征的构造"></a>one-hot特征的构造</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果有40个类别，那么会产生40列，如果第i行属于第j个类别，那么第j列第i行就是1，否则为0</span></span><br><span class="line"></span><br><span class="line">df_gene_target_symbol_name = pd.get_dummies(df.gene_target_symbol_name)</span><br><span class="line">df_gene_target_symbol_name.columns = [</span><br><span class="line">    <span class="string">f&quot;feat_gene_target_symbol_name_<span class="subst">&#123;c&#125;</span>&quot;</span> <span class="keyword">for</span> c <span class="keyword">in</span> df_gene_target_symbol_name.columns</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h3 id="时间特征构造"><a href="#时间特征构造" class="headerlink" title="时间特征构造"></a>时间特征构造</h3><blockquote><p>有可能<br>没看出来，啃臭cv一份，很妙</p></blockquote><p>在数据观察的时候发现，siRNA_duplex_id的编码方式很有意思，其格式为AD-1810676.1，我们猜测AD是某个类别，后面的.1是版本，当中的可能是按照一定顺序的序列号，因此可以构造如下特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">siRNA_duplex_id_values = df.siRNA_duplex_id.<span class="built_in">str</span>.split(<span class="string">&quot;-|\.&quot;</span>).<span class="built_in">str</span>[<span class="number">1</span>].astype(<span class="string">&quot;int&quot;</span>)</span><br></pre></td></tr></table></figure><p>这段代码是从siRNA_duplex_id列中提取出按照一定顺序的序列号作为新的特征siRNA_duplex_id_values。<br>siRNA_duplex_id的编码格式为”AD-1810676.1”，<strong>其中”AD”表示某个类别，”.1”表示版本号，而中间的数字则是按照顺序的序列号。(假定，大概率)</strong><br>代码通过使用正则表达式分隔符”-“和”.”，将siRNA_duplex_id拆分成多个部分，然后取第二部分（索引为1），并将其转换为整数类型。得到的siRNA_duplex_id_values列即为按照一定顺序的序列号特征。</p><h4 id="上述对每一个siRNA-duplex-id的过程同下"><a href="#上述对每一个siRNA-duplex-id的过程同下" class="headerlink" title="上述对每一个siRNA_duplex_id的过程同下"></a>上述对每一个siRNA_duplex_id的过程同下</h4><p>(方便复制)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="built_in">str</span> = <span class="string">&quot;AD-1810676.1&quot;</span></span><br><span class="line"><span class="comment"># 使用正则表达式分割字符串</span></span><br><span class="line">parts = re.split(<span class="string">r&#x27;[-.]&#x27;</span>, <span class="built_in">str</span>)</span><br><span class="line"><span class="comment"># 将数字部分转换为NumPy数组，并转换为整数类型</span></span><br><span class="line">numbers = np.array(parts[<span class="number">1</span>], dtype=<span class="built_in">int</span>)</span><br><span class="line"><span class="built_in">print</span>(numbers)</span><br></pre></td></tr></table></figure><p><img src="/img/downloaded/aHR0cHM6_578501e1ade440e8834f6f880cf4748d.png" alt="在这里插入图片描述"></p><h3 id="包含某些单词"><a href="#包含某些单词" class="headerlink" title="包含某些单词"></a>包含某些单词</h3><h4 id="对df中的cell-line-donor列构造特征"><a href="#对df中的cell-line-donor列构造特征" class="headerlink" title="对df中的cell_line_donor列构造特征"></a>对df中的<code>cell_line_donor</code>列构造特征</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 对cell_line_donor列进行独热编码</span></span><br><span class="line">df_cell_line_donor = pd.get_dummies(df.cell_line_donor)</span><br><span class="line"><span class="comment"># 为独热编码后的列名添加前缀</span></span><br><span class="line">df_cell_line_donor.columns = [</span><br><span class="line">    <span class="string">f&quot;feat_cell_line_donor_<span class="subst">&#123;c&#125;</span>&quot;</span> <span class="keyword">for</span> c <span class="keyword">in</span> df_cell_line_donor.columns</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建新的特征列feat_cell_line_donor_hepatocytes，值为cell_line_donor列是否包含&quot;Hepatocytes&quot;的布尔值转换为整数</span></span><br><span class="line">df_cell_line_donor[<span class="string">&quot;feat_cell_line_donor_hepatocytes&quot;</span>] = (</span><br><span class="line">    (df.cell_line_donor.<span class="built_in">str</span>.contains(<span class="string">&quot;Hepatocytes&quot;</span>)).fillna(<span class="literal">False</span>).astype(<span class="string">&quot;int&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建新的特征列feat_cell_line_donor_cells，值为cell_line_donor列是否包含&quot;Cells&quot;的布尔值转换为整数</span></span><br><span class="line">df_cell_line_donor[<span class="string">&quot;feat_cell_line_donor_cells&quot;</span>] = (</span><br><span class="line">    df.cell_line_donor.<span class="built_in">str</span>.contains(<span class="string">&quot;Cells&quot;</span>).fillna(<span class="literal">False</span>).astype(<span class="string">&quot;int&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="代码小结"><a href="#代码小结" class="headerlink" title="代码小结"></a>代码小结</h5><ol><li><strong>使用 <code>pd.get_dummies()</code> 函数对 <code>cell_line_donor</code> 列进行独热编码，</strong>  编码后的列会根据不同的取值创建新的列。</li><li><strong>使用列表推导式为 <code>df_cell_line_donor</code> 的列名添加前缀 “feat_cell_line_donor_”。</strong></li><li>创建新的特征列 <code>feat_cell_line_donor_hepatocytes</code>，<strong>根据 <code>cell_line_donor</code> 列是否包含 “Hepatocytes”</strong> ，将布尔值转换为整数（1 表示包含，0 表示不包含）。</li><li>创建新的特征列 <code>feat_cell_line_donor_cells</code>，<strong>根据 <code>cell_line_donor</code> 列是否包含 “Cells” 来确定的</strong>，将布尔值转换为整数（1 表示包含，0 表示不包含）。</li></ol><p>将 <code>cell_line_donor</code> 列转换为独热编码，并创建两个新的特征列，用于表示是否包含特定的关键词。</p><h3 id="对碱基的模式进行特征构造"><a href="#对碱基的模式进行特征构造" class="headerlink" title="对碱基的模式进行特征构造"></a>对碱基的模式进行特征构造</h3><h4 id="根据上一个task中的rna知识提取"><a href="#根据上一个task中的rna知识提取" class="headerlink" title="根据上一个task中的rna知识提取"></a>根据上一个task中的rna知识提取</h4><blockquote><p><img src="/img/downloaded/aHR0cHM6_ea0117b0c9ba4164bcf2c176b69dd5a1.png" alt="在这里插入图片描述"></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">siRNA_feat_builder</span>(<span class="params">s: pd.Series, anti: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    构建siRNA特征的函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    s: pd.Series -- 输入的siRNA序列</span></span><br><span class="line"><span class="string">    anti: bool -- 是否构建反义链特征，默认为False</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    pd.DataFrame -- 构建的siRNA特征DataFrame</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    name = <span class="string">&quot;anti&quot;</span> <span class="keyword">if</span> anti <span class="keyword">else</span> <span class="string">&quot;sense&quot;</span>  <span class="comment"># 根据 anti 的值确定特征名称前缀</span></span><br><span class="line">    df = s.to_frame()  <span class="comment"># 将输入的 Series 对象转换为 DataFrame 对象</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_len&quot;</span>] = s.<span class="built_in">str</span>.<span class="built_in">len</span>()  <span class="comment"># 计算序列长度，并将其作为特征添加到 DataFrame 中</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历两个位置：第一个和最后一个</span></span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> [<span class="number">0</span>, -<span class="number">1</span>]:</span><br><span class="line">        <span class="comment"># 遍历碱基：A、U、G、C</span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">list</span>(<span class="string">&quot;AUGC&quot;</span>):</span><br><span class="line">            <span class="comment"># 判断序列的第一个或最后一个碱基是否与当前碱基相等，并将结果作为特征添加到 DataFrame 中</span></span><br><span class="line">            df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_<span class="subst">&#123;c&#125;</span>_<span class="subst">&#123;<span class="string">&#x27;front&#x27;</span> <span class="keyword">if</span> pos == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;back&#x27;</span>&#125;</span>&quot;</span>] = (</span><br><span class="line">                s.<span class="built_in">str</span>[pos] == c</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断序列是否以特定的模式开头和结尾，并将结果作为特征添加到 DataFrame 中</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_1&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;AA&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UU&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_2&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;GA&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UU&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_3&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;CA&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UU&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_4&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UA&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UU&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_5&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UU&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;AA&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_6&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UU&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;GA&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_7&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UU&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;CA&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_8&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UU&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UA&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断序列的第二位和倒数第二位是否为 A，并将结果作为特征添加到 DataFrame 中</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_9&quot;</span>] = s.<span class="built_in">str</span>[<span class="number">1</span>] == <span class="string">&quot;A&quot;</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_10&quot;</span>] = s.<span class="built_in">str</span>[-<span class="number">2</span>] == <span class="string">&quot;A&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算序列中的 GC 碱基占整体长度的比例，并将结果作为特征添加到 DataFrame 中</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_GC_frac&quot;</span>] = (</span><br><span class="line">        s.<span class="built_in">str</span>.count(<span class="string">&quot;G&quot;</span>) + s.<span class="built_in">str</span>.count(<span class="string">&quot;C&quot;</span>)</span><br><span class="line">    ) / s.<span class="built_in">str</span>.<span class="built_in">len</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df.iloc[:, <span class="number">1</span>:]  <span class="comment"># 返回除第一列外的所有列，即去掉序列本身的列</span></span><br></pre></td></tr></table></figure><h5 id="代码小结-1"><a href="#代码小结-1" class="headerlink" title="代码小结"></a>代码小结</h5><ol><li>“feat_siRNA_{name}_seq_len”：siRNA序列的长度作为特征。</li><li>siRNA序列的第一个和最后一个位置，在前端或后端：<ul><li>“feat_siRNA_{name}<em>seq</em>{c}_{‘front’ if pos &#x3D;&#x3D; 0 else ‘back’}”：判断序列的第一个或最后一个碱基是否与’A’, ‘U’, ‘G’, ‘C’相等。</li></ul></li><li>siRNA序列的起始和结束：<ul><li>“feat_siRNA_{name}<em>seq_pattern_1”，…，”feat_siRNA</em>{name}_seq_pattern_8”：判断序列是否以特定的模式开头和结尾。</li></ul></li><li>siRNA序列的第二位和倒数第二位：<ul><li>“feat_siRNA_{name}_seq_pattern_9”：判断序列的第二位是否为’A’。</li><li>“feat_siRNA_{name}_seq_pattern_10”：判断序列的倒数第二位是否为’A’。</li></ul></li><li>“feat_siRNA_{name}_seq_pattern_GC_frac”：计算序列中的GC碱基占整体长度的比例。</li></ol><h2 id="最后选择模型预测"><a href="#最后选择模型预测" class="headerlink" title="最后选择模型预测"></a>最后选择模型预测</h2><blockquote><p>这里是task2给出的lightgbm的代码来对特征值预测 引一份</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">train_data = lgb.Dataset(X_train, label=y_train)  <span class="comment"># 创建训练数据集，X_train为特征矩阵，y_train为标签向量</span></span><br><span class="line">test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)  <span class="comment"># 创建测试数据集，并引用训练数据集</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_validation_result</span>(<span class="params">env</span>):</span><br><span class="line">    result = env.evaluation_result_list[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;env.iteration&#125;</span>] <span class="subst">&#123;result[<span class="number">1</span>]&#125;</span>&#x27;s <span class="subst">&#123;result[<span class="number">0</span>]&#125;</span>: <span class="subst">&#123;result[<span class="number">2</span>]&#125;</span>&quot;</span>)  <span class="comment"># 打印验证结果的回调函数，用于输出每次迭代后的验证结果</span></span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&quot;boosting_type&quot;</span>: <span class="string">&quot;gbdt&quot;</span>,  <span class="comment"># 梯度提升树类型，可选&quot;gbdt&quot;、&quot;dart&quot;、&quot;goss&quot;</span></span><br><span class="line">    <span class="string">&quot;objective&quot;</span>: <span class="string">&quot;regression&quot;</span>,  <span class="comment"># 模型优化目标，回归任务一般选择&quot;regression&quot;</span></span><br><span class="line">    <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;root_mean_squared_error&quot;</span>,  <span class="comment"># 评估指标，回归任务一般选择&quot;root_mean_squared_error&quot;（均方根误差）</span></span><br><span class="line">    <span class="string">&quot;max_depth&quot;</span>: <span class="number">7</span>,  <span class="comment"># 每棵树的最大深度，控制模型的复杂度</span></span><br><span class="line">    <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.02</span>,  <span class="comment"># 学习率，控制每个树的贡献</span></span><br><span class="line">    <span class="string">&quot;verbose&quot;</span>: <span class="number">0</span>,  <span class="comment"># 控制训练过程中的输出，设置为非零值可输出训练信息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gbm = lgb.train(</span><br><span class="line">    params,  <span class="comment"># 参数字典，包含模型训练所需的参数</span></span><br><span class="line">    train_data,  <span class="comment"># 训练数据集</span></span><br><span class="line">    num_boost_round=<span class="number">15000</span>,  <span class="comment"># 迭代次数，指定生成的树的数量</span></span><br><span class="line">    valid_sets=[test_data],  <span class="comment"># 用于验证模型的数据集，可以根据需要指定多个</span></span><br><span class="line">    callbacks=[print_validation_result],  <span class="comment"># 在训练过程中执行的回调函数，可用于打印验证结果、保存模型等</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="分数"><a href="#分数" class="headerlink" title="分数"></a>分数</h3><p><img src="/img/downloaded/aHR0cHM6_63cbb25b5cf54def8d7291c17327172b.png" alt="在这里插入图片描述"></p><h3 id="一些常用的LightGBM参数"><a href="#一些常用的LightGBM参数" class="headerlink" title="一些常用的LightGBM参数"></a>一些常用的LightGBM参数</h3><p>LightGBM是一种梯度提升树模型。</p><h4 id="boosting-type"><a href="#boosting-type" class="headerlink" title="boosting_type"></a><code>boosting_type</code></h4><blockquote><p>指定梯度提升树的类型</p></blockquote><p>有<code>gbdt</code>（传统的梯度提升决策树）、<code>dart</code>（dropout加速梯度提升树）和<code>goss</code>（梯度优化送出采样）。</p><h4 id="objective"><a href="#objective" class="headerlink" title="objective"></a><code>objective</code></h4><blockquote><p>指定模型的优化目标，根据任务类型选择合适的目标函数。</p></blockquote><p>回归任务可以使用<code>regression</code>，分类任务可以使用<code>binary</code>或<code>multiclass</code>。</p><h4 id="metric"><a href="#metric" class="headerlink" title="metric"></a><code>metric</code></h4><blockquote><p>指定模型的评估指标，用于衡量模型的性能。</p></blockquote><p>对于回归任务可以使用<code>root_mean_squared_error</code>（均方根误差）。</p><h4 id="max-depth"><a href="#max-depth" class="headerlink" title="max_depth"></a><code>max_depth</code></h4><blockquote><p>每棵树的最大深度，控制模型的复杂度。</p></blockquote><p>较小的值可以防止过拟合，但可能会导致欠拟合。<br><strong>max_depth 一般在 （6，10）</strong></p><h4 id="learning-rate"><a href="#learning-rate" class="headerlink" title="learning_rate"></a><code>learning_rate</code></h4><blockquote><p>学习率控制每个树的贡献。</p></blockquote><p>较小的值会使算法收敛得更慢，但可能会获得更好的精度。</p><h4 id="num-boost-round"><a href="#num-boost-round" class="headerlink" title="num_boost_round"></a><code>num_boost_round</code></h4><blockquote><p>迭代次数，指定生成的树的数量。</p></blockquote><p>较大的值可以提高模型的性能，但也会增加计算时间。</p><h4 id="valid-sets"><a href="#valid-sets" class="headerlink" title="valid_sets"></a><code>valid_sets</code></h4><blockquote><p>用于验证模型的数据集，可以根据需要指定多个。</p></blockquote><p>在训练过程中，模型会根据验证集的性能进行调整。</p><h4 id="callbacks"><a href="#callbacks" class="headerlink" title="callbacks"></a><code>callbacks</code></h4><blockquote><p>在训练过程中执行的回调函数，可以用于打印模型的验证结果、保存模型等。</p></blockquote><blockquote><p>可以通过回调函数自定义返回的东西，如打印测试情况之类的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">callbacks=[print_validation_result]</span><br></pre></td></tr></table></figure><p>这里就是回调时，用了print_validation_result 作为输出<br>输出函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_validation_result</span>(<span class="params">env</span>):</span><br><span class="line">    result = env.evaluation_result_list[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;env.iteration&#125;</span>] <span class="subst">&#123;result[<span class="number">1</span>]&#125;</span>&#x27;s <span class="subst">&#123;result[<span class="number">0</span>]&#125;</span>: <span class="subst">&#123;result[<span class="number">2</span>]&#125;</span>&quot;</span>)  <span class="comment"># 打印验证结果的回调函数，用于输出每次迭代后的验证结果</span></span><br></pre></td></tr></table></figure></blockquote><h4 id="num-leaves"><a href="#num-leaves" class="headerlink" title="num_leaves"></a><code>num_leaves</code></h4><blockquote><p>每棵树的叶子节点数，与<code>max_depth</code>参数一起控制模型的复杂度。</p></blockquote><h4 id="min-data-in-leaf"><a href="#min-data-in-leaf" class="headerlink" title="min_data_in_leaf"></a><code>min_data_in_leaf</code></h4><blockquote><p>叶子节点的最小数据量，用于防止模型在小数据集上过拟合。</p></blockquote><h4 id="subsample"><a href="#subsample" class="headerlink" title="subsample"></a><code>subsample</code></h4><blockquote><p>训练时使用的样本比例，可以用于防止过拟合。</p></blockquote><h4 id="verbose"><a href="#verbose" class="headerlink" title="verbose"></a><code>verbose</code></h4><blockquote><p>是否在训练过程中打印详细的信息。</p></blockquote><h4 id="random-state"><a href="#random-state" class="headerlink" title="random_state"></a><code>random_state</code></h4><blockquote><p>随机数生成器的种子，用于确保结果的可复现性。</p></blockquote><h4 id="device-type"><a href="#device-type" class="headerlink" title="device_type"></a><code>device_type</code></h4><blockquote><p>指定训练时使用的设备类型，如CPU或GPU。<br>一般本地训练需要调整</p></blockquote><p><strong>更多参数还是建议自主参考官方文档</strong><br><a href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">Parameters — LightGBM 4.5.0.99 documentation<br>https://lightgbm.readthedocs.io/en/latest/Parameters.htmll</a></p><p>举例一个其他的模型的训练参数<br><img src="/img/downloaded/aHR0cHM6_06551847b64747f9a13ecbcf6c382bf1.png" alt="在这里插入图片描述"></p><p>根据具体任务和数据的特点，可以尝试不同的参数组合来优化模型性能。</p><blockquote><p>tips : 可以构造更多特征，多模型融合，k折 ，调超参等方法涨点</p></blockquote><p>这里给出一个k折的框架</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="comment"># train函数用于训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">feats, n_original</span>):</span><br><span class="line">    <span class="comment"># 定义k折交叉验证</span></span><br><span class="line">    n_splits = <span class="number">10</span></span><br><span class="line">    kf = KFold(n_splits=n_splits, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    <span class="comment"># 开始k折交叉验证</span></span><br><span class="line">    gbms = []</span><br><span class="line">    <span class="keyword">for</span> fold, (train_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(</span><br><span class="line">        kf.split(feats.iloc[:n_original, :]), <span class="number">1</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="comment"># 准备训练集和验证集</span></span><br><span class="line">        X_train, X_val = feats.iloc[train_idx, :-<span class="number">1</span>], feats.iloc[val_idx, :-<span class="number">1</span>]</span><br><span class="line">        y_train, y_val = feats.iloc[train_idx, -<span class="number">1</span>], feats.iloc[val_idx, -<span class="number">1</span>]</span><br><span class="line">        w_train = weight_ls[train_idx]</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建LightGBM数据集</span></span><br><span class="line">        train_data = lgb.Dataset(X_train, label=y_train, weight=w_train)</span><br><span class="line">        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)</span><br><span class="line"></span><br><span class="line">        boost_round = <span class="number">25000</span></span><br><span class="line">        early_stop_rounds = <span class="built_in">int</span>(boost_round*<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 显示metric</span></span><br><span class="line">        lgb_log = lgb.log_evaluation(period=<span class="number">200</span>, show_stdv=<span class="literal">True</span>)</span><br><span class="line">        lgb_stop = lgb.early_stopping(stopping_rounds=early_stop_rounds, first_metric_only=<span class="literal">True</span>, verbose=<span class="literal">True</span>, min_delta=<span class="number">0.00001</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置LightGBM参数</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&quot;boosting_type&quot;</span>: <span class="string">&quot;gbdt&quot;</span>,</span><br><span class="line">            <span class="string">&quot;objective&quot;</span>: <span class="string">&quot;regression&quot;</span>,</span><br><span class="line">            <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;None&quot;</span>,</span><br><span class="line">            <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;root_mean_squared_error&quot;</span>,</span><br><span class="line">            <span class="string">&quot;max_depth&quot;</span>: <span class="number">8</span>,</span><br><span class="line">            <span class="string">&quot;num_leaves&quot;</span>: <span class="number">63</span>,</span><br><span class="line">            <span class="string">&quot;min_data_in_leaf&quot;</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.05</span>,</span><br><span class="line">            <span class="string">&quot;feature_fraction&quot;</span>: <span class="number">0.9</span>,</span><br><span class="line">            <span class="string">&quot;lambda_l1&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">            <span class="string">&quot;lambda_l2&quot;</span>: <span class="number">0.2</span>,</span><br><span class="line">            <span class="string">&quot;verbose&quot;</span>: -<span class="number">1</span>, <span class="comment"># -1时不输出</span></span><br><span class="line">            <span class="string">&quot;early_stopping_round&quot;</span>: early_stop_rounds,</span><br><span class="line">            <span class="string">&quot;num_threads&quot;</span>: <span class="number">8</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        gbm = lgb.train(</span><br><span class="line">            params,</span><br><span class="line">            train_data,</span><br><span class="line">            num_boost_round=boost_round,</span><br><span class="line">            valid_sets=[val_data],</span><br><span class="line">            feval=calculate_metrics,  <span class="comment"># 将自定义指标函数作为feval参数传入</span></span><br><span class="line">            callbacks=[print_validation_result, lgb_log, lgb_stop],</span><br><span class="line">        )</span><br><span class="line">        valid_score = gbm.best_score[<span class="string">&quot;valid_0&quot;</span>][<span class="string">&quot;custom_score&quot;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;best_valid_score: <span class="subst">&#123;valid_score&#125;</span>&quot;</span>)</span><br><span class="line">        gbms.append(gbm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gbms</span><br></pre></td></tr></table></figure><h3 id="分数-1"><a href="#分数-1" class="headerlink" title="分数"></a>分数</h3><blockquote><p>目前还在冲分，后续补上代码</p></blockquote><p><img src="/img/downloaded/aHR0cHM6_6c52070d6004422e81552c1be0f88c66.png" alt="在这里插入图片描述"></p><h1 id="Task3"><a href="#Task3" class="headerlink" title="Task3"></a>Task3</h1><blockquote><p>特征工程进阶</p></blockquote><h2 id="对task2引入生物知识"><a href="#对task2引入生物知识" class="headerlink" title="对task2引入生物知识"></a>对task2引入生物知识</h2><blockquote><p>引入的长度、GC含量等特征细节刻画</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">siRNA_feat_builder3</span>(<span class="params">s: pd.Series, anti: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    name = <span class="string">&quot;anti&quot;</span> <span class="keyword">if</span> anti <span class="keyword">else</span> <span class="string">&quot;sense&quot;</span></span><br><span class="line">    df = s.to_frame()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 长度分组</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_len21&quot;</span>] = (s.<span class="built_in">str</span>.<span class="built_in">len</span>() == <span class="number">21</span>)</span><br><span class="line">    <span class="comment"># 省略号标识以此类推构造特征</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># GC含量</span></span><br><span class="line">    GC_frac = (s.<span class="built_in">str</span>.count(<span class="string">&quot;G&quot;</span>) + s.<span class="built_in">str</span>.count(<span class="string">&quot;C&quot;</span>))/s.<span class="built_in">str</span>.<span class="built_in">len</span>()</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_GC_in&quot;</span>] = (GC_frac &gt;= <span class="number">0.36</span>) &amp; (GC_frac &lt;= <span class="number">0.52</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 局部GC含量</span></span><br><span class="line">    GC_frac1 = (s.<span class="built_in">str</span>[<span class="number">1</span>:<span class="number">7</span>].<span class="built_in">str</span>.count(<span class="string">&quot;G&quot;</span>) + s.<span class="built_in">str</span>[<span class="number">1</span>:<span class="number">7</span>].<span class="built_in">str</span>.count(<span class="string">&quot;C&quot;</span>))/s.<span class="built_in">str</span>[<span class="number">1</span>:<span class="number">7</span>].<span class="built_in">str</span>.<span class="built_in">len</span>()</span><br><span class="line"></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_GC_in1&quot;</span>] = GC_frac1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df.iloc[:, <span class="number">1</span>:]</span><br></pre></td></tr></table></figure><blockquote><p>代码可以看出，新增有长度分组，GC含量和局部GC含量</p></blockquote><h3 id="修饰siRNA构建特征"><a href="#修饰siRNA构建特征" class="headerlink" title="修饰siRNA构建特征"></a>修饰siRNA构建特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">siRNA_feat_builder3_mod</span>(<span class="params">s: pd.Series, anti: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    name = <span class="string">&quot;anti&quot;</span> <span class="keyword">if</span> anti <span class="keyword">else</span> <span class="string">&quot;sense&quot;</span></span><br><span class="line">    df = s.to_frame()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 修饰RNA的起始、终止位置单元类别</span></span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> [<span class="number">0</span>, -<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> voc_ls:</span><br><span class="line">            ...</span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> [<span class="number">1</span>, -<span class="number">2</span>]:</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> voc_ls:</span><br><span class="line">            ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df.iloc[:, <span class="number">1</span>:]</span><br></pre></td></tr></table></figure><h3 id="修饰siRNA序列进行n-gram的词频统计"><a href="#修饰siRNA序列进行n-gram的词频统计" class="headerlink" title="修饰siRNA序列进行n-gram的词频统计"></a>修饰siRNA序列进行n-gram的词频统计</h3><blockquote><p>同时也可对未修饰序列进行相同的操作</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GenomicTokenizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ngram=<span class="number">5</span>, stride=<span class="number">2</span></span>):</span><br><span class="line">        <span class="comment"># 初始化分词器，设置n-gram长度和步幅</span></span><br><span class="line">        <span class="variable language_">self</span>.ngram = ngram</span><br><span class="line">        <span class="variable language_">self</span>.stride = stride</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">self, t</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 字符串变list</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(t, <span class="built_in">str</span>):</span><br><span class="line">            t = <span class="built_in">list</span>(t)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.ngram == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 如果n-gram长度为1，直接将序列转换为字符列表</span></span><br><span class="line">            toks = t</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 否则，按照步幅对序列进行n-gram分词</span></span><br><span class="line">            toks = [t[i:i+<span class="variable language_">self</span>.ngram] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(t), <span class="variable language_">self</span>.stride) <span class="keyword">if</span> <span class="built_in">len</span>(t[i:i+<span class="variable language_">self</span>.ngram]) == <span class="variable language_">self</span>.ngram]</span><br><span class="line">        </span><br><span class="line">            <span class="comment"># 如果最后一个分词长度小于n-gram，移除最后一个分词</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(toks[-<span class="number">1</span>]) &lt; <span class="variable language_">self</span>.ngram:</span><br><span class="line">                toks = toks[:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># sub list to str</span></span><br><span class="line">            toks = [<span class="string">&#x27;&#x27;</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> toks]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回分词结果</span></span><br><span class="line">        <span class="keyword">return</span> toks</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GenomicVocab</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, itos</span>):</span><br><span class="line">        <span class="comment"># 初始化词汇表，itos是一个词汇表列表</span></span><br><span class="line">        <span class="variable language_">self</span>.itos = itos</span><br><span class="line">        <span class="comment"># 创建从词汇到索引的映射</span></span><br><span class="line">        <span class="variable language_">self</span>.stoi = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.itos)&#125;</span><br><span class="line">        </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create</span>(<span class="params">cls, tokens, max_vocab, min_freq</span>):</span><br><span class="line">        <span class="comment"># 创建词汇表类方法</span></span><br><span class="line">        <span class="comment"># 统计每个token出现的频率</span></span><br><span class="line">        freq = Counter(tokens)</span><br><span class="line">        <span class="comment"># 选择出现频率大于等于min_freq的token，并且最多保留max_vocab个token</span></span><br><span class="line">        <span class="comment"># itos = [&#x27;&lt;pad&gt;&#x27;] + [o for o, c in freq.most_common(max_vocab - 1) if c &gt;= min_freq]</span></span><br><span class="line">        itos = [o <span class="keyword">for</span> o, c <span class="keyword">in</span> freq.most_common(max_vocab - <span class="number">1</span>) <span class="keyword">if</span> c &gt;= min_freq]</span><br><span class="line">        <span class="comment"># 返回包含词汇表的类实例</span></span><br><span class="line">        <span class="keyword">return</span> cls(itos)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">siRNA_feat_builder_substr</span>(<span class="params">se, name, patterns</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建一个空字典来存储特征</span></span><br><span class="line">    features = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pattern <span class="keyword">in</span> patterns:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># escaped_pattern = re.escape(pattern)  # 转义模式中的特殊字符</span></span><br><span class="line">            escaped_pattern = pattern</span><br><span class="line">            features[<span class="string">f&quot;feat_<span class="subst">&#123;name&#125;</span>_seq_pattern_<span class="subst">&#123;escaped_pattern&#125;</span>&quot;</span>] = se.<span class="built_in">str</span>.count(escaped_pattern)</span><br><span class="line">        <span class="keyword">except</span> re.error <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error in pattern <span class="subst">&#123;pattern&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将字典转换为DataFrame</span></span><br><span class="line">    feature_df = pd.DataFrame(features)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feature_df</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理序列特征</span></span><br><span class="line">seq_features_df = pd.DataFrame()</span><br><span class="line"></span><br><span class="line">tokenizer1 = GenomicTokenizer(ngram=<span class="number">1</span>, stride=<span class="number">1</span>) <span class="comment"># 1gram</span></span><br><span class="line">tokenizer2 = GenomicTokenizer(ngram=<span class="number">2</span>, stride=<span class="number">1</span>) <span class="comment"># 2gram</span></span><br><span class="line">tokenizer3 = GenomicTokenizer(ngram=<span class="number">3</span>, stride=<span class="number">1</span>) <span class="comment"># 3gram</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 子串词频统计，未修饰序列</span></span><br><span class="line">cols_nomod = [<span class="string">&quot;siRNA_sense_seq&quot;</span>, <span class="string">&quot;siRNA_antisense_seq&quot;</span>]</span><br><span class="line">all_tokens_nomod = []</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_nomod:</span><br><span class="line">    <span class="keyword">for</span> seq <span class="keyword">in</span> df[col]:</span><br><span class="line">        <span class="keyword">if</span> pd.isna(seq):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;#all_tokens_nomod: &#x27;</span>, <span class="built_in">len</span>(all_tokens_nomod))</span><br><span class="line"></span><br><span class="line">vocab_nomod = GenomicVocab.create(all_tokens_nomod, max_vocab=<span class="number">100000</span>, min_freq=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;#vocab_nomod: &#x27;</span>, <span class="built_in">len</span>(vocab_nomod.itos))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_nomod:</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="tokenizer-的工作方式"><a href="#tokenizer-的工作方式" class="headerlink" title="tokenizer 的工作方式"></a><code>tokenizer</code> 的工作方式</h4><p> 这里解释一下通过一个例子来展示不同 <code>tokenizer</code> 的工作方式。<br>我们有一个由碱基组成的基因序列：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AGTCATG</span><br></pre></td></tr></table></figure><p>我们将使用这个序列来演示每个 <code>tokenizer</code> 如何将其分割。</p><h5 id="tokenizer1-ngram-1-stride-1"><a href="#tokenizer1-ngram-1-stride-1" class="headerlink" title="tokenizer1 (ngram&#x3D;1, stride&#x3D;1)"></a><strong><code>tokenizer1</code> (ngram&#x3D;1, stride&#x3D;1)</strong></h5><ul><li>将序列分割成单个碱基的片段，步长为1。</li><li>结果: <code>[&#39;A&#39;, &#39;G&#39;, &#39;T&#39;, &#39;C&#39;, &#39;A&#39;, &#39;T&#39;, &#39;G&#39;]</code></li></ul><h5 id="tokenizer2-ngram-2-stride-2"><a href="#tokenizer2-ngram-2-stride-2" class="headerlink" title="tokenizer2 (ngram&#x3D;2, stride&#x3D;2)"></a><strong><code>tokenizer2</code> (ngram&#x3D;2, stride&#x3D;2)</strong></h5><ul><li>将序列分割成长度为2的片段，步长为2。</li><li>结果: <code>[&#39;AG&#39;, &#39;TG&#39;]</code>（从’A’开始，跳过一个碱基到’G’，然后再次跳过一个碱基到’T’）</li></ul><h5 id="tokenizer3-ngram-3-stride-3"><a href="#tokenizer3-ngram-3-stride-3" class="headerlink" title="tokenizer3 (ngram&#x3D;3, stride&#x3D;3)"></a><strong><code>tokenizer3</code> (ngram&#x3D;3, stride&#x3D;3)</strong></h5><ul><li>将序列分割成长度为3的片段，步长为3。</li><li>结果: <code>[&#39;AGT&#39;]</code>（从’A’开始，跳过两个碱基到’G’）</li></ul><h5 id="tokenizer6-ngram-6-stride-6"><a href="#tokenizer6-ngram-6-stride-6" class="headerlink" title="tokenizer6 (ngram&#x3D;6, stride&#x3D;6)"></a><strong><code>tokenizer6</code> (ngram&#x3D;6, stride&#x3D;6)</strong></h5><ul><li>由于序列长度只有7个碱基，而步长为6，所以这个 <code>tokenizer</code> 只会生成一个长度为6的片段。</li><li>结果: <code>[&#39;AGTCAT&#39;]</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 子串词频统计，修饰序列</span></span><br><span class="line">cols_mod = [<span class="string">&quot;modified_siRNA_sense_seq&quot;</span>, <span class="string">&quot;modified_siRNA_antisense_seq&quot;</span>]</span><br><span class="line">cols_mod_ls = [<span class="string">&quot;modified_siRNA_sense_seq_list&quot;</span>, <span class="string">&quot;modified_siRNA_antisense_seq_list&quot;</span>]</span><br><span class="line">all_tokens_mod = []</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_mod_ls:</span><br><span class="line">    <span class="keyword">for</span> seq_ls <span class="keyword">in</span> df[col]:</span><br><span class="line">        <span class="keyword">if</span> pd.isna(seq_ls):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(&#x27;#all_tokens_mod: &#x27;, len(all_tokens_mod))</span></span><br><span class="line"></span><br><span class="line">vocab_mod = GenomicVocab.create(all_tokens_mod, max_vocab=<span class="number">100000</span>, min_freq=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(&#x27;#vocab_mod: &#x27;, len(vocab_mod.itos))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_mod:</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="siRNA序列与target序列对比"><a href="#siRNA序列与target序列对比" class="headerlink" title="siRNA序列与target序列对比"></a>siRNA序列与target序列对比</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Bio <span class="keyword">import</span> pairwise2</span><br><span class="line"><span class="keyword">from</span> Bio.pairwise2 <span class="keyword">import</span> format_alignment</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_feat_align</span>(<span class="params">df, anti: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算siRNA序列与target序列的比对得分。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    df : DataFrame</span></span><br><span class="line"><span class="string">        包含siRNA和target序列的DataFrame。</span></span><br><span class="line"><span class="string">    anti : bool</span></span><br><span class="line"><span class="string">        是否处理antisense siRNA序列。默认为False，表示处理sense siRNA序列。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    DataFrame</span></span><br><span class="line"><span class="string">        包含原始DataFrame和比对得分的DataFrame。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 假设DataFrame有两列，分别为&#x27;sirna_sequence&#x27;和&#x27;target_sequence&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        siRNA_seq = row[<span class="string">&#x27;siRNA_sequence&#x27;</span>]</span><br><span class="line">        target_seq = row[<span class="string">&#x27;target_sequence&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果是antisense siRNA，需要反转并补录序列</span></span><br><span class="line">        <span class="keyword">if</span> anti:</span><br><span class="line">            siRNA_seq = siRNA_seq[::-<span class="number">1</span>].translate(<span class="built_in">str</span>.maketrans(<span class="string">&quot;ATCG&quot;</span>, <span class="string">&quot;TAGC&quot;</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用pairwise2.align.localxx进行局部序列比对</span></span><br><span class="line">        alignments = pairwise2.align.localxx(siRNA_seq, target_seq)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算比对得分，这里取最高得分的比对</span></span><br><span class="line">        max_score = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> alignment <span class="keyword">in</span> alignments:</span><br><span class="line">            score = alignment[<span class="number">2</span>]  <span class="comment"># alignment[2] 是比对得分</span></span><br><span class="line">            <span class="keyword">if</span> score &gt; max_score:</span><br><span class="line">                max_score = score</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将得分添加到DataFrame中</span></span><br><span class="line">        df.at[index, <span class="string">&#x27;alignment_score&#x27;</span>] = max_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure><p>如果siRNA是antisense类型 </p><pre><code>result_df = get_feat_align(df, anti=True) </code></pre><p>如果siRNA是sense类型 </p><pre><code>result_df = get_feat_align(df)  </code></pre><h3 id="其他生物特征"><a href="#其他生物特征" class="headerlink" title="其他生物特征"></a>其他生物特征</h3><blockquote><p>有重复<br><img src="/img/downloaded/aHR0cHM6_402e5e90e3a143109122db8f5e3421d5.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_85c2119965214195afa8837198039a3f.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_7194f9935d2e4339921f7ec3b7b08ede.png" alt="在这里插入图片描述"></p></blockquote><h2 id="lgb模型优化"><a href="#lgb模型优化" class="headerlink" title="lgb模型优化"></a>lgb模型优化</h2><h3 id="低Remaining范围样本高权重"><a href="#低Remaining范围样本高权重" class="headerlink" title="低Remaining范围样本高权重"></a>低Remaining范围样本高权重</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight_ls = np.array(feats[<span class="string">&#x27;mRNA_remaining_pct&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="number">2</span> <span class="keyword">if</span> ((x&lt;=<span class="number">30</span>)<span class="keyword">and</span>(x&gt;=<span class="number">0</span>)) <span class="keyword">else</span> <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>这段代码是将<code>feats</code>中的<code>mRNA_remaining_pct</code>列的值进行一些判断和处理，生成一个新的<code>weight_ls</code>数组。<br>这段代码<strong>根据<code>mRNA_remaining_pct</code>列的值是否在0到30之间，将对应位置上的<code>weight_ls</code>值设置为2或者1。</strong></p><h3 id="使用官方评价指标作为损失函数"><a href="#使用官方评价指标作为损失函数" class="headerlink" title="使用官方评价指标作为损失函数"></a>使用官方评价指标作为损失函数</h3><blockquote><p>由原来的root_mean_squared_error评价指标被替换为更加复杂的官方评价分数</p></blockquote><p>具体公式为:</p><p>$$\text{score} &#x3D; 50% \times \left(1 - \frac{\text{MAE}}{100}\right) + 50% \times F1 \times \left(1 - \frac{\text{Range-MAE}}{100}\right)$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># calculate_metrics函数用于计算评估指标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_metrics</span>(<span class="params">preds, data, threshold=<span class="number">30</span></span>):</span><br><span class="line">    y_pred = preds</span><br><span class="line">    y_true = data.get_label()</span><br><span class="line">    mae = np.mean(np.<span class="built_in">abs</span>(y_true - y_pred))</span><br><span class="line">    <span class="comment"># if mae &lt; 0: mae = 0</span></span><br><span class="line">    <span class="comment"># elif mae &gt;100: mae = 100</span></span><br><span class="line"></span><br><span class="line">    y_true_binary = ((y_true &lt;= threshold) &amp; (y_true &gt;= <span class="number">0</span>)).astype(<span class="built_in">int</span>)</span><br><span class="line">    y_pred_binary = ((y_pred &lt;= threshold) &amp; (y_pred &gt;= <span class="number">0</span>)).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    mask = (y_pred &gt;= <span class="number">0</span>) &amp; (y_pred &lt;= threshold)</span><br><span class="line">    range_mae = (</span><br><span class="line">        mean_absolute_error(y_true[mask], y_pred[mask]) <span class="keyword">if</span> np.<span class="built_in">sum</span>(mask) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">100</span></span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># if range_mae &lt; 0: range_mae = 0</span></span><br><span class="line">    <span class="comment"># elif range_mae &gt;100: range_mae = 100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># precision = precision_score(y_true_binary, y_pred_binary, average=&quot;binary&quot;)</span></span><br><span class="line">    <span class="comment"># recall = recall_score(y_true_binary, y_pred_binary, average=&quot;binary&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">sum</span>(y_pred_binary) &gt; <span class="number">0</span>:</span><br><span class="line">        precision = (np.array(y_pred_binary) &amp; y_true_binary).<span class="built_in">sum</span>()/np.<span class="built_in">sum</span>(y_pred_binary)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        precision = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">sum</span>(y_true_binary) &gt; <span class="number">0</span>:</span><br><span class="line">        recall = (np.array(y_pred_binary) &amp; y_true_binary).<span class="built_in">sum</span>()/np.<span class="built_in">sum</span>(y_true_binary)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        recall = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> precision + recall == <span class="number">0</span>:</span><br><span class="line">        f1 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        f1 = <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line">    score = (<span class="number">1</span> - mae / <span class="number">100</span>) * <span class="number">0.5</span> + (<span class="number">1</span> - range_mae / <span class="number">100</span>) * f1 * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;custom_score&quot;</span>, score, <span class="literal">True</span>  <span class="comment"># True表示分数越高越好</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="自适应学习率"><a href="#自适应学习率" class="headerlink" title="自适应学习率"></a>自适应学习率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># adaptive_learning_rate函数用于自适应学习率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">adaptive_learning_rate</span>(<span class="params">decay_rate=<span class="number">0.8</span>, patience=<span class="number">50</span></span>):</span><br><span class="line">    best_score = <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>)  <span class="comment"># 初始化为负无穷,因为分数越高越好</span></span><br><span class="line">    wait = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">callback</span>(<span class="params">env</span>):</span><br><span class="line">        <span class="keyword">nonlocal</span> best_score, wait</span><br><span class="line">        current_score = env.evaluation_result_list[-<span class="number">1</span>][<span class="number">2</span>]  <span class="comment"># 假设使用的是最后一个评估指标</span></span><br><span class="line">        current_lr =  env.model.params.get(<span class="string">&#x27;learning_rate&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_score &gt; best_score: </span><br><span class="line">            best_score = current_score</span><br><span class="line">            <span class="comment"># wait = 0 # 需要连续的score没有上升</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            wait += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> wait &gt;= patience:</span><br><span class="line">            new_lr = <span class="built_in">float</span>(current_lr) * decay_rate</span><br><span class="line">            wait = <span class="number">0</span></span><br><span class="line">            env.model.params[<span class="string">&#x27;learning_rate&#x27;</span>] = new_lr</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Learning rate adjusted to <span class="subst">&#123;env.model.params.get(<span class="string">&#x27;learning_rate&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> callback</span><br></pre></td></tr></table></figure><h3 id="多折交叉训练"><a href="#多折交叉训练" class="headerlink" title="多折交叉训练"></a>多折交叉训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train函数用于训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">feats, n_original</span>):</span><br><span class="line">    <span class="comment"># 定义k折交叉验证</span></span><br><span class="line">    n_splits = <span class="number">10</span></span><br><span class="line">    kf = KFold(n_splits=n_splits, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    <span class="comment"># 开始k折交叉验证</span></span><br><span class="line">    gbms = []</span><br><span class="line">    <span class="keyword">for</span> fold, (train_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(</span><br><span class="line">        kf.split(feats.iloc[:n_original, :]), <span class="number">1</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="comment"># 准备训练集和验证集</span></span><br><span class="line">        X_train, X_val = feats.iloc[train_idx, :-<span class="number">1</span>], feats.iloc[val_idx, :-<span class="number">1</span>]</span><br><span class="line">        y_train, y_val = feats.iloc[train_idx, -<span class="number">1</span>], feats.iloc[val_idx, -<span class="number">1</span>]</span><br><span class="line">        w_train = weight_ls[train_idx]</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建LightGBM数据集</span></span><br><span class="line">        train_data = lgb.Dataset(X_train, label=y_train, weight=w_train)</span><br><span class="line">        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)</span><br><span class="line"></span><br><span class="line">        boost_round = <span class="number">25000</span></span><br><span class="line">        early_stop_rounds = <span class="built_in">int</span>(boost_round*<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 显示metric</span></span><br><span class="line">        lgb_log = lgb.log_evaluation(period=<span class="number">200</span>, show_stdv=<span class="literal">True</span>)</span><br><span class="line">        lgb_stop = lgb.early_stopping(stopping_rounds=early_stop_rounds, first_metric_only=<span class="literal">True</span>, verbose=<span class="literal">True</span>, min_delta=<span class="number">0.00001</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置LightGBM参数</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&quot;boosting_type&quot;</span>: <span class="string">&quot;gbdt&quot;</span>,</span><br><span class="line">            <span class="string">&quot;objective&quot;</span>: <span class="string">&quot;regression&quot;</span>,</span><br><span class="line">            <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;None&quot;</span>,</span><br><span class="line">            <span class="comment"># &quot;metric&quot;: &quot;root_mean_squared_error&quot;,</span></span><br><span class="line">            <span class="string">&quot;max_depth&quot;</span>: <span class="number">8</span>,</span><br><span class="line">            <span class="string">&quot;num_leaves&quot;</span>: <span class="number">63</span>,</span><br><span class="line">            <span class="string">&quot;min_data_in_leaf&quot;</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.05</span>,</span><br><span class="line">            <span class="string">&quot;feature_fraction&quot;</span>: <span class="number">0.9</span>,</span><br><span class="line">            <span class="string">&quot;lambda_l1&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">            <span class="string">&quot;lambda_l2&quot;</span>: <span class="number">0.2</span>,</span><br><span class="line">            <span class="string">&quot;verbose&quot;</span>: -<span class="number">1</span>, <span class="comment"># -1时不输出</span></span><br><span class="line">            <span class="string">&quot;early_stopping_round&quot;</span>: early_stop_rounds,</span><br><span class="line">            <span class="string">&quot;num_threads&quot;</span>: <span class="number">8</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在训练时使用自适应学习率回调函数</span></span><br><span class="line">        adaptive_lr = adaptive_learning_rate(decay_rate=<span class="number">0.9</span>, patience=<span class="number">1000</span>)</span><br><span class="line">        gbm = lgb.train(</span><br><span class="line">            params,</span><br><span class="line">            train_data,</span><br><span class="line">            num_boost_round=boost_round,</span><br><span class="line">            valid_sets=[val_data],</span><br><span class="line">            feval=calculate_metrics,  <span class="comment"># 将自定义指标函数作为feval参数传入</span></span><br><span class="line">            <span class="comment"># callbacks=[print_validation_result, adaptive_lr, lgb_log, lgb_stop],</span></span><br><span class="line">            callbacks=[adaptive_lr, lgb_log, lgb_stop],</span><br><span class="line">        )</span><br><span class="line">        valid_score = gbm.best_score[<span class="string">&quot;valid_0&quot;</span>][<span class="string">&quot;custom_score&quot;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;best_valid_score: <span class="subst">&#123;valid_score&#125;</span>&quot;</span>)</span><br><span class="line">        gbms.append(gbm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gbms</span><br></pre></td></tr></table></figure><h3 id="完成以上操作的分数"><a href="#完成以上操作的分数" class="headerlink" title="完成以上操作的分数"></a>完成以上操作的分数</h3><p><img src="/img/downloaded/aHR0cHM6_9d49d4b4dd414cf0b9c8196182d91ab6.png" alt="在这里插入图片描述"></p><h3 id="超参数优化"><a href="#超参数优化" class="headerlink" title="超参数优化"></a>超参数优化</h3><h4 id="贝叶斯优化-推荐）"><a href="#贝叶斯优化-推荐）" class="headerlink" title="贝叶斯优化(推荐）"></a>贝叶斯优化(推荐）</h4><blockquote><p>您可以使用如optuna这样的库来执行贝叶斯优化超参数, 参考代码如下</p></blockquote><p>伪代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> optuna</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">objective</span>(<span class="params">trial</span>):</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: trial.suggest_int(<span class="string">&#x27;max_depth&#x27;</span>, <span class="number">3</span>, <span class="number">10</span>),</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: trial.suggest_loguniform(<span class="string">&#x27;learning_rate&#x27;</span>, <span class="number">1e-3</span>, <span class="number">1e-1</span>),</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span>: trial.suggest_int(<span class="string">&#x27;n_estimators&#x27;</span>, <span class="number">100</span>, <span class="number">2000</span>),</span><br><span class="line">        <span class="string">&#x27;min_child_samples&#x27;</span>: trial.suggest_int(<span class="string">&#x27;min_child_samples&#x27;</span>, <span class="number">20</span>, <span class="number">100</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    model = LGBMRegressor(**params)</span><br><span class="line">    model.fit(X_train, y_train)</span><br><span class="line">    <span class="keyword">return</span> model.score(X_val, y_val)</span><br><span class="line"></span><br><span class="line">study = optuna.create_study(direction=<span class="string">&#x27;maximize&#x27;</span>)</span><br><span class="line">study.optimize(objective, n_trials=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Best trial:&#x27;</span>)</span><br><span class="line">trial = study.best_trial</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Value: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(trial.value))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Params: &#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> trial.params.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;    &#123;&#125;: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(key, value))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>通过贝叶斯优化方法来进行超参数优化。</p><ol><li>拆分数据集为训练集和测试集。 </li><li>定义超参数搜索空间。 </li><li>创建评估函数，训练LGBMClassifier模型，计算准确率。</li><li>使用贝叶斯优化，找出最佳超参数。</li></ol><p><img src="/img/downloaded/aHR0cHM6_9b8549bd50b14edda88219cbd2c99c40.png" alt="在这里插入图片描述"><br>真的跑很久。。。还没跑完</p><h4 id="网格搜索（Grid-Search）"><a href="#网格搜索（Grid-Search）" class="headerlink" title="网格搜索（Grid Search）"></a>网格搜索（Grid Search）</h4><blockquote><p>使用LightGBM</p></blockquote><p><strong>伪代码</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数搜索空间</span></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">10</span>],</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">0.2</span>],</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">100</span>, <span class="number">200</span>, <span class="number">300</span>],</span><br><span class="line">    <span class="string">&#x27;num_leaves&#x27;</span>: [<span class="number">31</span>, <span class="number">63</span>, <span class="number">127</span>],</span><br><span class="line">    <span class="string">&#x27;min_child_samples&#x27;</span>: [<span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建LightGBM分类器</span></span><br><span class="line">estimator = lgb.LGBMClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建GridSearchCV对象</span></span><br><span class="line">grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行网格搜索</span></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最佳参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Best parameters:&#x27;</span>, grid_search.best_params_)</span><br></pre></td></tr></table></figure><h4 id="随机搜索（Random-Search）"><a href="#随机搜索（Random-Search）" class="headerlink" title="随机搜索（Random Search）"></a>随机搜索（Random Search）</h4><blockquote><p>使用LightGBM</p></blockquote><p><strong>伪代码</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> randint, uniform</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数的连续搜索空间</span></span><br><span class="line">param_dist = &#123;</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: randint(<span class="number">3</span>, <span class="number">10</span>),</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: uniform(<span class="number">0.01</span>, <span class="number">0.2</span>),</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: randint(<span class="number">100</span>, <span class="number">300</span>),</span><br><span class="line">    <span class="string">&#x27;num_leaves&#x27;</span>: randint(<span class="number">31</span>, <span class="number">127</span>),</span><br><span class="line">    <span class="string">&#x27;min_child_samples&#x27;</span>: randint(<span class="number">5</span>, <span class="number">20</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建LightGBM分类器</span></span><br><span class="line">estimator = lgb.LGBMClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建RandomizedSearchCV对象</span></span><br><span class="line">random_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_dist, n_iter=<span class="number">100</span>, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行随机搜索</span></span><br><span class="line">random_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最佳参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Best parameters:&#x27;</span>, random_search.best_params_)</span><br></pre></td></tr></table></figure><h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><blockquote><p>多模型可以结合使得稳定</p></blockquote><blockquote><p>集成学习就是把多个弱分类器或回归模型组合起来，变成一个强分类器或回归模型，从而提高预测的准确性。</p></blockquote><p>实现集成学习的方式有很多种，比如通过投票决定最终结果、取平均值来预测、或者给每个模型分配不同的权重。集成学习的主要思想是通过多个模型之间的合作，来弥补每个模型的不足，使整体模型的预测能力更强。</p><blockquote><p>常见的集成学习方法:</p><ol><li>Bagging（自助聚合）：通过在原始数据集上进行多次重采样来创建多个子集，分别训练多个模型，最后进行平均或多数投票决策。</li><li>Boosting：训练多个模型，每个模型都尝试纠正前一个模型的错误，通常是序列处理。</li><li>Stacking：训练多个不同的模型，然后再训练一个新的模型来综合这些模型的输出。</li></ol></blockquote><h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><p>Stacking 是一种集成学习技术，它将多个模型的预测结果作为输入，然后使用另一个模型（通常称为元模型或元分类器）来进行最终的预测。</p><p>举例一个使用Python的 <code>scikit-learn</code> 库实现Stacking：</p><p><strong>伪代码</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> StackingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拆分数据集为训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义基模型列表</span></span><br><span class="line">estimators = [</span><br><span class="line">    (<span class="string">&#x27;rf&#x27;</span>, RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)),</span><br><span class="line">    (<span class="string">&#x27;gb&#x27;</span>, GradientBoostingClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)),</span><br><span class="line">    (<span class="string">&#x27;svc&#x27;</span>, SVC(probability=<span class="literal">True</span>, kernel=<span class="string">&#x27;linear&#x27;</span>))</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加元模型</span></span><br><span class="line">estimators.append((<span class="string">&#x27;lr&#x27;</span>, LogisticRegression()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建Stacking分类器</span></span><br><span class="line">stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练Stacking分类器</span></span><br><span class="line">stacking_clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测测试集</span></span><br><span class="line">y_pred = stacking_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test set accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="Stacking模型是什么？"><a href="#Stacking模型是什么？" class="headerlink" title="Stacking模型是什么？"></a>Stacking模型是什么？</h4><p>想象一下，你有好几个不同的老师，他们每个人都对同一组学生进行考试评分。Stacking模型就像是一个“超级老师”，它收集这些不同老师给的分数，然后根据这些分数再给出一个最终的评分。</p><h4 id="基模型"><a href="#基模型" class="headerlink" title="基模型"></a>基模型</h4><p>在这个例子里，我们有三个“老师”：</p><ul><li>第一个老师用的是“随机森林”方法来评分。</li><li>第二个老师用的是“梯度提升”方法。</li><li>第三个老师用的是“支持向量机”方法。</li></ul><h4 id="元模型"><a href="#元模型" class="headerlink" title="元模型"></a>元模型</h4><p>然后，我们有一个“超级老师”，也就是我们的元模型，它用的是“逻辑回归”方法来根据前面三个老师的评分给出最终的评分。</p><h4 id="为什么要这么做？"><a href="#为什么要这么做？" class="headerlink" title="为什么要这么做？"></a>为什么要这么做？</h4><ul><li>有时候，不同的老师（模型）对同一组学生（数据）的看法会有所不同。通过综合他们的意见，我们可以得到一个更全面、更准确的评分。</li><li>但是，这也有风险，如果这些老师（模型）都倾向于犯同样的错误，那么“超级老师”也可能跟着犯错。</li></ul><h4 id="如何实现？"><a href="#如何实现？" class="headerlink" title="如何实现？"></a>如何实现？</h4><ol><li>我们首先把学生（数据）分成两部分：一部分用来让每个老师单独评分（训练集），另一部分用来测试最终的评分结果（测试集）。</li><li>每个老师都用他们的方法给训练集的学生打分。</li><li>然后，我们把这些分数收集起来，让“超级老师”来根据这些分数给出最终的评分。</li><li>我们用测试集来看看“超级老师”的评分有多准确。</li></ol><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ul><li>支持向量机老师需要一个特别的设置（<code>probability=True</code>），这样它才能给出每个学生可能得到每个分数的概率，这对于“超级老师”来说很重要。</li><li>我们要小心，不要让“超级老师”太复杂，否则它可能会过度拟合，也就是说，它可能只是在模仿训练集中的分数，而不是真正理解学生的能力。</li></ul><p>总的来说，Stacking模型是一种很有趣的方法，可以让我们把不同的模型结合起来，得到更好的预测结果。但是，我们也需要小心，确保它不会变得太复杂，导致在新数据上表现不佳。</p><h3 id="官方给出的lgb举例"><a href="#官方给出的lgb举例" class="headerlink" title="官方给出的lgb举例"></a>官方给出的lgb举例</h3><blockquote><p>假设已有LightGBM、XGBoost和一个简单的神经网络模型，下面是一个使用Stacking方法的Python示例代码：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> StackingRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设已有数据集 df</span></span><br><span class="line">X = df.drop(<span class="string">&#x27;target&#x27;</span>, axis=<span class="number">1</span>)  <span class="comment"># 特征列</span></span><br><span class="line">y = df[<span class="string">&#x27;target&#x27;</span>]  <span class="comment"># 目标列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义基模型</span></span><br><span class="line">estimators = [</span><br><span class="line">    (<span class="string">&#x27;lgb&#x27;</span>, lgb.LGBMRegressor(objective=<span class="string">&#x27;regression&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;xgb&#x27;</span>, XGBRegressor(objective=<span class="string">&#x27;reg:squarederror&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;mlp&#x27;</span>, MLPRegressor(hidden_layer_sizes=(<span class="number">50</span>, <span class="number">30</span>), max_iter=<span class="number">500</span>))</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义最终的meta-regressor</span></span><br><span class="line">final_estimator = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建Stacking模型</span></span><br><span class="line">stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=final_estimator, cv=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">stacking_regressor.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">y_pred = stacking_regressor.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test MSE: <span class="subst">&#123;mse:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 看每个单独模型的性能</span></span><br><span class="line"><span class="keyword">for</span> name, est <span class="keyword">in</span> stacking_regressor.named_estimators_.items():</span><br><span class="line">    y_pred_individual = est.predict(X_test)</span><br><span class="line">    mse_individual = mean_squared_error(y_test, y_pred_individual)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> Test MSE: <span class="subst">&#123;mse_individual:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="混合学习"><a href="#混合学习" class="headerlink" title="混合学习"></a>混合学习</h3><p>在解决复杂的生物信息学问题时，机器学习和深度学习的混合方法可以提供强大的工具。<br>这种方法包括两个主要部分：使用深度学习模型进行特征提取，然后使用传统的机器学习模型进行最终的决策。可以使用PyTorch构建深度学习部分，然后将输出特征传递给LightGBM进行分类或回归。这种混合方法结合了深度学习的特征学习能力和传统机器学习模型的效率与解释性，可以在生物信息学问题中提供强大的解决方案。</p><h4 id="构建PyTorch模型"><a href="#构建PyTorch模型" class="headerlink" title="构建PyTorch模型"></a>构建PyTorch模型</h4><p>首先，我们定义一个简单的卷积神经网络（CNN）来处理序列数据。这个模型将用于提取有用的特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, TensorDataset</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RegressionCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sequence_length</span>):</span><br><span class="line">        <span class="built_in">super</span>(RegressionCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv1d(in_channels=<span class="number">1</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool1d(kernel_size=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.flatten = nn.Flatten()</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">32</span> * ((sequence_length // <span class="number">2</span>) - <span class="number">1</span>), <span class="number">100</span>)  <span class="comment"># Adjust size accordingly</span></span><br><span class="line">        <span class="variable language_">self</span>.regressor = nn.Linear(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.regressor(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设df是包含序列和目标值的DataFrame</span></span><br><span class="line">sequence_length = <span class="number">100</span>  <span class="comment"># 假定每个序列的长度</span></span><br><span class="line">X = np.array([np.array(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, <span class="built_in">list</span>(seq)))) <span class="keyword">for</span> seq <span class="keyword">in</span> df[<span class="string">&#x27;sequence&#x27;</span>]])</span><br><span class="line">X = X.reshape(X.shape[<span class="number">0</span>], <span class="number">1</span>, sequence_length)</span><br><span class="line">y = df[<span class="string">&#x27;target&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))</span><br><span class="line">test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DataLoader</span></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型和优化器</span></span><br><span class="line">model = RegressionCNN(sequence_length)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, train_loader</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output.view(-<span class="number">1</span>), target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取特征</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_features</span>(<span class="params">model, loader</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    features = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> loader:</span><br><span class="line">            output = model(data)</span><br><span class="line">            features.extend(output.view(-<span class="number">1</span>).numpy())</span><br><span class="line">            labels.extend(target.numpy())</span><br><span class="line">    <span class="keyword">return</span> np.array(features), np.array(labels)</span><br><span class="line"></span><br><span class="line">train_model(model, train_loader)</span><br><span class="line">X_train_features, y_train = extract_features(model, train_loader)</span><br><span class="line">X_test_features, y_test = extract_features(model, test_loader)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="使用LightGBM进行回归"><a href="#使用LightGBM进行回归" class="headerlink" title="使用LightGBM进行回归"></a>使用LightGBM进行回归</h4><p>在获取特征后，我们可以使用LightGBM进行回归预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 使用LightGBM进行最终的预测</span></span><br><span class="line">lgb_regressor = lgb.LGBMRegressor(n_estimators=<span class="number">100</span>, learning_rate=<span class="number">0.05</span>, max_depth=<span class="number">5</span>)</span><br><span class="line">lgb_regressor.fit(X_train_features.reshape(-<span class="number">1</span>, <span class="number">1</span>), y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测和评估</span></span><br><span class="line">y_pred = lgb_regressor.predict(X_test_features.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test MSE: <span class="subst">&#123;mse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="其他思路"><a href="#其他思路" class="headerlink" title="其他思路"></a>其他思路</h3><ul><li>集成额外的生物信息学数据库来增强特征。</li><li>实施自动化特征选择流程以减少模型复杂性和过拟合。</li><li>尝试动态调整学习率，如学习率预热和循环学习率。</li><li>考虑多目标优化，同时优化不同评价指标或设计更全面的评价函数。</li><li>生物学角度新特征</li></ul><h3 id="新模型构建"><a href="#新模型构建" class="headerlink" title="新模型构建"></a>新模型构建</h3><ul><li>使用attention机制进行end2end的建模，将siRNA序列和target gene序列进行拼接，并捕捉它们之间的相关模式。</li><li>利用现有的生物序列基础模型，生成siRNA和target gene序列的表征向量，并将其输入模型以提高预测效果。</li></ul><h3 id="外部数据集（官方未禁用）"><a href="#外部数据集（官方未禁用）" class="headerlink" title="外部数据集（官方未禁用）"></a>外部数据集（官方未禁用）</h3><h3 id="笔记发布前最新成绩"><a href="#笔记发布前最新成绩" class="headerlink" title="笔记发布前最新成绩"></a>笔记发布前最新成绩</h3><p><img src="/img/downloaded/aHR0cHM6_83ccd8a65a3f431cbbb97b21f3bd31a7.png" alt="在这里插入图片描述"></p><h2 id="引用文档"><a href="#引用文档" class="headerlink" title="引用文档"></a>引用文档</h2><blockquote><p>siRNA和shRNA:通过基因沉默抑制蛋白表达的工具<br><a href="http://www.labome.cn/method/siRNAs-and-shRNAs-Tools-for-Protein-Knockdown-by-Gene-Silencing.html">http://www.labome.cn/method/siRNAs-and-shRNAs-Tools-for-Protein-Knockdown-by-Gene-Silencing.html</a><br>Datawhale<br><a href="https://linklearner.com/activity/12/4/16">https://linklearner.com/activity/12/4/16</a><br>Datawhale<br><a href="https://linklearner.com/activity/12/4/11">https://linklearner.com/activity/12/4/11</a><br>Datawhale<br><a href="https://linklearner.com/activity/12/4/5">https://linklearner.com/activity/12/4/5</a><br>Datawhale<br><a href="https://linklearner.com/activity/12/4/4">https://linklearner.com/activity/12/4/4</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
          <category> AI4Science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI4Science </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构部分</title>
      <link href="/2025/03/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%83%A8%E5%88%86/"/>
      <url>/2025/03/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%83%A8%E5%88%86/</url>
      
        <content type="html"><![CDATA[<h1 id="数据结构部分"><a href="#数据结构部分" class="headerlink" title="数据结构部分"></a>数据结构部分</h1><h2 id="线性数据结构"><a href="#线性数据结构" class="headerlink" title="线性数据结构"></a>线性数据结构</h2><h3 id="数组-Array"><a href="#数组-Array" class="headerlink" title="数组(Array)"></a>数组(Array)</h3><ul><li>定义：连续内存空间存储同类型数据</li><li>特点：随机访问，固定大小</li><li>操作：插入、删除、查找、遍历、排序</li></ul><h3 id="链表-Linked-List"><a href="#链表-Linked-List" class="headerlink" title="链表(Linked List)"></a>链表(Linked List)</h3><ul><li>单向链表：每个节点存储数据和后继指针</li><li>双向链表：每个节点存储数据和前驱、后继指针</li><li>循环链表：尾节点指向头节点</li><li>操作：插入、删除、查找、遍历、排序</li></ul><h3 id="栈-Stack"><a href="#栈-Stack" class="headerlink" title="栈(Stack)"></a>栈(Stack)</h3><ul><li>定义：后进先出(LIFO)的线性表</li><li>操作：压栈(push)、出栈(pop)、获取栈顶(top)</li><li>应用：函数调用、表达式求值、括号匹配</li></ul><h3 id="队列-Queue"><a href="#队列-Queue" class="headerlink" title="队列(Queue)"></a>队列(Queue)</h3><ul><li>定义：先进先出(FIFO)的线性表</li><li>类型：普通队列、循环队列、双端队列</li><li>操作：入队(enqueue)、出队(dequeue)</li><li>应用：任务调度、缓冲区管理</li></ul><h2 id="非线性数据结构"><a href="#非线性数据结构" class="headerlink" title="非线性数据结构"></a>非线性数据结构</h2><h3 id="树-Tree"><a href="#树-Tree" class="headerlink" title="树(Tree)"></a>树(Tree)</h3><h4 id="二叉树-Binary-Tree"><a href="#二叉树-Binary-Tree" class="headerlink" title="二叉树(Binary Tree)"></a>二叉树(Binary Tree)</h4><ul><li>完全二叉树</li><li>满二叉树</li><li>遍历：前序、中序、后序、层序</li></ul><h4 id="二叉搜索树-BST"><a href="#二叉搜索树-BST" class="headerlink" title="二叉搜索树(BST)"></a>二叉搜索树(BST)</h4><ul><li>定义：左子树小于根节点，右子树大于根节点</li><li>操作：插入、删除、查找</li><li>平均时间复杂度：O(log n)</li></ul><h4 id="平衡二叉树-AVL-Tree"><a href="#平衡二叉树-AVL-Tree" class="headerlink" title="平衡二叉树(AVL Tree)"></a>平衡二叉树(AVL Tree)</h4><ul><li>定义：任意节点的左右子树高度差不超过1</li><li>操作：左旋、右旋、插入、删除</li></ul><h4 id="红黑树-Red-Black-Tree"><a href="#红黑树-Red-Black-Tree" class="headerlink" title="红黑树(Red-Black Tree)"></a>红黑树(Red-Black Tree)</h4><ul><li>特点：自平衡的二叉搜索树</li><li>性质：根黑、叶黑、红子黑、黑高相等</li><li>应用：STL容器实现</li></ul><h4 id="字典树-Trie"><a href="#字典树-Trie" class="headerlink" title="字典树(Trie)"></a>字典树(Trie)</h4><ul><li>特点：用于存储和检索字符串</li><li>应用：前缀匹配、自动补全</li></ul><h4 id="哈夫曼树-Huffman-Tree"><a href="#哈夫曼树-Huffman-Tree" class="headerlink" title="哈夫曼树(Huffman Tree)"></a>哈夫曼树(Huffman Tree)</h4><ul><li>特点：带权路径长度最小的二叉树</li><li>应用：数据压缩</li></ul><h3 id="图-Graph"><a href="#图-Graph" class="headerlink" title="图(Graph)"></a>图(Graph)</h3><ul><li>表示：邻接矩阵、邻接表</li><li>类型：有向图、无向图、带权图</li><li>遍历：深度优先(DFS)、广度优先(BFS)</li><li>算法：最短路径、最小生成树</li></ul><h3 id="堆-Heap"><a href="#堆-Heap" class="headerlink" title="堆(Heap)"></a>堆(Heap)</h3><ul><li>类型：最大堆、最小堆</li><li>特点：完全二叉树</li><li>操作：插入、删除最值、建堆</li><li>应用：优先队列、堆排序</li></ul><h3 id="哈希表-Hash-Table"><a href="#哈希表-Hash-Table" class="headerlink" title="哈希表(Hash Table)"></a>哈希表(Hash Table)</h3><ul><li>定义：通过哈希函数将键映射到数组</li><li>冲突解决：链地址法、开放地址法</li><li>应用：快速查找、缓存系统</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与编程</title>
      <link href="/2025/03/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BC%96%E7%A8%8B/"/>
      <url>/2025/03/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>今天是2023年3月10日，我是一名软件专业的学生，正在学习数据结构与算法。<br>数据结构是计算机科学中非常重要的一个分支，它研究的是数据的组织和存储方式，以及如何对数据进行操作和访问。算法是计算机科学中非常重要的一个分支，它研究的是如何解决问题的方法和步骤。<br>目前的学习目标是：蓝桥杯国奖</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/03/10/hello-world/"/>
      <url>/2025/03/10/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>如何创建GitHub个人网站</title>
      <link href="/2025/03/09/%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BAGitHub%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/"/>
      <url>/2025/03/09/%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BAGitHub%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<h1 id="如何创建GitHub个人网站"><a href="#如何创建GitHub个人网站" class="headerlink" title="如何创建GitHub个人网站"></a>如何创建GitHub个人网站</h1><p>本文将详细介绍如何从零开始搭建一个基于GitHub Pages的个人网站，包括环境配置、仓库创建、Hexo框架安装以及主题配置等全过程。</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>在开始之前，请确保你的电脑已经安装以下工具：</p><ul><li><a href="https://nodejs.org/">Node.js</a> (建议选择LTS版本)</li><li><a href="https://git-scm.com/">Git</a></li></ul><h2 id="1-配置SSH密钥"><a href="#1-配置SSH密钥" class="headerlink" title="1. 配置SSH密钥"></a>1. 配置SSH密钥</h2><ol><li>生成SSH密钥：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;你的邮箱地址&quot;</span></span><br></pre></td></tr></table></figure><ol start="2"><li>查看公钥内容：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> ~/.ssh/id_rsa.pub  <span class="comment"># Windows系统使用: type C:\Users\用户名\.ssh\id_rsa.pub</span></span><br></pre></td></tr></table></figure><ol start="3"><li><p>复制公钥内容，前往GitHub设置页面：</p><ul><li>访问 <a href="https://github.com/settings/keys">GitHub SSH设置</a></li><li>点击 “New SSH key”</li><li>填写标题（如：My PC）</li><li>粘贴公钥内容</li><li>点击 “Add SSH key”</li></ul></li><li><p>测试SSH连接：</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><h2 id="2-创建GitHub-Pages仓库"><a href="#2-创建GitHub-Pages仓库" class="headerlink" title="2. 创建GitHub Pages仓库"></a>2. 创建GitHub Pages仓库</h2><ol><li>登录GitHub，点击右上角 “+” 号，选择 “New repository”</li><li>仓库名称必须为：<code>你的用户名.github.io</code></li><li>选择 “Public”</li><li>点击 “Create repository”</li></ol><h2 id="3-安装Hexo框架"><a href="#3-安装Hexo框架" class="headerlink" title="3. 安装Hexo框架"></a>3. 安装Hexo框架</h2><ol><li>全局安装Hexo-CLI：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><ol start="2"><li>创建博客项目：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo init blog</span><br><span class="line"><span class="built_in">cd</span> blog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><ol start="3"><li>安装必要插件：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br><span class="line">npm install hexo-renderer-pug hexo-renderer-stylus --save</span><br></pre></td></tr></table></figure><h2 id="4-配置Hexo"><a href="#4-配置Hexo" class="headerlink" title="4. 配置Hexo"></a>4. 配置Hexo</h2><ol><li>编辑根目录下的 <code>_config.yml</code>，修改以下配置：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Site</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">你的网站标题</span></span><br><span class="line"><span class="attr">subtitle:</span> <span class="string">副标题</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">网站描述</span></span><br><span class="line"><span class="attr">keywords:</span> <span class="string">关键词</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">作者名</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-CN</span></span><br><span class="line"><span class="attr">timezone:</span> <span class="string">Asia/Shanghai</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># URL</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">https://你的用户名.github.io</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">git@github.com:你的用户名/你的用户名.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure><h2 id="5-安装Butterfly主题"><a href="#5-安装Butterfly主题" class="headerlink" title="5. 安装Butterfly主题"></a>5. 安装Butterfly主题</h2><ol><li>下载主题：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly</span><br></pre></td></tr></table></figure><ol start="2"><li>修改Hexo配置文件 <code>_config.yml</code>：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">butterfly</span></span><br></pre></td></tr></table></figure><ol start="3"><li>创建主题配置文件：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在博客根目录创建文件：_config.butterfly.yml</span></span><br><span class="line"><span class="comment"># 从主题目录复制配置</span></span><br><span class="line"><span class="built_in">cp</span> themes/butterfly/_config.yml _config.butterfly.yml</span><br></pre></td></tr></table></figure><h2 id="6-创建GitHub-Actions自动部署"><a href="#6-创建GitHub-Actions自动部署" class="headerlink" title="6. 创建GitHub Actions自动部署"></a>6. 创建GitHub Actions自动部署</h2><ol><li>在博客根目录创建 <code>.github/workflows/deploy.yml</code>：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Deploy</span></span><br><span class="line"></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="attr">branches:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">main</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">deploy:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/setup-node@v2</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">node-version:</span> <span class="string">&#x27;16&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">run:</span> <span class="string">npm</span> <span class="string">install</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">run:</span> <span class="string">npm</span> <span class="string">run</span> <span class="string">build</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Deploy</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">peaceiris/actions-gh-pages@v3</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">github_token:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.GITHUB_TOKEN</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">publish_dir:</span> <span class="string">./public</span></span><br></pre></td></tr></table></figure><h2 id="7-本地预览与部署"><a href="#7-本地预览与部署" class="headerlink" title="7. 本地预览与部署"></a>7. 本地预览与部署</h2><ol><li>本地预览：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo clean   <span class="comment"># 清除缓存</span></span><br><span class="line">hexo server  <span class="comment"># 启动本地服务器</span></span><br></pre></td></tr></table></figure><p>访问 <code>http://localhost:4000</code> 预览效果</p><ol start="2"><li>部署到GitHub：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo clean   <span class="comment"># 清除缓存</span></span><br><span class="line">hexo deploy  <span class="comment"># 部署到GitHub</span></span><br></pre></td></tr></table></figure><h2 id="8-自定义域名（可选）"><a href="#8-自定义域名（可选）" class="headerlink" title="8. 自定义域名（可选）"></a>8. 自定义域名（可选）</h2><ol><li><p>在你的域名服务商处添加DNS记录：</p><ul><li>类型：CNAME</li><li>主机记录：www 或 @</li><li>记录值：你的用户名.github.io</li></ul></li><li><p>在博客的source目录下创建CNAME文件：</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;你的域名&quot;</span> &gt; <span class="built_in">source</span>/CNAME</span><br></pre></td></tr></table></figure><h2 id="常见问题解决"><a href="#常见问题解决" class="headerlink" title="常见问题解决"></a>常见问题解决</h2><ol><li><p>部署失败：</p><ul><li>检查SSH配置是否正确</li><li>确认仓库名称格式是否正确</li><li>验证GitHub Actions配置文件语法</li></ul></li><li><p>主题显示异常：</p><ul><li>检查主题依赖是否安装完整</li><li>确认配置文件格式是否正确</li><li>清除缓存后重新生成</li></ul></li></ol><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>至此，你的GitHub个人网站就搭建完成了。你可以通过 <code>https://你的用户名.github.io</code> 访问你的网站。接下来，你可以：</p><ul><li>开始写作你的第一篇博客</li><li>自定义主题样式</li><li>添加更多功能插件</li><li>优化网站性能</li></ul><p>记得经常备份你的博客源文件，建议创建一个单独的仓库来存储。</p><p>祝你使用愉快！</p>]]></content>
      
      
      <categories>
          
          <category> 技术教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GitHub </tag>
            
            <tag> Hexo </tag>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
