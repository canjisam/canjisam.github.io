<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>从零入门 AI for Science（AI+药物) 笔记 | 诒森的博客</title><meta name="author" content="CanJisam"><meta name="copyright" content="CanJisam"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="使用平台我的Notebook · 魔搭社区 https:&#x2F;&#x2F;modelscope.cn&#x2F;my&#x2F;mynotebook&#x2F;preset .  魔搭高峰期打不开Task3又换回飞桨了 吧torch 架构换成了 飞桨的paddle   飞桨AI Studio星河社区-人工智能学习与实训社区https:&#x2F;&#x2F;aistudio.baidu.com&#x2F;projectdetail&#x2F;8191835?contributio">
<meta property="og:type" content="article">
<meta property="og:title" content="从零入门 AI for Science（AI+药物) 笔记">
<meta property="og:url" content="https://canjisam.github.io/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="诒森的博客">
<meta property="og:description" content="使用平台我的Notebook · 魔搭社区 https:&#x2F;&#x2F;modelscope.cn&#x2F;my&#x2F;mynotebook&#x2F;preset .  魔搭高峰期打不开Task3又换回飞桨了 吧torch 架构换成了 飞桨的paddle   飞桨AI Studio星河社区-人工智能学习与实训社区https:&#x2F;&#x2F;aistudio.baidu.com&#x2F;projectdetail&#x2F;8191835?contributio">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://canjisam.github.io/img/cover/9f13ef7ffc274ea1974a8c4bd3849b26_0.png">
<meta property="article:published_time" content="2025-03-10T01:51:02.000Z">
<meta property="article:modified_time" content="2025-03-10T15:34:57.804Z">
<meta property="article:author" content="CanJisam">
<meta property="article:tag" content="AI4Science">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://canjisam.github.io/img/cover/9f13ef7ffc274ea1974a8c4bd3849b26_0.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "从零入门 AI for Science（AI+药物) 笔记",
  "url": "https://canjisam.github.io/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/",
  "image": "https://canjisam.github.io/img/cover/9f13ef7ffc274ea1974a8c4bd3849b26_0.png",
  "datePublished": "2025-03-10T01:51:02.000Z",
  "dateModified": "2025-03-10T15:34:57.804Z",
  "author": [
    {
      "@type": "Person",
      "name": "CanJisam",
      "url": "https://canjisam.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://canjisam.github.io/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '从零入门 AI for Science（AI+药物) 笔记',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script>window.XF_API_KEY = "33ec326f4348794e214e464ff2990f32";
window.XF_API_SECRET = "NDQ3NGYyZWMwZWQ0ZWQ4ZWUzMTMwY2Y4";</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"></a><a class="nav-page-title" href="/"><span class="site-name">从零入门 AI for Science（AI+药物) 笔记</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">从零入门 AI for Science（AI+药物) 笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-10T01:51:02.000Z" title="发表于 2025-03-10 09:51:02">2025-03-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-10T15:34:57.804Z" title="更新于 2025-03-10 23:34:57">2025-03-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/AI4Science/">AI4Science</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">18.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span class="min2read">75 分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/#post-comment"><span class="valine-comment-count" data-xid="/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/"></span><span class="waline-comment-count" id="/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/"></span><span class="twikoo-count"></span><span class="fb-comments-count"></span><span class="gitalk-comment-count"></span></a></span></div></div></div><article class="container post-content" id="article-container"><h1 id="使用平台"><a href="#使用平台" class="headerlink" title="使用平台"></a>使用平台</h1><p><a target="_blank" rel="noopener" href="https://modelscope.cn/my/mynotebook/preset">我的Notebook · 魔搭社区 https://modelscope.cn/my/mynotebook/preset </a>.</p>
<blockquote>
<p>魔搭高峰期打不开Task3又换回飞桨了 吧torch 架构换成了 飞桨的paddle </p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/projectdetail/8191835?contributionType=1">飞桨AI Studio星河社区-人工智能学习与实训社区<br>https://aistudio.baidu.com/projectdetail/8191835?contributionType=1</a></p>
<h2 id="主要操作"><a href="#主要操作" class="headerlink" title="主要操作"></a>主要操作</h2><ol>
<li><p>运行实例，如果有时长尽量选择方式二（<strong>以下操作基于方式二的实例实现</strong>）<br><img src="/img/downloaded/aHR0cHM6_92e7fdf7158644d28c6c0e3b62aff0b9.png" alt="在这里插入图片描述"></p>
</li>
<li><p>创建文件夹，并重命名为  <strong>2.3siRNA</strong> </p>
</li>
<li><p>上传两个文件<img src="/img/downloaded/aHR0cHM6_41268aec0e374679b7216b239d101ff4.png" alt="在这里插入图片描述"><br>到文件夹， 这里面的第三个按钮是上传<img src="/img/downloaded/aHR0cHM6_fc198bfaeb75475b9cbac58e5cf1fc7e.png" alt="在这里插入图片描述"></p>
</li>
<li><p>在当前文件夹打开终端（如图示意打开终端）并输入解压命令<br><img src="/img/downloaded/aHR0cHM6_086901afd6a349a5bfb06ab4536adf46.png" alt="在这里插入图片描述"></p>
</li>
</ol>
<p>注意：如果你的压缩包名字不是这个请将“siRNA_0715.zip” 换成你的压缩文件的名字“xxx.zip”(xxx为文件名)<br>（方便复制）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip siRNA_0715.zip </span><br></pre></td></tr></table></figure>
<pre><code>到这里准备工作可以了，如果解压出问题了，可以重新上传一下，然后重复解压的操作
</code></pre>
<h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p><img src="/img/downloaded/aHR0cHM6_ec1ffa1535df433d9866dae1ce51808e.png" alt="在这里插入图片描述"></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_23311271/article/details/140357529"> 详细可以参考这篇 </a></p>
<h1 id="参赛平台"><a href="#参赛平台" class="headerlink" title="参赛平台"></a>参赛平台</h1><p><a target="_blank" rel="noopener" href="http://competition.sais.com.cn/competitionDetail/532230/format"> 上海科学智能研究院 </a></p>
<h1 id="Task-1-跑通基线"><a href="#Task-1-跑通基线" class="headerlink" title="Task 1 跑通基线"></a>Task 1 跑通基线</h1><blockquote>
<p><strong>baseline</strong></p>
</blockquote>
<ol>
<li>运行笔记本<blockquote>
<p>2.3siRNA&#x2F;task3.2_siRNA.ipynb<br><img src="/img/downloaded/aHR0cHM6_eb0ba47957fd4bf2aad2d33e633b2b16.png" alt="在这里插入图片描述"><br>就是这个橙不溜秋的书签，双击运行</p>
</blockquote>
</li>
<li>运行笔记本中的所有代码<br><img src="/img/downloaded/aHR0cHM6_ee4bb5641c0b436faffe246b30265603.png" alt="在这里插入图片描述"></li>
<li>等待结果出来<br><img src="/img/downloaded/aHR0cHM6_21c0df2a98f545b29c1d63ead8a5875f.png" alt="在这里插入图片描述"><br>可以看到多了一个文件夹和文件<blockquote>
<p>右键下载<strong>result&#x2F;submission.csv</strong>文件（<strong>download</strong>）</p>
</blockquote>
</li>
</ol>
<p><img src="/img/downloaded/aHR0cHM6_62f2ab77362b42bc9f367cc35b494ac8.png" alt="在这里插入图片描述"></p>
<h4 id="注意用完平台记得关闭实例（右上角）"><a href="#注意用完平台记得关闭实例（右上角）" class="headerlink" title="注意用完平台记得关闭实例（右上角）!!!"></a><font color="red" size = "1" >注意用完平台记得关闭实例（右上角）!!!</font></h4><h4 id="注意用完平台记得关闭实例（右上角）-1"><a href="#注意用完平台记得关闭实例（右上角）-1" class="headerlink" title="注意用完平台记得关闭实例（右上角）!!!"></a><font color="red" size = "2" >注意用完平台记得关闭实例（右上角）!!!</font></h4><h4 id="注意用完平台记得关闭实例（右上角）-2"><a href="#注意用完平台记得关闭实例（右上角）-2" class="headerlink" title="注意用完平台记得关闭实例（右上角）!!! "></a><font color="red" size = "3" >注意用完平台记得关闭实例（右上角）!!! </font></h4><p><img src="/img/downloaded/aHR0cHM6_00d5071a6a4f47ca960e424701f6ee83.png" alt="在这里插入图片描述"><br>tips: 算力充足可以当我没说,不关的话时长会一直使用</p>
<h2 id="提交文件获得第一个分数"><a href="#提交文件获得第一个分数" class="headerlink" title="提交文件获得第一个分数"></a>提交文件获得第一个分数</h2><p>平台：<a target="_blank" rel="noopener" href="http://competition.sais.com.cn/competitionDetail/532230/format"> 上海科学智能研究院 </a></p>
<blockquote>
<p>注册和实名制略过</p>
</blockquote>
<h3 id="点击提交结果和选中刚刚下载的文件等待上传"><a href="#点击提交结果和选中刚刚下载的文件等待上传" class="headerlink" title="点击提交结果和选中刚刚下载的文件等待上传"></a>点击提交结果和选中刚刚下载的文件等待上传</h3><p><img src="/img/downloaded/aHR0cHM6_244591e9908741fea87392f2f0b922dd.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_31f7f73a377a4c258dcc762529a674ba.png" alt="在这里插入图片描述"></p>
<h3 id="点击我的成绩查看分数"><a href="#点击我的成绩查看分数" class="headerlink" title="点击我的成绩查看分数"></a>点击我的成绩查看分数</h3><p><img src="/img/downloaded/aHR0cHM6_efc7fa8898c945a68fa54f42e5207e63.png" alt="在这里插入图片描述"><br>其中task1中只选择了部分作为特征值，可以将全部的有效数据转换成特征值，必涨点。<br><img src="/img/downloaded/aHR0cHM6_add42f7cd5224b7bb3c98235ac281141.png" alt="在这里插入图片描述"></p>
<h3 id="训练数据表头说明"><a href="#训练数据表头说明" class="headerlink" title="训练数据表头说明"></a>训练数据表头说明</h3><blockquote>
<p>数据来源于官网</p>
</blockquote>
<p><img src="/img/downloaded/aHR0cHM6_a59fef77e4c14944adf799a4de3ebb0c.png" alt="在这里插入图片描述"></p>
<h4 id="特征的分析总结"><a href="#特征的分析总结" class="headerlink" title="特征的分析总结"></a>特征的分析总结</h4><table>
<thead>
<tr>
<th>特征类别</th>
<th>特征字段名称</th>
<th>特征描述</th>
<th>分析目的</th>
</tr>
</thead>
<tbody><tr>
<td>基因特异性</td>
<td>gene_target_symbol_name</td>
<td>靶基因符号名称</td>
<td>研究不同基因名称对siRNA设计的影响</td>
</tr>
<tr>
<td></td>
<td>gene_target_ncbi_id</td>
<td>靶基因的NCBI标识</td>
<td>研究不同NCBI ID对siRNA设计的影响</td>
</tr>
<tr>
<td></td>
<td>gene_target_species</td>
<td>靶基因参考序列的物种</td>
<td>研究不同物种对siRNA沉默效率的影响</td>
</tr>
<tr>
<td>siRNA序列特征</td>
<td>siRNA_sense_seq</td>
<td>siRNA的sense序列</td>
<td>分析sense序列设计对沉默效率的影响</td>
</tr>
<tr>
<td></td>
<td>siRNA_antisense_seq</td>
<td>siRNA的antisense序列</td>
<td>分析antisense序列设计对沉默效率的影响</td>
</tr>
<tr>
<td></td>
<td>modified_siRNA_sense_seq</td>
<td>带修饰的siRNA的sense序列</td>
<td>分析修饰对siRNA功能的影响</td>
</tr>
<tr>
<td></td>
<td>modified_siRNA_antisense_seq</td>
<td>带修饰的siRNA的antisense序列</td>
<td>分析修饰对siRNA功能的影响</td>
</tr>
<tr>
<td>siRNA浓度和单位</td>
<td>siRNA_concentration</td>
<td>实验使用的siRNA浓度</td>
<td>研究不同浓度对沉默效率的影响</td>
</tr>
<tr>
<td></td>
<td>concentration_unit</td>
<td>siRNA浓度单位</td>
<td>研究不同单位对siRNA浓度影响的理解</td>
</tr>
<tr>
<td>转染方法</td>
<td>Transfection_method</td>
<td>转染方法</td>
<td>分析不同转染技术对siRNA传递和沉默效果的影响</td>
</tr>
<tr>
<td>转染后持续时间</td>
<td>Duration_after_transfection_h</td>
<td>转染后持续时间</td>
<td>了解转染后不同时间点的沉默效果</td>
</tr>
<tr>
<td>序列分解列表</td>
<td>modified_siRNA_sense_seq_list</td>
<td>带修饰的siRNA的sense序列分解列表</td>
<td>识别关键核苷酸位点，优化siRNA设计</td>
</tr>
<tr>
<td></td>
<td>modified_siRNA_antisense_seq_list</td>
<td>带修饰的siRNA的antisense序列分解列表</td>
<td>识别关键核苷酸位点，优化siRNA设计</td>
</tr>
<tr>
<td>靶基因序列</td>
<td>gene_target_seq</td>
<td>靶基因的参考序列</td>
<td>分析siRNA与靶基因序列匹配程度对沉默效率的影响</td>
</tr>
<tr>
<td>沉默效率</td>
<td>mRNA_remaining_pct</td>
<td>实验后mRNA的剩余百分比</td>
<td>评估不同条件下siRNA沉默效率的直接指标</td>
</tr>
</tbody></table>
<blockquote>
<p>目前尝试了 计算序列的长度 、计算序列的熵值、序列中腺嘌呤（A）、胸腺嘧啶（T）、胞嘧啶（C）和鸟嘌呤（G）的数目、GC含量、序列的熵值</p>
</blockquote>
<p>创建了两个函数作为特征</p>
<ol>
<li><p><code>calculate_sequence_features</code> 函数：</p>
<ul>
<li>它首先计算序列的长度。</li>
<li>然后计算序列中腺嘌呤（A）、胸腺嘧啶（T）、胞嘧啶（C）和鸟嘌呤（G）的数目，并由此计算出它们的相对频率。</li>
<li>接着计算GC含量，即序列中G和C的比例，这是影响DNA稳定性的一个重要因素。</li>
<li>计算序列的熵值，熵是一个度量序列随机性或复杂性的指标。熵越高，表示序列的多样性越高，没有明显的偏好性。</li>
</ul>
</li>
<li><p><code>calculate_entropy</code> 函数：</p>
<ul>
<li>计算序列中每个核苷酸（A、C、G、T）的数目。</li>
<li>用一个字典来存储每个核苷酸的计数。</li>
<li>遍历这个字典，对每个非零计数的核苷酸，使用公式 $-p \log_2(p)$  来计算其对熵的贡献。</li>
</ul>
</li>
</ol>
<p>（比赛原因先不贴代码）</p>
<blockquote>
<p>至此Task1 baseline 任务完成 </p>
</blockquote>
<h2 id="Task1-知识点终结"><a href="#Task1-知识点终结" class="headerlink" title="Task1 知识点终结"></a>Task1 知识点终结</h2><h3 id="基因组分词器类"><a href="#基因组分词器类" class="headerlink" title="基因组分词器类"></a>基因组分词器类</h3><p>基因组分词器的目的是将基因组序列分割成固定长度的n-gram片段。这是为了进一步处理或分析基因组数据时的需要。</p>
<p><strong>基因组数据通常是由ACGT四个字母（腺嘌呤、胞嘧啶、鸟嘌呤和胸腺嘧啶）组成的序列。</strong> </p>
<h4 id="n-gram"><a href="#n-gram" class="headerlink" title="n-gram"></a>n-gram</h4><blockquote>
<p>指由n个连续字母构成的片段。将基因组序列分割成n-gram片段可以帮助我们理解基因组的结构和功能。</p>
</blockquote>
<p>基因组分词器将基因组序列分割成固定长度的n-gram片段可以用于以下应用：</p>
<ul>
<li><strong>基因组注释</strong>：通过分析n-gram片段可以识别基因、启动子、转录因子结合位点等功能区域。</li>
<li><strong>基因组比对</strong>：将n-gram片段与已知的基因组序列进行比对，可以找到相似的片段并识别基因的同源性。</li>
<li><strong>基因组序列分类</strong>：通过分析n-gram片段可以将不同物种的基因组序列进行分类。</li>
</ul>
<h3 id="GRU的神经网络模型"><a href="#GRU的神经网络模型" class="headerlink" title="GRU的神经网络模型"></a>GRU的神经网络模型</h3><blockquote>
<p>GRU是一种循环神经网络（RNN）模型，全称为Gated Recurrent Unit。它是一种改进的RNN架构，用于处理序列数据，尤其在自然语言处理和语音识别等任务中表现出色。</p>
</blockquote>
<p>GRU通过<strong>引入门控机制来解决传统RNN存在的短期记忆和长期记忆不平衡的问题</strong>。它具有两个门控单元：<strong>重置门（reset gate）和更新门（update gate）</strong>。重置门控制了当前状态如何与先前状态相结合，而更新门控制了用于传递信息的新状态的计算。</p>
<blockquote>
<p>GRU单元结构如下图所示<br><img src="/img/downloaded/aHR0cHM6_e5feeae81be9445ca8263ebf1a870248.png" alt="在这里插入图片描述"><br>GRU是Ilya Sutskever和Oriol Vinyals等人在2014年提出的一种改进的RNN单元，它旨在解决传统RNN在处理长序列时出现的梯度消失或梯度爆炸问题。</p>
</blockquote>
<p>GRU的核心思想是引入两个门控机制：<strong>更新门（Update Gate）和重置门（Reset Gate）。<strong>这两个门控机制允许模型</strong>动态地决定在每个时间步上应该保留多少之前的信息，以及应该更新多少当前的信息</strong>。这使得GRU能够更好地捕捉长距离依赖关系。</p>
<h4 id="GRU的数学模型"><a href="#GRU的数学模型" class="headerlink" title="GRU的数学模型"></a>GRU的数学模型</h4><h5 id="更新门（Update-Gate）"><a href="#更新门（Update-Gate）" class="headerlink" title="更新门（Update Gate）"></a>更新门（Update Gate）</h5><p>更新门决定了在当前时间步应该保留多少之前的隐藏状态。更新门的公式如下：</p>
<p>$$<br>z_t &#x3D; \sigma(W_z \cdot [h_{t-1}, x_t])<br>$$</p>
<p>其中，$z_t$ 是更新门的输出，$W_z$ 是更新门的权重矩阵，$\sigma$ 是<strong>sigmoid函数</strong>（不懂的后面有讲 sigmoid函数）。</p>
<h5 id="重置门（Reset-Gate）"><a href="#重置门（Reset-Gate）" class="headerlink" title="重置门（Reset Gate）"></a>重置门（Reset Gate）</h5><p>重置门决定了在当前时间步应该忽略多少之前的隐藏状态。重置门的公式如下：</p>
<p>$$<br>r_t &#x3D; \sigma(W_r \cdot [h_{t-1}, x_t])<br>$$</p>
<p>其中，$r_t$ 是重置门的输出，$W_r$ 是重置门的权重矩阵。</p>
<h5 id="候选隐藏状态（Candidate-Hidden-State）"><a href="#候选隐藏状态（Candidate-Hidden-State）" class="headerlink" title="候选隐藏状态（Candidate Hidden State）"></a>候选隐藏状态（Candidate Hidden State）</h5><p>候选隐藏状态是当前时间步的新信息，其公式如下：</p>
<p>$$<br>\tilde{h}<em>t &#x3D; \tanh(W \cdot [r_t \odot h</em>{t-1}, x_t])<br>$$</p>
<p>其中，$\tilde{h}_t$ 是候选隐藏状态，$W$ 是候选隐藏状态的权重矩阵，$\odot$ 表示<strong>Hadamard乘积</strong>(不懂的后面有讲 Hadamard乘积)。</p>
<h5 id="最终隐藏状态（Final-Hidden-State）"><a href="#最终隐藏状态（Final-Hidden-State）" class="headerlink" title="最终隐藏状态（Final Hidden State）"></a>最终隐藏状态（Final Hidden State）</h5><p>最终隐藏状态结合了之前保留的信息和当前的新信息，其公式如下：</p>
<p>$$<br>h_t &#x3D; (1 - z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t<br>$$</p>
<p>其中，$h_t$ 是最终的隐藏状态。　</p>
<p><strong>GRU在自然语言处理、语音识别和时间序列预测等领域有着广泛的应用</strong>。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p><strong>相比于普通的RNN模型，GRU具有更好的记忆能力和更强的建模能力，同时减少了参数数量，使得训练过程更加高效。</strong> 由于其优秀的性能和实用性，GRU已经成为经典的循环神经网络模型之一，并被广泛应用于各种序列数据分析任务中。</p>
<h3 id="学科知识"><a href="#学科知识" class="headerlink" title="学科知识"></a>学科知识</h3><h4 id="RNA干扰（RNAi）"><a href="#RNA干扰（RNAi）" class="headerlink" title="RNA干扰（RNAi）"></a>RNA干扰（RNAi）</h4><blockquote>
<p><strong>RNA干扰（RNAi）是一种细胞内的基因调控机制，通过通过RNA分子的干扰来抑制特定基因的表达。</strong></p>
</blockquote>
<p>RNAi在细胞内通过两种途径实现：<strong>小干扰RNA（siRNA） 和微小RNA（miRNA）</strong>。</p>
<p>在RNAi中，基因表达的抑制通常发生在转录后水平。当特定基因的DNA序列转录成RNA时，RNA聚合酶将生成多个复制的RNA分子。<strong>这些RNA分子中的一部分可以通过Dicer酶切割成长度约为21-23个核苷酸的小片段，即siRNA或miRNA</strong>。这些小片段与蛋白质复合物<strong>形成RNA-诱导沉默复合物（RISC），并通过与靶标mRNA相互作用来抑制其翻译或引起其降解</strong>。</p>
<p><strong>siRNA是通过外源性引入细胞的siRNA分子，通过与特定基因的mRNA相互作用来抑制其表达。</strong><br><strong>miRNA是内在于细胞的小RNA分子，能够识别并与多个基因的mRNA结合，从而调节多个基因的表达。</strong></p>
<p>RNAi在生物学研究中被广泛应用。可以<strong>用于研究基因功能，筛选潜在药物靶点，开发基因治疗方法等</strong>。<strong>还有潜力成为治疗疾病的方法，包括癌症、病毒感染和遗传疾病等</strong>。</p>
<h4 id="Dicer-酶"><a href="#Dicer-酶" class="headerlink" title="Dicer 酶"></a>Dicer 酶</h4><blockquote>
<p>RNA 干扰（RNAi）过程中的一个关键酶。它是一种 RNase III 家族的内切酶，在 RNAi 过程中起着重要的作用。</p>
</blockquote>
<p>Dicer 酶能够识别和切割双链 RNA（dsRNA）分子，将其切割成短的双链小干扰 RNA（siRNA）。</p>
<h4 id="RNAi作用机制"><a href="#RNAi作用机制" class="headerlink" title="RNAi作用机制"></a>RNAi作用机制</h4><blockquote>
<p>文档内容里面的这个讲的很详细我啃臭cv一份</p>
</blockquote>
<p>生物体内，RNAi首先将较长的双链RNA加工和切割成 siRNA，通常在每条链的3’末端带有2个核苷酸突出端。负责这种加工的酶是一种RNase III样酶，称为Dicer。形成后，siRNA与一种称为RNA诱导的沉默复合物（RNAinduced silencing complex, RISC）的多蛋白组分复合物结合。在RISC复合物中，siRNA链被分离，具有更稳定的5′末端的链通常被整合到活性RISC复合物中。然后，反义单链siRNA组分引导并排列在靶mRNA上，并通过催化RISC蛋白（Argonaute family（Ago2））的作用，mRNA被切割，即对应基因被沉默，表达蛋白能力削弱。<br><img src="/img/downloaded/aHR0cHM6_87da9c44cd4a49e493ce7ccd5998c7c7.png" alt="在这里插入图片描述"><br>传统siRNA设计原则与知识<br>  siRNA的沉默效率与众多因素相关，例如siRNA的稳定性、修饰、转染方法等。一些经验的生物知识可用于特征构建和AI模型的设计。</p>
<p>在siRNA一般设计过程中有以下知识和原则：</p>
<blockquote>
<ol>
<li>siRNA序列（一般为反义链）与靶向RNA互补。</li>
<li>siRNA序列长度一般在19～29nt之间。研究表明21nt相比27nt对靶基因的最大抑制率更容易达到。</li>
<li>一般来说，从靶基因起始密码子AUG下游50～100个核苷酸，或位于终止密码子50-100个核苷酸范围内的序列（确保转录基因为沉默状态）搜寻理想的siRNA序列，越靠近靶基因的3′端，其基因沉默效果可能越好。</li>
<li>一般设计好的潜在siRNA序列，会在GenBank数据库进行BLAST，去掉其他基因有显著同源性的靶序列（错误靶向）。</li>
<li>具体序列而言，最好为AA+(Nn)UU(N代表任意碱基，n为碱基数目)，其次是NA(Nn)UU和NA(Nn)NN。</li>
<li>一般情况下，siRNA的稳定性直接影响其最终在细胞中的敲低效率。在siRNA的反义链5’端第一个碱基尽量可能是为A或U; siRNA正义链的5’端第一个碱基尽量为G或C。</li>
<li>一般情况下，3′端的2个碱基使用突出的dTdT（deoxythymidine dinucleotide）取代，能够增强siRNA 双链复合体的稳定性，进而增加siRNA的敲低效率。</li>
<li>G&#x2F;C含量在30%～52%的siRNA序列，其沉默基因效果较好。研究表明40–55％ GC的含量敲低效率高于GC含量高于55%的。</li>
<li>一般来说，siRNA序列中连续2个及以上G&#x2F;C能够降低双链RNA内在稳定性，从而降低siRNA在细胞中的敲低效率；而连续3个以上的A和U可能终止由RNA Polymerase III介导的转录作用。siRNA序列中的重复序列或回文结构可能形成发夹状结构，这种结构的存在可以降低siRNA敲低效率。</li>
</ol>
</blockquote>
<h4 id="化学修饰siRNA"><a href="#化学修饰siRNA" class="headerlink" title="化学修饰siRNA"></a>化学修饰siRNA</h4><p>化学修饰siRNA是指通过<strong>在siRNA分子上引入化学修饰基团，改变其结构或性质的方法</strong>。这种修饰<strong>可以增强siRNA的稳定性、增加其目标特异性、改善细胞内进入能力</strong>等。</p>
<blockquote>
<p>常用的siRNA化学修饰包括以下几种:</p>
<ol>
<li>2’-氧甲基（2’-O-Me）修饰：这种修饰是将2’-羟基上的氧原子替换为甲基基团。它可以增加siRNA的稳定性，提高RNA酶的抵抗性。</li>
<li>2’-氟（2’-F）修饰：这种修饰是将2’-羟基上的氧原子替换为氟原子。它可以提高siRNA的稳定性和特异性，减少对非特定靶标的作用。</li>
<li>磷酸甲酯（PS）修饰：这种修饰是在磷酸二酯桥上引入甲酯基团。它可以增强siRNA的稳定性和细胞内进入能力。</li>
<li>枝状修饰：这种修饰是在siRNA分子上引入枝状结构，增加其稳定性和亲水性。</li>
<li>核苷酸修饰：这种修饰是在siRNA的碱基上引入修饰基团，例如甲基化、二硫苷化等。它可以改变siRNA与靶标RNA的配对能力和稳定性。</li>
</ol>
</blockquote>
<p>化学修饰siRNA可以<strong>优化其性能和提高其在RNAi研究和治疗中的应用潜力</strong>。但化学修饰可能会<strong>对siRNA的活性和毒性产生影响</strong>，因此在设计和选择修饰方案时需要进行<strong>全面的评估和优化</strong>。</p>
<h3 id="机器学习知识点"><a href="#机器学习知识点" class="headerlink" title="机器学习知识点"></a>机器学习知识点</h3><h4 id="MAE-Mean-Absolute-Error"><a href="#MAE-Mean-Absolute-Error" class="headerlink" title="MAE (Mean Absolute Error)"></a>MAE (Mean Absolute Error)</h4><blockquote>
<p><strong>表示预测值与真实值之间的平均绝对误差。</strong></p>
</blockquote>
<p>它计算每个样本的预测值与真实值之间的差值的绝对值，然后对所有样本取平均。</p>
<h4 id="召回率（Recall）"><a href="#召回率（Recall）" class="headerlink" title="召回率（Recall）"></a>召回率（Recall）</h4><blockquote>
<p><strong>表示所有真正例中被正确预测为正例的比例。</strong></p>
</blockquote>
<p>召回率可以衡量模型对正例的覆盖程度，即模型有多少能够找到真正例。</p>
<h4 id="F1得分"><a href="#F1得分" class="headerlink" title="F1得分"></a>F1得分</h4><blockquote>
<p><strong>精确度和召回率的调和平均值。</strong></p>
</blockquote>
<p>F1得分的取值范围为0到1，其中1表示最佳性能，0表示最差性能。</p>
<h4 id="精确度（Precision）"><a href="#精确度（Precision）" class="headerlink" title="精确度（Precision）"></a>精确度（Precision）</h4><blockquote>
<p><strong>表示被预测为正例中实际为正例的比例。</strong></p>
</blockquote>
<p>精确度可以衡量模型的准确性，即模型有多少预测为正例的样本真正是正例。</p>
<h5 id="赛题评分代码"><a href="#赛题评分代码" class="headerlink" title="赛题评分代码"></a>赛题评分代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># score = 50% × (1−MAE/100) + 50% × F1 × (1−Range-MAE/100)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_metrics</span>(<span class="params">y_true, y_pred, threshold=<span class="number">30</span></span>):</span><br><span class="line">    <span class="comment"># 计算平均绝对误差（MAE）</span></span><br><span class="line">    mae = np.mean(np.<span class="built_in">abs</span>(y_true - y_pred))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将真实值和预测值转换为二值标签，根据阈值进行分类</span></span><br><span class="line">    y_true_binary = (y_true &lt; threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">    y_pred_binary = (y_pred &lt; threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 阈值（30）</span></span><br><span class="line">    <span class="comment"># 创建一个掩码，用于将预测值限制在指定范围内</span></span><br><span class="line">    mask = (y_pred &gt;= <span class="number">0</span>) &amp; (y_pred &lt;= threshold)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在掩码范围内计算平均绝对误差（MAE）</span></span><br><span class="line">    range_mae = mean_absolute_error(y_true[mask], y_pred[mask]) <span class="keyword">if</span> mask.<span class="built_in">sum</span>() &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算精确度、召回率和F1分数</span></span><br><span class="line">    precision = precision_score(y_true_binary, y_pred_binary, average=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    recall = recall_score(y_true_binary, y_pred_binary, average=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    f1 = <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算综合评分</span></span><br><span class="line">    score = (<span class="number">1</span> - mae / <span class="number">100</span>) * <span class="number">0.5</span> + (<span class="number">1</span> - range_mae / <span class="number">100</span>) * f1 * <span class="number">0.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> score </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="综合评分"><a href="#综合评分" class="headerlink" title="综合评分"></a>综合评分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score = (<span class="number">1</span> - mae / <span class="number">100</span>) * <span class="number">0.5</span> + (<span class="number">1</span> - range_mae / <span class="number">100</span>) * f1 * <span class="number">0.5</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>最终的评分是根据模型在三个方面的表现进行计算的。</p>
<ol>
<li>通过计算平均绝对误差（MAE）来衡量模型的整体预测精度，MAE越小，表明模型的预测误差越小，得分越高。</li>
<li>通过计算在指定范围内的平均绝对误差（Range MAE），来衡量模型对于特定范围内的预测的准确性，Range MAE越小，表明模型在该范围内的预测误差越小，得分越高。</li>
<li>计算模型的分类性能，即精确度、召回率和F1得分。F1得分越高，表明模型在分类任务上的性能越好，得分越高。最终的评分是这几个值的加权平均数，其中MAE和Range MAE各占50%权重。<br>综合考虑这些因素，可以得出模型的总体表现得分。</li>
</ol>
</blockquote>
<h5 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h5><p><strong>在分类问题中，精确度和召回率是互相影响的指标</strong>。高精确度可能意味着模型只预测那些非常确信的正例，导致召回率较低。相反，高召回率可能意味着模型会将更多样本预测为正例，导致精确度较低。因此，F1得分作为精确度和召回率的综合指标，可以平衡这两个指标的表现。<strong>在评估模型性能时，通常会综合考虑精确度、召回率和F1得分。</strong></p>
<h4 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h4><blockquote>
<p>一种常用的激活函数，用于在神经网络中引入非线性。</p>
</blockquote>
<p>它的数学表达式如下：</p>
<p>$$<br>sigmoid(x) &#x3D; 1 &#x2F; (1 + exp(-x))<br>$$</p>
<p>其中，$exp(-x)$表示e的-x次方，e是自然常数。</p>
<p><strong>Sigmoid函数的输出值范围在0到1之间，通常用于将输入值映射到一个概率分布，或者作为二分类问题中的激活函数。</strong></p>
<p>在GRU单元中，Sigmoid函数被用于计算两个门控向量：更新门（update gate）和重置门（reset gate）。这两个门控向量通过Sigmoid函数将输入向量和先前的隐藏状态向量映射到0到1之间的值，以控制它们对更新和重置操作的贡献。</p>
<p><strong>更新门决定了先前的隐藏状态应该如何被保留或更新，而重置门决定了先前的隐藏状态如何与当前输入进行组合。<br>Sigmoid函数在GRU单元中通过限制门控向量的取值范围，使得GRU单元能够自适应地更新和遗忘信息，并有效地处理输入序列数据。</strong></p>
<h4 id="Hadamard乘积"><a href="#Hadamard乘积" class="headerlink" title="Hadamard乘积"></a>Hadamard乘积</h4><blockquote>
<p>也称为元素级乘积或逐元素乘积，是一种运算，用来<strong>对两个具有相同维度的向量、矩阵或张量进行逐元素的相乘</strong>。</p>
</blockquote>
<p>对于两个维度相同的向量 A 和 B，Hadamard乘积的运算规则为：<br>$$<br>C &#x3D; A ⊙ B<br>$$<br>其中 ⊙ 表示Hadamard乘积运算，C 是结果向量，C 的每个元素都等于 A 和 B 对应位置元素的乘积。</p>
<p>对于矩阵和张量，Hadamard乘积的运算规则与向量相同，只不过是在对应位置的元素进行相乘。<br><strong>Hadamard乘积通常用于逐元素操作，如逐元素乘法、逐元素加法等。</strong><br>它与矩阵乘法或点积运算不同，<strong>矩阵乘法是对应位置元素的乘积再求和</strong>，<br>而<strong>Hadamard乘积是对应位置元素直接相乘。</strong><br>Hadamard乘积<strong>在深度学习中经常用于一些操作，如逐元素激活函数、逐元素损失函数、逐元素操作的正则化等</strong>。它可以帮助模型学习非线性关系，同时保持数据的维度不变。</p>
<h1 id="Task2"><a href="#Task2" class="headerlink" title="Task2"></a>Task2</h1><blockquote>
<p>前面了解了赛题，这个主要讲baseline代码，入门RNN和特征工程</p>
</blockquote>
<h2 id="解读官方baseline"><a href="#解读官方baseline" class="headerlink" title="解读官方baseline"></a>解读官方baseline</h2><h2 id="set-random-seed"><a href="#set-random-seed" class="headerlink" title="set_random_seed"></a>set_random_seed</h2><blockquote>
<p>统一设置随机种子</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">set_random_seed</span>(<span class="params">seed</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    设置随机种子，确保结果可复现。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        seed (int): 随机种子值。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        无</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    np.random.seed(seed)  <span class="comment"># 设置NumPy的随机种子</span></span><br><span class="line">    random.seed(seed)  <span class="comment"># 设置Python内置的随机数生成器的种子</span></span><br><span class="line">    torch.manual_seed(seed)  <span class="comment"># 设置PyTorch的随机种子</span></span><br><span class="line">    torch.cuda.manual_seed(seed)  <span class="comment"># 设置CUDA的随机种子</span></span><br><span class="line">    torch.cuda.manual_seed_all(seed)  <span class="comment"># 设置所有CUDA设备的随机种子</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span>  <span class="comment"># 确保每次卷积算法选择都是确定的</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span>  <span class="comment"># 关闭CuDNN自动优化功能，确保结果可复现</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里做了这些操作</p>
</blockquote>
<ol>
<li>设置NumPy的随机种子 </li>
<li>设置Python内置的随机数生成器的种子 </li>
<li>设置PyTorch的随机种子 </li>
<li>设置CUDA的随机种子</li>
<li>设置所有CUDA设备的随机种子 </li>
<li>确保每次卷积算法选择是确定的 </li>
<li>关闭CuDNN自动优化功能</li>
</ol>
<p><strong>就是把每一个自动优化或随机种子的选项都关掉了，然后确保结果不会因为自动优化或随机数而改变,因而可以复现结果。</strong></p>
<h2 id="SiRNADataset"><a href="#SiRNADataset" class="headerlink" title="SiRNADataset"></a>SiRNADataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SiRNADataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, df, columns, vocab, tokenizer, max_len, is_test=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化SiRNADataset类</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            df (DataFrame): 包含数据的数据框</span></span><br><span class="line"><span class="string">            columns (list): 包含序列的列名列表</span></span><br><span class="line"><span class="string">            vocab (Vocab): 词汇表</span></span><br><span class="line"><span class="string">            tokenizer (Tokenizer): 分词器</span></span><br><span class="line"><span class="string">            max_len (int): 最大序列长度</span></span><br><span class="line"><span class="string">            is_test (bool, optional): 是否是测试集，默认为False</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.df = df</span><br><span class="line">        <span class="variable language_">self</span>.columns = columns</span><br><span class="line">        <span class="variable language_">self</span>.vocab = vocab</span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = tokenizer</span><br><span class="line">        <span class="variable language_">self</span>.max_len = max_len</span><br><span class="line">        <span class="variable language_">self</span>.is_test = is_test</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        返回数据集的长度</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.df)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        获取数据集中的第idx个样本</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            idx (int): 样本索引</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            seqs (list): 编码后的序列列表</span></span><br><span class="line"><span class="string">            target (tensor): 目标值张量（仅在非测试集模式下）</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        row = <span class="variable language_">self</span>.df.iloc[idx]</span><br><span class="line">        seqs = [<span class="variable language_">self</span>.tokenize_and_encode(row[col]) <span class="keyword">for</span> col <span class="keyword">in</span> <span class="variable language_">self</span>.columns]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_test:</span><br><span class="line">            <span class="keyword">return</span> seqs</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            target = torch.tensor(row[<span class="string">&#x27;mRNA_remaining_pct&#x27;</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            <span class="keyword">return</span> seqs, target</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tokenize_and_encode</span>(<span class="params">self, seq</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对序列进行分词和编码</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            seq (str): 待处理的序列</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            encoded_seq (tensor): 编码后的序列张量</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">in</span> seq:</span><br><span class="line">            tokens = seq.split()  <span class="comment"># 如果序列中包含空格，则按空格分词</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tokens = <span class="variable language_">self</span>.tokenizer.tokenize(seq)  <span class="comment"># 否则使用分词器进行分词</span></span><br><span class="line">        encoded = [<span class="variable language_">self</span>.vocab.stoi.get(token, <span class="number">0</span>) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]  <span class="comment"># 将分词后的每个词编码为对应的索引</span></span><br><span class="line">        padded = encoded + [<span class="number">0</span>] * (<span class="variable language_">self</span>.max_len - <span class="built_in">len</span>(encoded))  <span class="comment"># 将序列补齐到最大长度</span></span><br><span class="line">        <span class="keyword">return</span> torch.tensor(padded[:<span class="variable language_">self</span>.max_len], dtype=torch.long)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>定义了一个<strong>SiRNADataset类来创建一个自定义的PyTorch数据集对象</strong>。</p>
<p><strong>目的是将输入的数据框（df）中的序列数据分词、编码和填充，并返回编码后的序列和目标值</strong>。</p>
<h3 id="SiRNADataset类的方法"><a href="#SiRNADataset类的方法" class="headerlink" title="SiRNADataset类的方法"></a>SiRNADataset类的方法</h3><h4 id="初始化方法："><a href="#初始化方法：" class="headerlink" title="初始化方法："></a>初始化方法：</h4><blockquote>
<p>接受数据并处理成对象属性</p>
</blockquote>
<p>接收了下面这些数据并保存为对象的属性：</p>
<p> <strong>1. 接收数据框（df）<br> 2. 包含序列的列名（columns）<br> 3. 词汇表（vocab）<br> 4. 分词器（tokenizer）<br> 5. 最大序列长度（max_len）<br> 6. 否为测试集（is_test)</strong></p>
<h4 id="len-方法"><a href="#len-方法" class="headerlink" title="__len__方法"></a>__len__方法</h4><blockquote>
<p>返回数据框中的样本数量。</p>
</blockquote>
<h4 id="getitem-方法"><a href="#getitem-方法" class="headerlink" title="__getitem__方法"></a>__getitem__方法</h4><blockquote>
<p>根据给定的索引（idx），获取数据集中的第idx个样本。</p>
</blockquote>
<p>首先根据索引获取数据框中的一行数据，然后对每一列的序列数据进行分词和编码。</p>
<ul>
<li>如果是测试集模式（is_test为True），则返回编码后的序列。</li>
<li>如果不是测试集模式，则将目标值转换为张量，并返回编码后的序列和目标值。</li>
</ul>
<h4 id="tokenize-and-encode方法"><a href="#tokenize-and-encode方法" class="headerlink" title="tokenize_and_encode方法"></a>tokenize_and_encode方法</h4><blockquote>
<p>接收一个序列（seq，这个就是我们要处理的序列）作为输入，根据序列是否包含空格，选择不同的方式分词。</p>
</blockquote>
<p>这里有两种分词方法:</p>
<ul>
<li>包含空格的序列，将其按空格进行分词；  （这个就是对<strong>modified_siRNA_antisense_seq_list(modified_xxxx)</strong> 的数据，它本身已经根据空格分好了）</li>
<li>常规序列，使用指定的分词器进行分词。</li>
</ul>
<p>然后，将分词后的token转换为词汇表中对应的索引，未知的token使用索引0（代表$<pad>$）。最后将编码后的序列填充到最大长度，返回张量格式的序列。</p>
<h2 id="SiRNAModel-类"><a href="#SiRNAModel-类" class="headerlink" title="SiRNAModel 类"></a>SiRNAModel 类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SiRNAModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_dim=<span class="number">200</span>, hidden_dim=<span class="number">256</span>, n_layers=<span class="number">3</span>, dropout=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化SiRNA模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            vocab_size (int): 词汇表大小</span></span><br><span class="line"><span class="string">            embed_dim (int): 嵌入维度 (默认值: 200)</span></span><br><span class="line"><span class="string">            hidden_dim (int): 隐藏层维度 (默认值: 256)</span></span><br><span class="line"><span class="string">            n_layers (int): GRU层的层数 (默认值: 3)</span></span><br><span class="line"><span class="string">            dropout (float): Dropout层的丢弃率 (默认值: 0.5)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(SiRNAModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=<span class="number">0</span>)  <span class="comment"># 初始化嵌入层</span></span><br><span class="line">        <span class="variable language_">self</span>.gru = nn.GRU(embed_dim, hidden_dim, n_layers, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>, dropout=dropout)  <span class="comment"># 初始化GRU层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(hidden_dim * <span class="number">4</span>, <span class="number">1</span>)  <span class="comment"># 初始化全连接层</span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)  <span class="comment"># 初始化Dropout层</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向传播函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            x (List[Tensor]): 输入序列列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">            Tensor: 模型的输出张量</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        embedded = [<span class="variable language_">self</span>.embedding(seq) <span class="keyword">for</span> seq <span class="keyword">in</span> x]  <span class="comment"># 将输入序列传入嵌入层</span></span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> embed <span class="keyword">in</span> embedded:</span><br><span class="line">            x, _ = <span class="variable language_">self</span>.gru(embed)  <span class="comment"># 传入GRU层</span></span><br><span class="line">            x = <span class="variable language_">self</span>.dropout(x[:, -<span class="number">1</span>, :])  <span class="comment"># 取最后一个隐藏状态，并进行dropout处理</span></span><br><span class="line">            outputs.append(x)</span><br><span class="line"></span><br><span class="line">        x = torch.cat(outputs, dim=<span class="number">1</span>)  <span class="comment"># 将所有序列的输出拼接起来</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)  <span class="comment"># 传入全连接层</span></span><br><span class="line">        <span class="keyword">return</span> x.squeeze()  <span class="comment"># 返回结果</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这个类继承自nn.Module类，用来处理RNA序列。</p>
<ol>
<li><strong>先将输入序列列表x传入嵌入层</strong>，</li>
<li>然后通过<strong>循环将每个序列的嵌入向量传入双向GRU层</strong>，<strong>取最后一个隐藏状态</strong>，<strong>并进行dropout处理</strong>。</li>
<li>最后，<strong>将所有序列的输出拼接起来，并传入一个全连接层，输出一个标量结果</strong>。</li>
</ol>
<h3 id="nn-Module类"><a href="#nn-Module类" class="headerlink" title="nn.Module类"></a>nn.Module类</h3><p><strong>nn.Module类是PyTorch中所有神经网络模型的基类</strong>，提供了一些<strong>基本的功能和方法，用于定义和管理神经网络模型的结构和参数</strong>。</p>
<h4 id="nn-Module类的作用有："><a href="#nn-Module类的作用有：" class="headerlink" title="nn.Module类的作用有："></a>nn.Module类的作用有：</h4><h5 id="定义模型的结构"><a href="#定义模型的结构" class="headerlink" title="定义模型的结构"></a>定义模型的结构</h5><blockquote>
<p><strong>通过__init__方法中定义各个层和模块，可以将不同的层组合在一起，构建出模型的结构。</strong></p>
</blockquote>
<h5 id="前向传播函数"><a href="#前向传播函数" class="headerlink" title="前向传播函数"></a>前向传播函数</h5><blockquote>
<p>通过forward方法中<strong>定义前向传播的过程</strong>，可以<strong>将输入数据在模型中传递，计算输出结果</strong>。</p>
</blockquote>
<h5 id="参数管理"><a href="#参数管理" class="headerlink" title="参数管理"></a>参数管理</h5><p>nn.Module类提供了一些方法，如<code>parameters()</code>和<code>named_parameters()</code>，可以自动追踪模型中所有的可学习参数，可以方便地进行参数的访问和管理。</p>
<h6 id="parameters"><a href="#parameters" class="headerlink" title="parameters()"></a><code>parameters()</code></h6><blockquote>
<p><code>parameters()</code>方法返回一个迭代器，该迭代器会遍历模型中的所有可学习参数。</p>
</blockquote>
<p>可学习参数是指那些需要在训练过程中进行优化调整的参数，例如神经网络中的权重和偏置项。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = SiRNAModel(...)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<h6 id="named-parameters"><a href="#named-parameters" class="headerlink" title="named_parameters()"></a><code>named_parameters()</code></h6><blockquote>
<p><code>named_parameters()</code>方法返回一个迭代器，该迭代器会遍历模型中的所有可学习参数，并为每个参数附上一个名称。</p>
</blockquote>
<p>这个方法<strong>在调试和模型分析时常见</strong>，可以方便地<strong>查看每个参数的名称和对应的数值</strong>。也<strong>可以利用这个方法来选择性地冻结或更新某些参数。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;embedding&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">        param.requires_grad = <span class="literal">False</span>  <span class="comment"># 冻结嵌入层的参数</span></span><br></pre></td></tr></table></figure>
<h5 id="模型保存和加载"><a href="#模型保存和加载" class="headerlink" title="模型保存和加载"></a>模型保存和加载</h5><blockquote>
<p>nn.Module类提供了方法，如<code>state_dict()</code>和<code>load_state_dict()</code>，可以方便地保存模型的状态和加载已保存的状态。</p>
</blockquote>
<p><strong>继承自nn.Module类的子类可以自由定义自己的网络结构，并且可以利用nn.Module提供的方法和功能来管理参数和实现前向传播过程。</strong><br>还可以<strong>与优化器、损失函数、数据加载器</strong>等，<strong>进一步提升模型的训练和使用效果</strong>。</p>
<h5 id="state-dict"><a href="#state-dict" class="headerlink" title="state_dict()"></a><code>state_dict()</code></h5><blockquote>
<p><code>state_dict()</code>(状态字典)是一个Python字典对象，其中包含了模型的所有可学习参数的名称和对应的张量值。</p>
</blockquote>
<p><code>state_dict()</code>方法返回模型的状态字典，可以将其保存到文件中，以便在之后的时间点恢复模型的状态。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = SiRNAModel(...)</span><br><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;model.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h5 id="load-state-dict"><a href="#load-state-dict" class="headerlink" title="load_state_dict()"></a><code>load_state_dict()</code></h5><blockquote>
<p>用于加载之前保存的模型的状态字典。可以将保存的状态字典加载到同一类别的模型对象中，以便恢复模型的参数。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = SiRNAModel(...)</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;model.pth&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>通过<code>state_dict()</code>和<code>load_state_dict()</code>方法，可以方便地保存和加载模型的参数状态，以便进行模型的训练和推理。这些方法在迁移学习、继续训练以及模型部署等场景中常见。</p>
<h2 id="如何将序列转换成张量输入到模型里"><a href="#如何将序列转换成张量输入到模型里" class="headerlink" title="如何将序列转换成张量输入到模型里"></a>如何将序列转换成张量输入到模型里</h2><blockquote>
<p>关键代码是在<code>forward()</code>方法<br>方法: <code>forward(self, x)</code><br>参数: x (List[Tensor]): 输入序列列表</p>
</blockquote>
<p>   发现输入的是这个x，x又是输入的序列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> inputs,target <span class="keyword">in</span> train_loader:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;len(inputs):\n &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(inputs)))</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;inputs[0].shape:\n &#123;0&#125; &quot;</span>.<span class="built_in">format</span>(inputs[<span class="number">0</span>].shape))</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;intputs[0][0]:\n &#123;0&#125; &quot;</span>.<span class="built_in">format</span>(inputs[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;traget.shape:\n &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(target.shape))</span><br><span class="line">  <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p><img src="/img/downloaded/aHR0cHM6_91e9abd4fcdb4caa81d99e2e2132da2f.png" alt="在这里插入图片描述"><br>在处理siRNA序列数据时，我们首先注意到输入数据inputs包含两个元素，每个元素的尺寸为64×25。<br>这里的64表示批量处理的大小，而25代表每个序列的长度。通过观察inputs[0][0]，我们可以了解到siRNA的反义链序列（siRNA_antisense_seq）在经过向量化处理后的表现。在这里，<strong>序列的前7位是非零值，这些非零值代表了序列编码中每个字符的唯一标识符。</strong></p>
<blockquote>
<p>在这个模型的嵌入层初始化时我们做了这样一个操作，<br><img src="/img/downloaded/aHR0cHM6_965bd3ff86014a3986bcb223777759b1.png" alt="在这里插入图片描述"><br>其中<br><strong>vocab_size表示词汇表的大小<br>embed_dim表示嵌入向量的维度<br>padding_idx&#x3D;0表示对应的填充符号的索引。</strong></p>
</blockquote>
<p>为了使RNN模型能够有效处理这些数据，需要保证每个输入样本的长度一致，在创建模型时采取了<strong>填充（padding）策略</strong>（上方引用）。<br><strong>如果某个序列编码后的长度小于最大长度，我们会在其后补零，以确保所有序列在输入到RNN模型时具有统一的长度</strong>。<br>这里把所有序列都被填充至25位，来满足模型的输入要求。</p>
<h2 id="如何为siRNA序列分配唯一标识符"><a href="#如何为siRNA序列分配唯一标识符" class="headerlink" title="如何为siRNA序列分配唯一标识符"></a>如何为siRNA序列分配唯一标识符</h2><h3 id="首先进行分词处理"><a href="#首先进行分词处理" class="headerlink" title="首先进行分词处理"></a>首先进行分词处理</h3><h4 id="对于未格式化的siRNA-antisense-seq等序列"><a href="#对于未格式化的siRNA-antisense-seq等序列" class="headerlink" title="对于未格式化的siRNA_antisense_seq等序列"></a>对于未格式化的siRNA_antisense_seq等序列</h4><blockquote>
<p>使用GenomicTokenizer实现</p>
</blockquote>
<p>siRNA_antisense_seq序列通过每3个核苷酸一组划分，使用GenomicTokenizer实现，其中ngram和stride均设为3。</p>
<p>例如序列”AGCCGAGAU”，分词后得到[“AGC”, “CGA”, “GAU”]。</p>
<h4 id="对于格式化的modified-siRNA-antisense-seq-list等序列"><a href="#对于格式化的modified-siRNA-antisense-seq-list等序列" class="headerlink" title="对于格式化的modified_siRNA_antisense_seq_list等序列"></a>对于格式化的modified_siRNA_antisense_seq_list等序列</h4><blockquote>
<p>modified_siRNA_antisense_seq_list序列根据空格已分词。</p>
</blockquote>
<h3 id="基于数据集中所有token构建词汇表。"><a href="#基于数据集中所有token构建词汇表。" class="headerlink" title="基于数据集中所有token构建词汇表。"></a>基于数据集中所有token构建词汇表。</h3><blockquote>
<p>该词汇表映射token至唯一标识符，即索引。映射过程确保RNN模型接收数值形式输入，同时学习序列中不同token间关系。</p>
</blockquote>
<p>使用<code>GenomicVocab.create</code>方法基于<code>tokens</code>创建基因词汇表。</p>
<h3 id="创建基因词汇表代码"><a href="#创建基因词汇表代码" class="headerlink" title="创建基因词汇表代码"></a>创建基因词汇表代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建分词器</span></span><br><span class="line">```python</span><br><span class="line">tokenizer = GenomicTokenizer(ngram=<span class="number">3</span>, stride=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建词汇表</span></span><br><span class="line">all_tokens = []  <span class="comment"># 用于存储所有的tokens</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:  <span class="comment"># 遍历每一列</span></span><br><span class="line">    <span class="keyword">for</span> seq <span class="keyword">in</span> train_data[col]:  <span class="comment"># 遍历每个序列</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">in</span> seq:  <span class="comment"># 如果序列中包含空格，则说明是修改过的序列</span></span><br><span class="line">            all_tokens.extend(seq.split())  <span class="comment"># 将序列按空格进行切分，并添加到all_tokens中</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 如果序列中不包含空格，则使用tokenizer对序列进行分词</span></span><br><span class="line">            all_tokens.extend(tokenizer.tokenize(seq))  <span class="comment"># 将分词后的结果添加到all_tokens中</span></span><br><span class="line"></span><br><span class="line">vocab = GenomicVocab.create(all_tokens, max_vocab=<span class="number">10000</span>, min_freq=<span class="number">1</span>)  <span class="comment"># 使用all_tokens创建基因词汇表，设定最大词汇量为10000，词频阈值为1</span></span><br></pre></td></tr></table></figure>
<ol>
<li>先创建一个<code>GenomicTokenizer</code>对象，用于对序列进行分词。</li>
<li>然后遍历数据集中的每个序列，如果序列中包含空格，则说明是修改过的序列，直接按空格切分并添加到<code>all_tokens</code>中；</li>
<li>如果序列中不包含空格，则使用分词器<code>tokenizer</code>对序列进行分词，并将结果添加到<code>all_tokens</code>中。</li>
<li>最后使用<code>GenomicVocab.create</code>方法基于<code>all_tokens</code>创建基因词汇表，设定最大词汇量为10000，词频阈值为1。</li>
</ol>
<h4 id="来获得序列的最大长度"><a href="#来获得序列的最大长度" class="headerlink" title="来获得序列的最大长度"></a>来获得序列的最大长度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于计算训练数据中每列数据最大长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先使用嵌套的生成器表达式，遍历训练数据中的每一列</span></span><br><span class="line"><span class="comment"># 在内部生成器中，首先检查当前列的每个样本，判断是否包含空格</span></span><br><span class="line"><span class="comment"># 如果包含空格，则使用split()方法将字符串拆分成单词，并返回拆分后的单词个数</span></span><br><span class="line"><span class="comment"># 如果不包含空格，则使用tokenizer.tokenize()将字符串拆分成单词，并返回拆分后的单词个数</span></span><br><span class="line"><span class="comment"># 通过max函数将每列中的最大长度取出，并使用嵌套的生成器表达式再次计算所有列中的最大长度</span></span><br><span class="line">max_len = <span class="built_in">max</span>(</span><br><span class="line">    <span class="built_in">max</span>(</span><br><span class="line">        <span class="built_in">len</span>(seq.split()) <span class="keyword">if</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">in</span> seq <span class="keyword">else</span> <span class="built_in">len</span>(tokenizer.tokenize(seq))</span><br><span class="line">        <span class="keyword">for</span> seq <span class="keyword">in</span> train_data[col]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> columns</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="SiRNADataset类"><a href="#SiRNADataset类" class="headerlink" title="SiRNADataset类"></a>SiRNADataset类</h3><blockquote>
<p>完成上面的操作之后，在loader获取样本的时候把token转为索引，即我们通过转换成SiRNADataset类的过程中，让数据转换成索引</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SiRNADataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, df, columns, vocab, tokenizer, max_len, is_test=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化SiRNADataset类</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">        - df：包含数据的DataFrame</span></span><br><span class="line"><span class="string">        - columns：包含序列的列名</span></span><br><span class="line"><span class="string">        - vocab：词汇表</span></span><br><span class="line"><span class="string">        - tokenizer：分词器</span></span><br><span class="line"><span class="string">        - max_len：最大序列长度</span></span><br><span class="line"><span class="string">        - is_test：指示是否是测试集</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.df = df  <span class="comment"># 数据框</span></span><br><span class="line">        <span class="variable language_">self</span>.columns = columns  <span class="comment"># 包含序列的列名</span></span><br><span class="line">        <span class="variable language_">self</span>.vocab = vocab  <span class="comment"># 词汇表</span></span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = tokenizer  <span class="comment"># 分词器</span></span><br><span class="line">        <span class="variable language_">self</span>.max_len = max_len  <span class="comment"># 最大序列长度</span></span><br><span class="line">        <span class="variable language_">self</span>.is_test = is_test  <span class="comment"># 指示是否是测试集</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        获取数据集的长度</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回值：</span></span><br><span class="line"><span class="string">        - 数据集的长度</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.df)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        获取数据集中的第idx个样本</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">        - idx：样本索引</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回值：</span></span><br><span class="line"><span class="string">        - 如果是测试集模式，返回编码后的序列</span></span><br><span class="line"><span class="string">        - 如果是训练集模式，返回编码后的序列和对应的目标值</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        row = <span class="variable language_">self</span>.df.iloc[idx]  <span class="comment"># 获取第idx行数据</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对每一列进行分词和编码</span></span><br><span class="line">        seqs = [<span class="variable language_">self</span>.tokenize_and_encode(row[col]) <span class="keyword">for</span> col <span class="keyword">in</span> <span class="variable language_">self</span>.columns]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_test:</span><br><span class="line">            <span class="comment"># 仅返回编码后的序列（测试集模式）</span></span><br><span class="line">            <span class="keyword">return</span> seqs</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 获取目标值并转换为张量（训练集模式）</span></span><br><span class="line">            target = torch.tensor(row[<span class="string">&#x27;mRNA_remaining_pct&#x27;</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            <span class="comment"># 返回编码后的序列和目标值</span></span><br><span class="line">            <span class="keyword">return</span> seqs, target</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tokenize_and_encode</span>(<span class="params">self, seq</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对序列进行分词和编码</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">        - seq：输入的序列</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回值：</span></span><br><span class="line"><span class="string">        - 编码后的序列</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">in</span> seq:</span><br><span class="line">            <span class="comment"># 修改过的序列，按空格分词</span></span><br><span class="line">            tokens = seq.split()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 常规序列，使用分词器分词</span></span><br><span class="line">            tokens = <span class="variable language_">self</span>.tokenizer.tokenize(seq)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将token转换为索引，未知token使用0（&lt;pad&gt;）</span></span><br><span class="line">        encoded = [<span class="variable language_">self</span>.vocab.stoi.get(token, <span class="number">0</span>) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]</span><br><span class="line">        <span class="comment"># 将序列填充到最大长度</span></span><br><span class="line">        padded = encoded + [<span class="number">0</span>] * (<span class="variable language_">self</span>.max_len - <span class="built_in">len</span>(encoded))</span><br><span class="line">        <span class="comment"># 返回张量格式的序列</span></span><br><span class="line">        <span class="keyword">return</span> torch.tensor(padded[:<span class="variable language_">self</span>.max_len], dtype=torch.long)</span><br></pre></td></tr></table></figure>
<p>这个类继承自<strong>PyTorch的Dataset类</strong>，用于加载数据并将其传递给模型进行训练或预测。</p>
<p>在<code>__getitem__</code>方法中，根据索引idx获取对应的数据行。然后<strong>针对每个包含序列的列，调用<code>tokenize_and_encode</code>方法对序列进行分词和编码。</strong> 如果是测试集模式，直接返回编码后的序列；如果是训练集模式，还需获取目标值并将其转换为张量。然后，<code>tokenize_and_encode</code>方法用于对序列进行分词和编码。<strong>对于常规序列，使用传入的分词器对其进行分词；对于修改过的序列，直接按空格进行分词。然后将分词后的token转换为词汇表中的索引，未知token使用索引0表示。最后将序列填充到最大长度，并返回张量格式的序列。</strong></p>
<h4 id="Dataset类"><a href="#Dataset类" class="headerlink" title="Dataset类"></a>Dataset类</h4><blockquote>
<p>它是一个数据集的抽象接口，可以根据需要自定义数据集的读取和处理方式。</p>
</blockquote>
<p>在<strong>使用PyTorch进行训练和预测</strong>时，需要将<strong>数据加载到Dataset对象中</strong>，并<strong>通过DataLoader对象对数据进行批处理和数据加载</strong>。<br><strong>通过继承Dataset类，我们可以自定义数据集的处理逻辑，包括数据读取、数据预处理、数据转换等。</strong></p>
<p>我们需要实现__len__和__getitem__方法，分别用于获取数据集的长度和获取指定索引位置的样本。</p>
<p><strong>可以自定义Dataset类来灵活地处理不同类型的数据集，并将其传递给模型进行训练或预测。</strong></p>
<p>关于训练的模型前面在<code>SiRNAModel 类</code>时讲过，就不再重述</p>
<p>我们首先进行索引嵌入处理，即<strong>将离散的符号（例如单词、字符或基因序列片段）转换成连续的向量形式</strong>。过程中涉及<strong>将高维的稀疏表示（如独热编码）转换为低维的密集向量</strong>，以使得<strong>语义相近的符号在向量空间中的相对位置更接近</strong>。<br>转换后，嵌入向量的维度将从BatchSize * Length扩展为BatchSize * Length * EmbeddingSize，其中EmbeddingSize，也就是嵌入维度embed_dim，被设定为200。</p>
<h3 id="RNN（递归神经网络）知识点"><a href="#RNN（递归神经网络）知识点" class="headerlink" title="RNN（递归神经网络）知识点"></a>RNN（递归神经网络）知识点</h3><blockquote>
<p>一种专门用于处理序列数据的神经网络模型。<br>与传统的前馈神经网络不同，RNN具有反馈连接，可以将前面的输出作为后续输入的一部分，使其具有记忆性。</p>
</blockquote>
<p>RNN的基本结构是一个单元（cell）或节点，其中包含一个输入层、一个隐藏层和一个输出层。隐藏层中的神经元通过时间反馈连接，使得信息可以在不同时间步之间传递和共享。这种结构使得RNN能够处理任意长度的序列数据，并且能够捕捉到序列中的上下文信息。</p>
<blockquote>
<p>RNN的架构示意图<br><img src="/img/downloaded/aHR0cHM6_f48dc300b4e84e29aa59b0553582be4d.png" alt="在这里插入图片描述"><br>RNN，即循环神经网络（Recurrent Neural Network），是一种适合于序列数据的深度学习模型。它与传统的前馈神经网络（如多层感知机）不同，RNN 能够处理序列中的动态特征，即能够捕捉时间序列中的动态依赖关系。</p>
</blockquote>
<p>RNN的数学表达可以简化为以下形式：<br>$$<br> h_t &#x3D; f(W_{hh} h_{t-1} + W_{xh} x_t + b_h)<br>$$<br>$$<br>y_t &#x3D; f(W_{hy} h_t + b_y)<br>$$</p>
<p>其中，<br>$h_t$是时间步$t$的隐藏状态。<br>$x_t$是时间步$t$的输入向量。<br>$W_{hh}$和$W_{xh}$分别是从上一个时间步的隐藏状态到当前隐藏状态、从当前时间步的输入到当前隐藏状态的权重矩阵。<br>$b_h$是隐藏层的偏置项。<br>$W_{hy}$是从隐藏状态到输出的权重矩阵。<br>$b_y$是输出层的偏置项。<br>$f$是激活函数。</p>
<h4 id="RNN的训练过程"><a href="#RNN的训练过程" class="headerlink" title="RNN的训练过程"></a>RNN的训练过程</h4><p>在RNN中，<strong>每个时间步都有一个输入和一个输出</strong>。输入可以是任意维度的向量，而输出通常是一个固定大小的向量或者是一个标量。RNN通过学习一组可学习的权重参数来对输入序列进行处理，并输出相应的预测结果。</p>
<p><strong>RNN的训练过程通常是使用反向传播算法来优化模型的权重参数。</strong> 由于反向传播算法的梯度消失问题，在处理长序列时RNN往往会出现难以学习到长期依赖关系的情况。为了解决这个问题，一种<strong>常用的改进版本是长短期记忆网络（LSTM）和门控循环单元（GRU），它们能够更有效地捕捉和利用序列中的长期依赖关系。</strong> </p>
<h4 id="RNN-的特点"><a href="#RNN-的特点" class="headerlink" title="RNN 的特点"></a>RNN 的特点</h4><ul>
<li><strong>循环连接</strong>：RNN的每个神经元不仅与下一层的神经元相连，而且与同一层的下一个时间步的神经元相连，形成了一个循环结构。    </li>
<li><strong>时间步</strong>：RNN在序列的每个时间步上都会进行计算，每个时间步的输出不仅依赖于当前的输入，还依赖于前一个时间步的输出。</li>
<li><strong>隐藏状态</strong>：RNN通过隐藏状态（hidden state）来传递之前时间步的信息。隐藏状态可以看作是网络对之前序列信息的总结。  </li>
<li><strong>参数共享</strong>：在RNN中，同一网络参数在每个时间步上都会被重复使用，这简化了模型结构，但同时也带来了一些挑战，如梯度消失或梯度爆炸问题。</li>
<li><strong>长短期记忆（LSTM）和门控循环单元（GRU）</strong>：这两种网络结构是对传统RNN的改进，它们通过引入门控机制来解决梯度消失问题，使得网络能够学习长期依赖关系。</li>
<li><strong>应用领域</strong>：RNN广泛应用于自然语言处理（NLP）、语音识别、时间序列预测等领域，特别是在需要处理序列数据和捕捉时间依赖性的任务中。</li>
<li><strong>训练挑战</strong>：RNN的训练可能面临梯度消失或梯度爆炸的问题，这使得训练过程可能不稳定。现代优化技术如梯度裁剪或使用更高级的优化器（如Adam）可以帮助缓解这些问题。</li>
<li><strong>变长序列处理</strong>：RNN能够处理不同长度的序列，但需要通过填充（padding）或截断来保证输入序列具有相同的长度。</li>
</ul>
<h2 id="数据的特征工程-（EDA）"><a href="#数据的特征工程-（EDA）" class="headerlink" title="数据的特征工程 （EDA）"></a>数据的特征工程 （EDA）</h2><p>在官方baseline中，得分较低可能是由于数据特征简单、序列特征构造粗糙以及数据量不足等原因。为了解决序列特征问题，可以将其转化为表格问题并进行特征工程。</p>
<h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><h4 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h4><p>检查数据是否存在缺失值，并根据具体情况决定如何处理缺失值，如删除、填充等。</p>
<h4 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h4><p>检测和处理数据中的异常值，包括通过可视化和统计学方法识别异常值，并根据业务逻辑进行处理。</p>
<h3 id="处理类别型变量"><a href="#处理类别型变量" class="headerlink" title="处理类别型变量"></a>处理类别型变量</h3><h4 id="统计唯一值"><a href="#统计唯一值" class="headerlink" title="统计唯一值"></a>统计唯一值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.gene_target_symbol_name.nunique()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>计算DataFrame（df）中某一列（gene_target_symbol_name）中唯一值（unique value）的数量（nunique）。也就是统计该列中有多少不重复的值。</p>
</blockquote>
<h5 id="nunique"><a href="#nunique" class="headerlink" title="nunique()"></a><code>nunique()</code></h5><p><code>nunique()</code>函数是<strong>pandas库</strong>中的一个方法，用于<strong>计算一个序列（Series）或数据框（DataFrame）中唯一值的数量</strong>。<br>语法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Series.nunique(dropna=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line"></span><br><span class="line">DataFrame.nunique(axis=<span class="number">0</span>, dropna=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li><code>dropna</code>：是否排除缺失值，默认为True，即排除缺失值。</li>
<li><code>axis</code>：对于数据框，可以指定按行（axis&#x3D;0）或按列（axis&#x3D;1）计算唯一值的数量。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">data = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">unique_count = data.nunique()</span><br><span class="line"><span class="built_in">print</span>(unique_count)  <span class="comment"># 输出：5</span></span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;B&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">unique_count_col = df.nunique(axis=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(unique_count_col)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="comment"># A    3</span></span><br><span class="line"><span class="comment"># B    2</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure>

<h3 id="统计每个值的频率分布"><a href="#统计每个值的频率分布" class="headerlink" title="统计每个值的频率分布"></a>统计每个值的频率分布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.gene_target_symbol_name.value_counts()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这段代码是用来计算DataFrame（df）中某一列（gene_target_symbol_name）中每个唯一值（unique value）出现的次数（count）。它会返回一个Series对象，其中索引是唯一值，值是对应唯一值的出现次数。通过这个可以快速了解该列中每个值的频率分布。</p>
</blockquote>
<h4 id="value-counts"><a href="#value-counts" class="headerlink" title="value_counts()"></a><code>value_counts()</code></h4><p><code>value_counts()</code>函数是<strong>pandas库</strong>中的一个方法，用于<strong>计算一个序列（Series）中每个唯一值的数量。</strong></p>
<p>语法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Series.value_counts(normalize=<span class="literal">False</span>, sort=<span class="literal">True</span>, ascending=<span class="literal">False</span>, bins=<span class="literal">None</span>, dropna=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li><code>normalize</code>：是否返回相对频率，默认为False，即返回唯一值的数量。</li>
<li><code>sort</code>：是否按值进行排序，默认为True，即按值进行排序。</li>
<li><code>ascending</code>：是否按升序排列，默认为False，即按降序排列。</li>
<li><code>bins</code>：指定柱状图的箱数。</li>
<li><code>dropna</code>：是否排除缺失值，默认为True，即排除缺失值。</li>
</ul>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">value_count = data.value_counts()</span><br><span class="line"><span class="built_in">print</span>(value_count)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="comment"># 2    3</span></span><br><span class="line"><span class="comment"># 1    2</span></span><br><span class="line"><span class="comment"># 3    2</span></span><br><span class="line"><span class="comment"># 5    1</span></span><br><span class="line"><span class="comment"># 4    1</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure>
<p>以上<code>value_counts()</code>方法计算了序列<code>data</code>中每个唯一值出现的次数，按降序排列输出。</p>
<h3 id="one-hot特征的构造"><a href="#one-hot特征的构造" class="headerlink" title="one-hot特征的构造"></a>one-hot特征的构造</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果有40个类别，那么会产生40列，如果第i行属于第j个类别，那么第j列第i行就是1，否则为0</span></span><br><span class="line"></span><br><span class="line">df_gene_target_symbol_name = pd.get_dummies(df.gene_target_symbol_name)</span><br><span class="line">df_gene_target_symbol_name.columns = [</span><br><span class="line">    <span class="string">f&quot;feat_gene_target_symbol_name_<span class="subst">&#123;c&#125;</span>&quot;</span> <span class="keyword">for</span> c <span class="keyword">in</span> df_gene_target_symbol_name.columns</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h3 id="时间特征构造"><a href="#时间特征构造" class="headerlink" title="时间特征构造"></a>时间特征构造</h3><blockquote>
<p>有可能<br>没看出来，啃臭cv一份，很妙</p>
</blockquote>
<p>在数据观察的时候发现，siRNA_duplex_id的编码方式很有意思，其格式为AD-1810676.1，我们猜测AD是某个类别，后面的.1是版本，当中的可能是按照一定顺序的序列号，因此可以构造如下特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">siRNA_duplex_id_values = df.siRNA_duplex_id.<span class="built_in">str</span>.split(<span class="string">&quot;-|\.&quot;</span>).<span class="built_in">str</span>[<span class="number">1</span>].astype(<span class="string">&quot;int&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>这段代码是从siRNA_duplex_id列中提取出按照一定顺序的序列号作为新的特征siRNA_duplex_id_values。<br>siRNA_duplex_id的编码格式为”AD-1810676.1”，<strong>其中”AD”表示某个类别，”.1”表示版本号，而中间的数字则是按照顺序的序列号。(假定，大概率)</strong><br>代码通过使用正则表达式分隔符”-“和”.”，将siRNA_duplex_id拆分成多个部分，然后取第二部分（索引为1），并将其转换为整数类型。得到的siRNA_duplex_id_values列即为按照一定顺序的序列号特征。</p>
<h4 id="上述对每一个siRNA-duplex-id的过程同下"><a href="#上述对每一个siRNA-duplex-id的过程同下" class="headerlink" title="上述对每一个siRNA_duplex_id的过程同下"></a>上述对每一个siRNA_duplex_id的过程同下</h4><p>(方便复制)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="built_in">str</span> = <span class="string">&quot;AD-1810676.1&quot;</span></span><br><span class="line"><span class="comment"># 使用正则表达式分割字符串</span></span><br><span class="line">parts = re.split(<span class="string">r&#x27;[-.]&#x27;</span>, <span class="built_in">str</span>)</span><br><span class="line"><span class="comment"># 将数字部分转换为NumPy数组，并转换为整数类型</span></span><br><span class="line">numbers = np.array(parts[<span class="number">1</span>], dtype=<span class="built_in">int</span>)</span><br><span class="line"><span class="built_in">print</span>(numbers)</span><br></pre></td></tr></table></figure>
<p><img src="/img/downloaded/aHR0cHM6_578501e1ade440e8834f6f880cf4748d.png" alt="在这里插入图片描述"></p>
<h3 id="包含某些单词"><a href="#包含某些单词" class="headerlink" title="包含某些单词"></a>包含某些单词</h3><h4 id="对df中的cell-line-donor列构造特征"><a href="#对df中的cell-line-donor列构造特征" class="headerlink" title="对df中的cell_line_donor列构造特征"></a>对df中的<code>cell_line_donor</code>列构造特征</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 对cell_line_donor列进行独热编码</span></span><br><span class="line">df_cell_line_donor = pd.get_dummies(df.cell_line_donor)</span><br><span class="line"><span class="comment"># 为独热编码后的列名添加前缀</span></span><br><span class="line">df_cell_line_donor.columns = [</span><br><span class="line">    <span class="string">f&quot;feat_cell_line_donor_<span class="subst">&#123;c&#125;</span>&quot;</span> <span class="keyword">for</span> c <span class="keyword">in</span> df_cell_line_donor.columns</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建新的特征列feat_cell_line_donor_hepatocytes，值为cell_line_donor列是否包含&quot;Hepatocytes&quot;的布尔值转换为整数</span></span><br><span class="line">df_cell_line_donor[<span class="string">&quot;feat_cell_line_donor_hepatocytes&quot;</span>] = (</span><br><span class="line">    (df.cell_line_donor.<span class="built_in">str</span>.contains(<span class="string">&quot;Hepatocytes&quot;</span>)).fillna(<span class="literal">False</span>).astype(<span class="string">&quot;int&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建新的特征列feat_cell_line_donor_cells，值为cell_line_donor列是否包含&quot;Cells&quot;的布尔值转换为整数</span></span><br><span class="line">df_cell_line_donor[<span class="string">&quot;feat_cell_line_donor_cells&quot;</span>] = (</span><br><span class="line">    df.cell_line_donor.<span class="built_in">str</span>.contains(<span class="string">&quot;Cells&quot;</span>).fillna(<span class="literal">False</span>).astype(<span class="string">&quot;int&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="代码小结"><a href="#代码小结" class="headerlink" title="代码小结"></a>代码小结</h5><ol>
<li><strong>使用 <code>pd.get_dummies()</code> 函数对 <code>cell_line_donor</code> 列进行独热编码，</strong>  编码后的列会根据不同的取值创建新的列。</li>
<li><strong>使用列表推导式为 <code>df_cell_line_donor</code> 的列名添加前缀 “feat_cell_line_donor_”。</strong></li>
<li>创建新的特征列 <code>feat_cell_line_donor_hepatocytes</code>，<strong>根据 <code>cell_line_donor</code> 列是否包含 “Hepatocytes”</strong> ，将布尔值转换为整数（1 表示包含，0 表示不包含）。</li>
<li>创建新的特征列 <code>feat_cell_line_donor_cells</code>，<strong>根据 <code>cell_line_donor</code> 列是否包含 “Cells” 来确定的</strong>，将布尔值转换为整数（1 表示包含，0 表示不包含）。</li>
</ol>
<p>将 <code>cell_line_donor</code> 列转换为独热编码，并创建两个新的特征列，用于表示是否包含特定的关键词。</p>
<h3 id="对碱基的模式进行特征构造"><a href="#对碱基的模式进行特征构造" class="headerlink" title="对碱基的模式进行特征构造"></a>对碱基的模式进行特征构造</h3><h4 id="根据上一个task中的rna知识提取"><a href="#根据上一个task中的rna知识提取" class="headerlink" title="根据上一个task中的rna知识提取"></a>根据上一个task中的rna知识提取</h4><blockquote>
<p><img src="/img/downloaded/aHR0cHM6_ea0117b0c9ba4164bcf2c176b69dd5a1.png" alt="在这里插入图片描述"></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">siRNA_feat_builder</span>(<span class="params">s: pd.Series, anti: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    构建siRNA特征的函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    s: pd.Series -- 输入的siRNA序列</span></span><br><span class="line"><span class="string">    anti: bool -- 是否构建反义链特征，默认为False</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    pd.DataFrame -- 构建的siRNA特征DataFrame</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    name = <span class="string">&quot;anti&quot;</span> <span class="keyword">if</span> anti <span class="keyword">else</span> <span class="string">&quot;sense&quot;</span>  <span class="comment"># 根据 anti 的值确定特征名称前缀</span></span><br><span class="line">    df = s.to_frame()  <span class="comment"># 将输入的 Series 对象转换为 DataFrame 对象</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_len&quot;</span>] = s.<span class="built_in">str</span>.<span class="built_in">len</span>()  <span class="comment"># 计算序列长度，并将其作为特征添加到 DataFrame 中</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历两个位置：第一个和最后一个</span></span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> [<span class="number">0</span>, -<span class="number">1</span>]:</span><br><span class="line">        <span class="comment"># 遍历碱基：A、U、G、C</span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">list</span>(<span class="string">&quot;AUGC&quot;</span>):</span><br><span class="line">            <span class="comment"># 判断序列的第一个或最后一个碱基是否与当前碱基相等，并将结果作为特征添加到 DataFrame 中</span></span><br><span class="line">            df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_<span class="subst">&#123;c&#125;</span>_<span class="subst">&#123;<span class="string">&#x27;front&#x27;</span> <span class="keyword">if</span> pos == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;back&#x27;</span>&#125;</span>&quot;</span>] = (</span><br><span class="line">                s.<span class="built_in">str</span>[pos] == c</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断序列是否以特定的模式开头和结尾，并将结果作为特征添加到 DataFrame 中</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_1&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;AA&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UU&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_2&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;GA&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UU&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_3&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;CA&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UU&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_4&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UA&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UU&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_5&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UU&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;AA&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_6&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UU&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;GA&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_7&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UU&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;CA&quot;</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_8&quot;</span>] = s.<span class="built_in">str</span>.startswith(<span class="string">&quot;UU&quot;</span>) &amp; s.<span class="built_in">str</span>.endswith(</span><br><span class="line">        <span class="string">&quot;UA&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断序列的第二位和倒数第二位是否为 A，并将结果作为特征添加到 DataFrame 中</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_9&quot;</span>] = s.<span class="built_in">str</span>[<span class="number">1</span>] == <span class="string">&quot;A&quot;</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_10&quot;</span>] = s.<span class="built_in">str</span>[-<span class="number">2</span>] == <span class="string">&quot;A&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算序列中的 GC 碱基占整体长度的比例，并将结果作为特征添加到 DataFrame 中</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_seq_pattern_GC_frac&quot;</span>] = (</span><br><span class="line">        s.<span class="built_in">str</span>.count(<span class="string">&quot;G&quot;</span>) + s.<span class="built_in">str</span>.count(<span class="string">&quot;C&quot;</span>)</span><br><span class="line">    ) / s.<span class="built_in">str</span>.<span class="built_in">len</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df.iloc[:, <span class="number">1</span>:]  <span class="comment"># 返回除第一列外的所有列，即去掉序列本身的列</span></span><br></pre></td></tr></table></figure>
<h5 id="代码小结-1"><a href="#代码小结-1" class="headerlink" title="代码小结"></a>代码小结</h5><ol>
<li>“feat_siRNA_{name}_seq_len”：siRNA序列的长度作为特征。</li>
<li>siRNA序列的第一个和最后一个位置，在前端或后端：<ul>
<li>“feat_siRNA_{name}<em>seq</em>{c}_{‘front’ if pos &#x3D;&#x3D; 0 else ‘back’}”：判断序列的第一个或最后一个碱基是否与’A’, ‘U’, ‘G’, ‘C’相等。</li>
</ul>
</li>
<li>siRNA序列的起始和结束：<ul>
<li>“feat_siRNA_{name}<em>seq_pattern_1”，…，”feat_siRNA</em>{name}_seq_pattern_8”：判断序列是否以特定的模式开头和结尾。</li>
</ul>
</li>
<li>siRNA序列的第二位和倒数第二位：<ul>
<li>“feat_siRNA_{name}_seq_pattern_9”：判断序列的第二位是否为’A’。</li>
<li>“feat_siRNA_{name}_seq_pattern_10”：判断序列的倒数第二位是否为’A’。</li>
</ul>
</li>
<li>“feat_siRNA_{name}_seq_pattern_GC_frac”：计算序列中的GC碱基占整体长度的比例。</li>
</ol>
<h2 id="最后选择模型预测"><a href="#最后选择模型预测" class="headerlink" title="最后选择模型预测"></a>最后选择模型预测</h2><blockquote>
<p>这里是task2给出的lightgbm的代码来对特征值预测 引一份</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">train_data = lgb.Dataset(X_train, label=y_train)  <span class="comment"># 创建训练数据集，X_train为特征矩阵，y_train为标签向量</span></span><br><span class="line">test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)  <span class="comment"># 创建测试数据集，并引用训练数据集</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_validation_result</span>(<span class="params">env</span>):</span><br><span class="line">    result = env.evaluation_result_list[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;env.iteration&#125;</span>] <span class="subst">&#123;result[<span class="number">1</span>]&#125;</span>&#x27;s <span class="subst">&#123;result[<span class="number">0</span>]&#125;</span>: <span class="subst">&#123;result[<span class="number">2</span>]&#125;</span>&quot;</span>)  <span class="comment"># 打印验证结果的回调函数，用于输出每次迭代后的验证结果</span></span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&quot;boosting_type&quot;</span>: <span class="string">&quot;gbdt&quot;</span>,  <span class="comment"># 梯度提升树类型，可选&quot;gbdt&quot;、&quot;dart&quot;、&quot;goss&quot;</span></span><br><span class="line">    <span class="string">&quot;objective&quot;</span>: <span class="string">&quot;regression&quot;</span>,  <span class="comment"># 模型优化目标，回归任务一般选择&quot;regression&quot;</span></span><br><span class="line">    <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;root_mean_squared_error&quot;</span>,  <span class="comment"># 评估指标，回归任务一般选择&quot;root_mean_squared_error&quot;（均方根误差）</span></span><br><span class="line">    <span class="string">&quot;max_depth&quot;</span>: <span class="number">7</span>,  <span class="comment"># 每棵树的最大深度，控制模型的复杂度</span></span><br><span class="line">    <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.02</span>,  <span class="comment"># 学习率，控制每个树的贡献</span></span><br><span class="line">    <span class="string">&quot;verbose&quot;</span>: <span class="number">0</span>,  <span class="comment"># 控制训练过程中的输出，设置为非零值可输出训练信息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gbm = lgb.train(</span><br><span class="line">    params,  <span class="comment"># 参数字典，包含模型训练所需的参数</span></span><br><span class="line">    train_data,  <span class="comment"># 训练数据集</span></span><br><span class="line">    num_boost_round=<span class="number">15000</span>,  <span class="comment"># 迭代次数，指定生成的树的数量</span></span><br><span class="line">    valid_sets=[test_data],  <span class="comment"># 用于验证模型的数据集，可以根据需要指定多个</span></span><br><span class="line">    callbacks=[print_validation_result],  <span class="comment"># 在训练过程中执行的回调函数，可用于打印验证结果、保存模型等</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="分数"><a href="#分数" class="headerlink" title="分数"></a>分数</h3><p><img src="/img/downloaded/aHR0cHM6_63cbb25b5cf54def8d7291c17327172b.png" alt="在这里插入图片描述"></p>
<h3 id="一些常用的LightGBM参数"><a href="#一些常用的LightGBM参数" class="headerlink" title="一些常用的LightGBM参数"></a>一些常用的LightGBM参数</h3><p>LightGBM是一种梯度提升树模型。</p>
<h4 id="boosting-type"><a href="#boosting-type" class="headerlink" title="boosting_type"></a><code>boosting_type</code></h4><blockquote>
<p>指定梯度提升树的类型</p>
</blockquote>
<p>有<code>gbdt</code>（传统的梯度提升决策树）、<code>dart</code>（dropout加速梯度提升树）和<code>goss</code>（梯度优化送出采样）。</p>
<h4 id="objective"><a href="#objective" class="headerlink" title="objective"></a><code>objective</code></h4><blockquote>
<p>指定模型的优化目标，根据任务类型选择合适的目标函数。</p>
</blockquote>
<p>回归任务可以使用<code>regression</code>，分类任务可以使用<code>binary</code>或<code>multiclass</code>。</p>
<h4 id="metric"><a href="#metric" class="headerlink" title="metric"></a><code>metric</code></h4><blockquote>
<p>指定模型的评估指标，用于衡量模型的性能。</p>
</blockquote>
<p>对于回归任务可以使用<code>root_mean_squared_error</code>（均方根误差）。</p>
<h4 id="max-depth"><a href="#max-depth" class="headerlink" title="max_depth"></a><code>max_depth</code></h4><blockquote>
<p>每棵树的最大深度，控制模型的复杂度。</p>
</blockquote>
<p>较小的值可以防止过拟合，但可能会导致欠拟合。<br><strong>max_depth 一般在 （6，10）</strong></p>
<h4 id="learning-rate"><a href="#learning-rate" class="headerlink" title="learning_rate"></a><code>learning_rate</code></h4><blockquote>
<p>学习率控制每个树的贡献。</p>
</blockquote>
<p>较小的值会使算法收敛得更慢，但可能会获得更好的精度。</p>
<h4 id="num-boost-round"><a href="#num-boost-round" class="headerlink" title="num_boost_round"></a><code>num_boost_round</code></h4><blockquote>
<p>迭代次数，指定生成的树的数量。</p>
</blockquote>
<p>较大的值可以提高模型的性能，但也会增加计算时间。</p>
<h4 id="valid-sets"><a href="#valid-sets" class="headerlink" title="valid_sets"></a><code>valid_sets</code></h4><blockquote>
<p>用于验证模型的数据集，可以根据需要指定多个。</p>
</blockquote>
<p>在训练过程中，模型会根据验证集的性能进行调整。</p>
<h4 id="callbacks"><a href="#callbacks" class="headerlink" title="callbacks"></a><code>callbacks</code></h4><blockquote>
<p>在训练过程中执行的回调函数，可以用于打印模型的验证结果、保存模型等。</p>
</blockquote>
<blockquote>
<p>可以通过回调函数自定义返回的东西，如打印测试情况之类的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">callbacks=[print_validation_result]</span><br></pre></td></tr></table></figure>
<p>这里就是回调时，用了print_validation_result 作为输出<br>输出函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_validation_result</span>(<span class="params">env</span>):</span><br><span class="line">    result = env.evaluation_result_list[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[<span class="subst">&#123;env.iteration&#125;</span>] <span class="subst">&#123;result[<span class="number">1</span>]&#125;</span>&#x27;s <span class="subst">&#123;result[<span class="number">0</span>]&#125;</span>: <span class="subst">&#123;result[<span class="number">2</span>]&#125;</span>&quot;</span>)  <span class="comment"># 打印验证结果的回调函数，用于输出每次迭代后的验证结果</span></span><br></pre></td></tr></table></figure></blockquote>
<h4 id="num-leaves"><a href="#num-leaves" class="headerlink" title="num_leaves"></a><code>num_leaves</code></h4><blockquote>
<p>每棵树的叶子节点数，与<code>max_depth</code>参数一起控制模型的复杂度。</p>
</blockquote>
<h4 id="min-data-in-leaf"><a href="#min-data-in-leaf" class="headerlink" title="min_data_in_leaf"></a><code>min_data_in_leaf</code></h4><blockquote>
<p>叶子节点的最小数据量，用于防止模型在小数据集上过拟合。</p>
</blockquote>
<h4 id="subsample"><a href="#subsample" class="headerlink" title="subsample"></a><code>subsample</code></h4><blockquote>
<p>训练时使用的样本比例，可以用于防止过拟合。</p>
</blockquote>
<h4 id="verbose"><a href="#verbose" class="headerlink" title="verbose"></a><code>verbose</code></h4><blockquote>
<p>是否在训练过程中打印详细的信息。</p>
</blockquote>
<h4 id="random-state"><a href="#random-state" class="headerlink" title="random_state"></a><code>random_state</code></h4><blockquote>
<p>随机数生成器的种子，用于确保结果的可复现性。</p>
</blockquote>
<h4 id="device-type"><a href="#device-type" class="headerlink" title="device_type"></a><code>device_type</code></h4><blockquote>
<p>指定训练时使用的设备类型，如CPU或GPU。<br>一般本地训练需要调整</p>
</blockquote>
<p><strong>更多参数还是建议自主参考官方文档</strong><br><a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">Parameters — LightGBM 4.5.0.99 documentation<br>https://lightgbm.readthedocs.io/en/latest/Parameters.htmll</a></p>
<p>举例一个其他的模型的训练参数<br><img src="/img/downloaded/aHR0cHM6_06551847b64747f9a13ecbcf6c382bf1.png" alt="在这里插入图片描述"></p>
<p>根据具体任务和数据的特点，可以尝试不同的参数组合来优化模型性能。</p>
<blockquote>
<p>tips : 可以构造更多特征，多模型融合，k折 ，调超参等方法涨点</p>
</blockquote>
<p>这里给出一个k折的框架</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="comment"># train函数用于训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">feats, n_original</span>):</span><br><span class="line">    <span class="comment"># 定义k折交叉验证</span></span><br><span class="line">    n_splits = <span class="number">10</span></span><br><span class="line">    kf = KFold(n_splits=n_splits, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    <span class="comment"># 开始k折交叉验证</span></span><br><span class="line">    gbms = []</span><br><span class="line">    <span class="keyword">for</span> fold, (train_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(</span><br><span class="line">        kf.split(feats.iloc[:n_original, :]), <span class="number">1</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="comment"># 准备训练集和验证集</span></span><br><span class="line">        X_train, X_val = feats.iloc[train_idx, :-<span class="number">1</span>], feats.iloc[val_idx, :-<span class="number">1</span>]</span><br><span class="line">        y_train, y_val = feats.iloc[train_idx, -<span class="number">1</span>], feats.iloc[val_idx, -<span class="number">1</span>]</span><br><span class="line">        w_train = weight_ls[train_idx]</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建LightGBM数据集</span></span><br><span class="line">        train_data = lgb.Dataset(X_train, label=y_train, weight=w_train)</span><br><span class="line">        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)</span><br><span class="line"></span><br><span class="line">        boost_round = <span class="number">25000</span></span><br><span class="line">        early_stop_rounds = <span class="built_in">int</span>(boost_round*<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 显示metric</span></span><br><span class="line">        lgb_log = lgb.log_evaluation(period=<span class="number">200</span>, show_stdv=<span class="literal">True</span>)</span><br><span class="line">        lgb_stop = lgb.early_stopping(stopping_rounds=early_stop_rounds, first_metric_only=<span class="literal">True</span>, verbose=<span class="literal">True</span>, min_delta=<span class="number">0.00001</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置LightGBM参数</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&quot;boosting_type&quot;</span>: <span class="string">&quot;gbdt&quot;</span>,</span><br><span class="line">            <span class="string">&quot;objective&quot;</span>: <span class="string">&quot;regression&quot;</span>,</span><br><span class="line">            <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;None&quot;</span>,</span><br><span class="line">            <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;root_mean_squared_error&quot;</span>,</span><br><span class="line">            <span class="string">&quot;max_depth&quot;</span>: <span class="number">8</span>,</span><br><span class="line">            <span class="string">&quot;num_leaves&quot;</span>: <span class="number">63</span>,</span><br><span class="line">            <span class="string">&quot;min_data_in_leaf&quot;</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.05</span>,</span><br><span class="line">            <span class="string">&quot;feature_fraction&quot;</span>: <span class="number">0.9</span>,</span><br><span class="line">            <span class="string">&quot;lambda_l1&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">            <span class="string">&quot;lambda_l2&quot;</span>: <span class="number">0.2</span>,</span><br><span class="line">            <span class="string">&quot;verbose&quot;</span>: -<span class="number">1</span>, <span class="comment"># -1时不输出</span></span><br><span class="line">            <span class="string">&quot;early_stopping_round&quot;</span>: early_stop_rounds,</span><br><span class="line">            <span class="string">&quot;num_threads&quot;</span>: <span class="number">8</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        gbm = lgb.train(</span><br><span class="line">            params,</span><br><span class="line">            train_data,</span><br><span class="line">            num_boost_round=boost_round,</span><br><span class="line">            valid_sets=[val_data],</span><br><span class="line">            feval=calculate_metrics,  <span class="comment"># 将自定义指标函数作为feval参数传入</span></span><br><span class="line">            callbacks=[print_validation_result, lgb_log, lgb_stop],</span><br><span class="line">        )</span><br><span class="line">        valid_score = gbm.best_score[<span class="string">&quot;valid_0&quot;</span>][<span class="string">&quot;custom_score&quot;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;best_valid_score: <span class="subst">&#123;valid_score&#125;</span>&quot;</span>)</span><br><span class="line">        gbms.append(gbm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gbms</span><br></pre></td></tr></table></figure>

<h3 id="分数-1"><a href="#分数-1" class="headerlink" title="分数"></a>分数</h3><blockquote>
<p>目前还在冲分，后续补上代码</p>
</blockquote>
<p><img src="/img/downloaded/aHR0cHM6_6c52070d6004422e81552c1be0f88c66.png" alt="在这里插入图片描述"></p>
<h1 id="Task3"><a href="#Task3" class="headerlink" title="Task3"></a>Task3</h1><blockquote>
<p>特征工程进阶</p>
</blockquote>
<h2 id="对task2引入生物知识"><a href="#对task2引入生物知识" class="headerlink" title="对task2引入生物知识"></a>对task2引入生物知识</h2><blockquote>
<p>引入的长度、GC含量等特征细节刻画</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">siRNA_feat_builder3</span>(<span class="params">s: pd.Series, anti: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    name = <span class="string">&quot;anti&quot;</span> <span class="keyword">if</span> anti <span class="keyword">else</span> <span class="string">&quot;sense&quot;</span></span><br><span class="line">    df = s.to_frame()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 长度分组</span></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_len21&quot;</span>] = (s.<span class="built_in">str</span>.<span class="built_in">len</span>() == <span class="number">21</span>)</span><br><span class="line">    <span class="comment"># 省略号标识以此类推构造特征</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># GC含量</span></span><br><span class="line">    GC_frac = (s.<span class="built_in">str</span>.count(<span class="string">&quot;G&quot;</span>) + s.<span class="built_in">str</span>.count(<span class="string">&quot;C&quot;</span>))/s.<span class="built_in">str</span>.<span class="built_in">len</span>()</span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_GC_in&quot;</span>] = (GC_frac &gt;= <span class="number">0.36</span>) &amp; (GC_frac &lt;= <span class="number">0.52</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 局部GC含量</span></span><br><span class="line">    GC_frac1 = (s.<span class="built_in">str</span>[<span class="number">1</span>:<span class="number">7</span>].<span class="built_in">str</span>.count(<span class="string">&quot;G&quot;</span>) + s.<span class="built_in">str</span>[<span class="number">1</span>:<span class="number">7</span>].<span class="built_in">str</span>.count(<span class="string">&quot;C&quot;</span>))/s.<span class="built_in">str</span>[<span class="number">1</span>:<span class="number">7</span>].<span class="built_in">str</span>.<span class="built_in">len</span>()</span><br><span class="line"></span><br><span class="line">    df[<span class="string">f&quot;feat_siRNA_<span class="subst">&#123;name&#125;</span>_GC_in1&quot;</span>] = GC_frac1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df.iloc[:, <span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>代码可以看出，新增有长度分组，GC含量和局部GC含量</p>
</blockquote>
<h3 id="修饰siRNA构建特征"><a href="#修饰siRNA构建特征" class="headerlink" title="修饰siRNA构建特征"></a>修饰siRNA构建特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">siRNA_feat_builder3_mod</span>(<span class="params">s: pd.Series, anti: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    name = <span class="string">&quot;anti&quot;</span> <span class="keyword">if</span> anti <span class="keyword">else</span> <span class="string">&quot;sense&quot;</span></span><br><span class="line">    df = s.to_frame()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 修饰RNA的起始、终止位置单元类别</span></span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> [<span class="number">0</span>, -<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> voc_ls:</span><br><span class="line">            ...</span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> [<span class="number">1</span>, -<span class="number">2</span>]:</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> voc_ls:</span><br><span class="line">            ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df.iloc[:, <span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
<h3 id="修饰siRNA序列进行n-gram的词频统计"><a href="#修饰siRNA序列进行n-gram的词频统计" class="headerlink" title="修饰siRNA序列进行n-gram的词频统计"></a>修饰siRNA序列进行n-gram的词频统计</h3><blockquote>
<p>同时也可对未修饰序列进行相同的操作</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GenomicTokenizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ngram=<span class="number">5</span>, stride=<span class="number">2</span></span>):</span><br><span class="line">        <span class="comment"># 初始化分词器，设置n-gram长度和步幅</span></span><br><span class="line">        <span class="variable language_">self</span>.ngram = ngram</span><br><span class="line">        <span class="variable language_">self</span>.stride = stride</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">self, t</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 字符串变list</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(t, <span class="built_in">str</span>):</span><br><span class="line">            t = <span class="built_in">list</span>(t)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.ngram == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 如果n-gram长度为1，直接将序列转换为字符列表</span></span><br><span class="line">            toks = t</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 否则，按照步幅对序列进行n-gram分词</span></span><br><span class="line">            toks = [t[i:i+<span class="variable language_">self</span>.ngram] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(t), <span class="variable language_">self</span>.stride) <span class="keyword">if</span> <span class="built_in">len</span>(t[i:i+<span class="variable language_">self</span>.ngram]) == <span class="variable language_">self</span>.ngram]</span><br><span class="line">        </span><br><span class="line">            <span class="comment"># 如果最后一个分词长度小于n-gram，移除最后一个分词</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(toks[-<span class="number">1</span>]) &lt; <span class="variable language_">self</span>.ngram:</span><br><span class="line">                toks = toks[:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># sub list to str</span></span><br><span class="line">            toks = [<span class="string">&#x27;&#x27;</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> toks]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回分词结果</span></span><br><span class="line">        <span class="keyword">return</span> toks</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GenomicVocab</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, itos</span>):</span><br><span class="line">        <span class="comment"># 初始化词汇表，itos是一个词汇表列表</span></span><br><span class="line">        <span class="variable language_">self</span>.itos = itos</span><br><span class="line">        <span class="comment"># 创建从词汇到索引的映射</span></span><br><span class="line">        <span class="variable language_">self</span>.stoi = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.itos)&#125;</span><br><span class="line">        </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create</span>(<span class="params">cls, tokens, max_vocab, min_freq</span>):</span><br><span class="line">        <span class="comment"># 创建词汇表类方法</span></span><br><span class="line">        <span class="comment"># 统计每个token出现的频率</span></span><br><span class="line">        freq = Counter(tokens)</span><br><span class="line">        <span class="comment"># 选择出现频率大于等于min_freq的token，并且最多保留max_vocab个token</span></span><br><span class="line">        <span class="comment"># itos = [&#x27;&lt;pad&gt;&#x27;] + [o for o, c in freq.most_common(max_vocab - 1) if c &gt;= min_freq]</span></span><br><span class="line">        itos = [o <span class="keyword">for</span> o, c <span class="keyword">in</span> freq.most_common(max_vocab - <span class="number">1</span>) <span class="keyword">if</span> c &gt;= min_freq]</span><br><span class="line">        <span class="comment"># 返回包含词汇表的类实例</span></span><br><span class="line">        <span class="keyword">return</span> cls(itos)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">siRNA_feat_builder_substr</span>(<span class="params">se, name, patterns</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建一个空字典来存储特征</span></span><br><span class="line">    features = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pattern <span class="keyword">in</span> patterns:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># escaped_pattern = re.escape(pattern)  # 转义模式中的特殊字符</span></span><br><span class="line">            escaped_pattern = pattern</span><br><span class="line">            features[<span class="string">f&quot;feat_<span class="subst">&#123;name&#125;</span>_seq_pattern_<span class="subst">&#123;escaped_pattern&#125;</span>&quot;</span>] = se.<span class="built_in">str</span>.count(escaped_pattern)</span><br><span class="line">        <span class="keyword">except</span> re.error <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error in pattern <span class="subst">&#123;pattern&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将字典转换为DataFrame</span></span><br><span class="line">    feature_df = pd.DataFrame(features)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feature_df</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理序列特征</span></span><br><span class="line">seq_features_df = pd.DataFrame()</span><br><span class="line"></span><br><span class="line">tokenizer1 = GenomicTokenizer(ngram=<span class="number">1</span>, stride=<span class="number">1</span>) <span class="comment"># 1gram</span></span><br><span class="line">tokenizer2 = GenomicTokenizer(ngram=<span class="number">2</span>, stride=<span class="number">1</span>) <span class="comment"># 2gram</span></span><br><span class="line">tokenizer3 = GenomicTokenizer(ngram=<span class="number">3</span>, stride=<span class="number">1</span>) <span class="comment"># 3gram</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 子串词频统计，未修饰序列</span></span><br><span class="line">cols_nomod = [<span class="string">&quot;siRNA_sense_seq&quot;</span>, <span class="string">&quot;siRNA_antisense_seq&quot;</span>]</span><br><span class="line">all_tokens_nomod = []</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_nomod:</span><br><span class="line">    <span class="keyword">for</span> seq <span class="keyword">in</span> df[col]:</span><br><span class="line">        <span class="keyword">if</span> pd.isna(seq):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;#all_tokens_nomod: &#x27;</span>, <span class="built_in">len</span>(all_tokens_nomod))</span><br><span class="line"></span><br><span class="line">vocab_nomod = GenomicVocab.create(all_tokens_nomod, max_vocab=<span class="number">100000</span>, min_freq=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;#vocab_nomod: &#x27;</span>, <span class="built_in">len</span>(vocab_nomod.itos))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_nomod:</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="tokenizer-的工作方式"><a href="#tokenizer-的工作方式" class="headerlink" title="tokenizer 的工作方式"></a><code>tokenizer</code> 的工作方式</h4><p> 这里解释一下通过一个例子来展示不同 <code>tokenizer</code> 的工作方式。<br>我们有一个由碱基组成的基因序列：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AGTCATG</span><br></pre></td></tr></table></figure>

<p>我们将使用这个序列来演示每个 <code>tokenizer</code> 如何将其分割。</p>
<h5 id="tokenizer1-ngram-1-stride-1"><a href="#tokenizer1-ngram-1-stride-1" class="headerlink" title="tokenizer1 (ngram&#x3D;1, stride&#x3D;1)"></a><strong><code>tokenizer1</code> (ngram&#x3D;1, stride&#x3D;1)</strong></h5><ul>
<li>将序列分割成单个碱基的片段，步长为1。</li>
<li>结果: <code>[&#39;A&#39;, &#39;G&#39;, &#39;T&#39;, &#39;C&#39;, &#39;A&#39;, &#39;T&#39;, &#39;G&#39;]</code></li>
</ul>
<h5 id="tokenizer2-ngram-2-stride-2"><a href="#tokenizer2-ngram-2-stride-2" class="headerlink" title="tokenizer2 (ngram&#x3D;2, stride&#x3D;2)"></a><strong><code>tokenizer2</code> (ngram&#x3D;2, stride&#x3D;2)</strong></h5><ul>
<li>将序列分割成长度为2的片段，步长为2。</li>
<li>结果: <code>[&#39;AG&#39;, &#39;TG&#39;]</code>（从’A’开始，跳过一个碱基到’G’，然后再次跳过一个碱基到’T’）</li>
</ul>
<h5 id="tokenizer3-ngram-3-stride-3"><a href="#tokenizer3-ngram-3-stride-3" class="headerlink" title="tokenizer3 (ngram&#x3D;3, stride&#x3D;3)"></a><strong><code>tokenizer3</code> (ngram&#x3D;3, stride&#x3D;3)</strong></h5><ul>
<li>将序列分割成长度为3的片段，步长为3。</li>
<li>结果: <code>[&#39;AGT&#39;]</code>（从’A’开始，跳过两个碱基到’G’）</li>
</ul>
<h5 id="tokenizer6-ngram-6-stride-6"><a href="#tokenizer6-ngram-6-stride-6" class="headerlink" title="tokenizer6 (ngram&#x3D;6, stride&#x3D;6)"></a><strong><code>tokenizer6</code> (ngram&#x3D;6, stride&#x3D;6)</strong></h5><ul>
<li>由于序列长度只有7个碱基，而步长为6，所以这个 <code>tokenizer</code> 只会生成一个长度为6的片段。</li>
<li>结果: <code>[&#39;AGTCAT&#39;]</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 子串词频统计，修饰序列</span></span><br><span class="line">cols_mod = [<span class="string">&quot;modified_siRNA_sense_seq&quot;</span>, <span class="string">&quot;modified_siRNA_antisense_seq&quot;</span>]</span><br><span class="line">cols_mod_ls = [<span class="string">&quot;modified_siRNA_sense_seq_list&quot;</span>, <span class="string">&quot;modified_siRNA_antisense_seq_list&quot;</span>]</span><br><span class="line">all_tokens_mod = []</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_mod_ls:</span><br><span class="line">    <span class="keyword">for</span> seq_ls <span class="keyword">in</span> df[col]:</span><br><span class="line">        <span class="keyword">if</span> pd.isna(seq_ls):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(&#x27;#all_tokens_mod: &#x27;, len(all_tokens_mod))</span></span><br><span class="line"></span><br><span class="line">vocab_mod = GenomicVocab.create(all_tokens_mod, max_vocab=<span class="number">100000</span>, min_freq=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(&#x27;#vocab_mod: &#x27;, len(vocab_mod.itos))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_mod:</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="siRNA序列与target序列对比"><a href="#siRNA序列与target序列对比" class="headerlink" title="siRNA序列与target序列对比"></a>siRNA序列与target序列对比</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Bio <span class="keyword">import</span> pairwise2</span><br><span class="line"><span class="keyword">from</span> Bio.pairwise2 <span class="keyword">import</span> format_alignment</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_feat_align</span>(<span class="params">df, anti: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算siRNA序列与target序列的比对得分。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    df : DataFrame</span></span><br><span class="line"><span class="string">        包含siRNA和target序列的DataFrame。</span></span><br><span class="line"><span class="string">    anti : bool</span></span><br><span class="line"><span class="string">        是否处理antisense siRNA序列。默认为False，表示处理sense siRNA序列。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    DataFrame</span></span><br><span class="line"><span class="string">        包含原始DataFrame和比对得分的DataFrame。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 假设DataFrame有两列，分别为&#x27;sirna_sequence&#x27;和&#x27;target_sequence&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        siRNA_seq = row[<span class="string">&#x27;siRNA_sequence&#x27;</span>]</span><br><span class="line">        target_seq = row[<span class="string">&#x27;target_sequence&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果是antisense siRNA，需要反转并补录序列</span></span><br><span class="line">        <span class="keyword">if</span> anti:</span><br><span class="line">            siRNA_seq = siRNA_seq[::-<span class="number">1</span>].translate(<span class="built_in">str</span>.maketrans(<span class="string">&quot;ATCG&quot;</span>, <span class="string">&quot;TAGC&quot;</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用pairwise2.align.localxx进行局部序列比对</span></span><br><span class="line">        alignments = pairwise2.align.localxx(siRNA_seq, target_seq)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算比对得分，这里取最高得分的比对</span></span><br><span class="line">        max_score = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> alignment <span class="keyword">in</span> alignments:</span><br><span class="line">            score = alignment[<span class="number">2</span>]  <span class="comment"># alignment[2] 是比对得分</span></span><br><span class="line">            <span class="keyword">if</span> score &gt; max_score:</span><br><span class="line">                max_score = score</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将得分添加到DataFrame中</span></span><br><span class="line">        df.at[index, <span class="string">&#x27;alignment_score&#x27;</span>] = max_score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>

<p>如果siRNA是antisense类型 </p>
<pre><code>result_df = get_feat_align(df, anti=True) 
</code></pre>
<p>如果siRNA是sense类型 </p>
<pre><code>result_df = get_feat_align(df)  
</code></pre>
<h3 id="其他生物特征"><a href="#其他生物特征" class="headerlink" title="其他生物特征"></a>其他生物特征</h3><blockquote>
<p>有重复<br><img src="/img/downloaded/aHR0cHM6_402e5e90e3a143109122db8f5e3421d5.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_85c2119965214195afa8837198039a3f.png" alt="在这里插入图片描述"><br><img src="/img/downloaded/aHR0cHM6_7194f9935d2e4339921f7ec3b7b08ede.png" alt="在这里插入图片描述"></p>
</blockquote>
<h2 id="lgb模型优化"><a href="#lgb模型优化" class="headerlink" title="lgb模型优化"></a>lgb模型优化</h2><h3 id="低Remaining范围样本高权重"><a href="#低Remaining范围样本高权重" class="headerlink" title="低Remaining范围样本高权重"></a>低Remaining范围样本高权重</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight_ls = np.array(feats[<span class="string">&#x27;mRNA_remaining_pct&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="number">2</span> <span class="keyword">if</span> ((x&lt;=<span class="number">30</span>)<span class="keyword">and</span>(x&gt;=<span class="number">0</span>)) <span class="keyword">else</span> <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>这段代码是将<code>feats</code>中的<code>mRNA_remaining_pct</code>列的值进行一些判断和处理，生成一个新的<code>weight_ls</code>数组。<br>这段代码<strong>根据<code>mRNA_remaining_pct</code>列的值是否在0到30之间，将对应位置上的<code>weight_ls</code>值设置为2或者1。</strong></p>
<h3 id="使用官方评价指标作为损失函数"><a href="#使用官方评价指标作为损失函数" class="headerlink" title="使用官方评价指标作为损失函数"></a>使用官方评价指标作为损失函数</h3><blockquote>
<p>由原来的root_mean_squared_error评价指标被替换为更加复杂的官方评价分数</p>
</blockquote>
<p>具体公式为:</p>
<p>$$\text{score} &#x3D; 50% \times \left(1 - \frac{\text{MAE}}{100}\right) + 50% \times F1 \times \left(1 - \frac{\text{Range-MAE}}{100}\right)$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># calculate_metrics函数用于计算评估指标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_metrics</span>(<span class="params">preds, data, threshold=<span class="number">30</span></span>):</span><br><span class="line">    y_pred = preds</span><br><span class="line">    y_true = data.get_label()</span><br><span class="line">    mae = np.mean(np.<span class="built_in">abs</span>(y_true - y_pred))</span><br><span class="line">    <span class="comment"># if mae &lt; 0: mae = 0</span></span><br><span class="line">    <span class="comment"># elif mae &gt;100: mae = 100</span></span><br><span class="line"></span><br><span class="line">    y_true_binary = ((y_true &lt;= threshold) &amp; (y_true &gt;= <span class="number">0</span>)).astype(<span class="built_in">int</span>)</span><br><span class="line">    y_pred_binary = ((y_pred &lt;= threshold) &amp; (y_pred &gt;= <span class="number">0</span>)).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    mask = (y_pred &gt;= <span class="number">0</span>) &amp; (y_pred &lt;= threshold)</span><br><span class="line">    range_mae = (</span><br><span class="line">        mean_absolute_error(y_true[mask], y_pred[mask]) <span class="keyword">if</span> np.<span class="built_in">sum</span>(mask) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">100</span></span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># if range_mae &lt; 0: range_mae = 0</span></span><br><span class="line">    <span class="comment"># elif range_mae &gt;100: range_mae = 100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># precision = precision_score(y_true_binary, y_pred_binary, average=&quot;binary&quot;)</span></span><br><span class="line">    <span class="comment"># recall = recall_score(y_true_binary, y_pred_binary, average=&quot;binary&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">sum</span>(y_pred_binary) &gt; <span class="number">0</span>:</span><br><span class="line">        precision = (np.array(y_pred_binary) &amp; y_true_binary).<span class="built_in">sum</span>()/np.<span class="built_in">sum</span>(y_pred_binary)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        precision = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">sum</span>(y_true_binary) &gt; <span class="number">0</span>:</span><br><span class="line">        recall = (np.array(y_pred_binary) &amp; y_true_binary).<span class="built_in">sum</span>()/np.<span class="built_in">sum</span>(y_true_binary)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        recall = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> precision + recall == <span class="number">0</span>:</span><br><span class="line">        f1 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        f1 = <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line">    score = (<span class="number">1</span> - mae / <span class="number">100</span>) * <span class="number">0.5</span> + (<span class="number">1</span> - range_mae / <span class="number">100</span>) * f1 * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;custom_score&quot;</span>, score, <span class="literal">True</span>  <span class="comment"># True表示分数越高越好</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="自适应学习率"><a href="#自适应学习率" class="headerlink" title="自适应学习率"></a>自适应学习率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># adaptive_learning_rate函数用于自适应学习率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">adaptive_learning_rate</span>(<span class="params">decay_rate=<span class="number">0.8</span>, patience=<span class="number">50</span></span>):</span><br><span class="line">    best_score = <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>)  <span class="comment"># 初始化为负无穷,因为分数越高越好</span></span><br><span class="line">    wait = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">callback</span>(<span class="params">env</span>):</span><br><span class="line">        <span class="keyword">nonlocal</span> best_score, wait</span><br><span class="line">        current_score = env.evaluation_result_list[-<span class="number">1</span>][<span class="number">2</span>]  <span class="comment"># 假设使用的是最后一个评估指标</span></span><br><span class="line">        current_lr =  env.model.params.get(<span class="string">&#x27;learning_rate&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_score &gt; best_score: </span><br><span class="line">            best_score = current_score</span><br><span class="line">            <span class="comment"># wait = 0 # 需要连续的score没有上升</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            wait += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> wait &gt;= patience:</span><br><span class="line">            new_lr = <span class="built_in">float</span>(current_lr) * decay_rate</span><br><span class="line">            wait = <span class="number">0</span></span><br><span class="line">            env.model.params[<span class="string">&#x27;learning_rate&#x27;</span>] = new_lr</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Learning rate adjusted to <span class="subst">&#123;env.model.params.get(<span class="string">&#x27;learning_rate&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> callback</span><br></pre></td></tr></table></figure>

<h3 id="多折交叉训练"><a href="#多折交叉训练" class="headerlink" title="多折交叉训练"></a>多折交叉训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train函数用于训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">feats, n_original</span>):</span><br><span class="line">    <span class="comment"># 定义k折交叉验证</span></span><br><span class="line">    n_splits = <span class="number">10</span></span><br><span class="line">    kf = KFold(n_splits=n_splits, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    <span class="comment"># 开始k折交叉验证</span></span><br><span class="line">    gbms = []</span><br><span class="line">    <span class="keyword">for</span> fold, (train_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(</span><br><span class="line">        kf.split(feats.iloc[:n_original, :]), <span class="number">1</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="comment"># 准备训练集和验证集</span></span><br><span class="line">        X_train, X_val = feats.iloc[train_idx, :-<span class="number">1</span>], feats.iloc[val_idx, :-<span class="number">1</span>]</span><br><span class="line">        y_train, y_val = feats.iloc[train_idx, -<span class="number">1</span>], feats.iloc[val_idx, -<span class="number">1</span>]</span><br><span class="line">        w_train = weight_ls[train_idx]</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建LightGBM数据集</span></span><br><span class="line">        train_data = lgb.Dataset(X_train, label=y_train, weight=w_train)</span><br><span class="line">        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)</span><br><span class="line"></span><br><span class="line">        boost_round = <span class="number">25000</span></span><br><span class="line">        early_stop_rounds = <span class="built_in">int</span>(boost_round*<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 显示metric</span></span><br><span class="line">        lgb_log = lgb.log_evaluation(period=<span class="number">200</span>, show_stdv=<span class="literal">True</span>)</span><br><span class="line">        lgb_stop = lgb.early_stopping(stopping_rounds=early_stop_rounds, first_metric_only=<span class="literal">True</span>, verbose=<span class="literal">True</span>, min_delta=<span class="number">0.00001</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置LightGBM参数</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&quot;boosting_type&quot;</span>: <span class="string">&quot;gbdt&quot;</span>,</span><br><span class="line">            <span class="string">&quot;objective&quot;</span>: <span class="string">&quot;regression&quot;</span>,</span><br><span class="line">            <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;None&quot;</span>,</span><br><span class="line">            <span class="comment"># &quot;metric&quot;: &quot;root_mean_squared_error&quot;,</span></span><br><span class="line">            <span class="string">&quot;max_depth&quot;</span>: <span class="number">8</span>,</span><br><span class="line">            <span class="string">&quot;num_leaves&quot;</span>: <span class="number">63</span>,</span><br><span class="line">            <span class="string">&quot;min_data_in_leaf&quot;</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.05</span>,</span><br><span class="line">            <span class="string">&quot;feature_fraction&quot;</span>: <span class="number">0.9</span>,</span><br><span class="line">            <span class="string">&quot;lambda_l1&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">            <span class="string">&quot;lambda_l2&quot;</span>: <span class="number">0.2</span>,</span><br><span class="line">            <span class="string">&quot;verbose&quot;</span>: -<span class="number">1</span>, <span class="comment"># -1时不输出</span></span><br><span class="line">            <span class="string">&quot;early_stopping_round&quot;</span>: early_stop_rounds,</span><br><span class="line">            <span class="string">&quot;num_threads&quot;</span>: <span class="number">8</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在训练时使用自适应学习率回调函数</span></span><br><span class="line">        adaptive_lr = adaptive_learning_rate(decay_rate=<span class="number">0.9</span>, patience=<span class="number">1000</span>)</span><br><span class="line">        gbm = lgb.train(</span><br><span class="line">            params,</span><br><span class="line">            train_data,</span><br><span class="line">            num_boost_round=boost_round,</span><br><span class="line">            valid_sets=[val_data],</span><br><span class="line">            feval=calculate_metrics,  <span class="comment"># 将自定义指标函数作为feval参数传入</span></span><br><span class="line">            <span class="comment"># callbacks=[print_validation_result, adaptive_lr, lgb_log, lgb_stop],</span></span><br><span class="line">            callbacks=[adaptive_lr, lgb_log, lgb_stop],</span><br><span class="line">        )</span><br><span class="line">        valid_score = gbm.best_score[<span class="string">&quot;valid_0&quot;</span>][<span class="string">&quot;custom_score&quot;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;best_valid_score: <span class="subst">&#123;valid_score&#125;</span>&quot;</span>)</span><br><span class="line">        gbms.append(gbm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gbms</span><br></pre></td></tr></table></figure>
<h3 id="完成以上操作的分数"><a href="#完成以上操作的分数" class="headerlink" title="完成以上操作的分数"></a>完成以上操作的分数</h3><p><img src="/img/downloaded/aHR0cHM6_9d49d4b4dd414cf0b9c8196182d91ab6.png" alt="在这里插入图片描述"></p>
<h3 id="超参数优化"><a href="#超参数优化" class="headerlink" title="超参数优化"></a>超参数优化</h3><h4 id="贝叶斯优化-推荐）"><a href="#贝叶斯优化-推荐）" class="headerlink" title="贝叶斯优化(推荐）"></a>贝叶斯优化(推荐）</h4><blockquote>
<p>您可以使用如optuna这样的库来执行贝叶斯优化超参数, 参考代码如下</p>
</blockquote>
<p>伪代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> optuna</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">objective</span>(<span class="params">trial</span>):</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: trial.suggest_int(<span class="string">&#x27;max_depth&#x27;</span>, <span class="number">3</span>, <span class="number">10</span>),</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: trial.suggest_loguniform(<span class="string">&#x27;learning_rate&#x27;</span>, <span class="number">1e-3</span>, <span class="number">1e-1</span>),</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span>: trial.suggest_int(<span class="string">&#x27;n_estimators&#x27;</span>, <span class="number">100</span>, <span class="number">2000</span>),</span><br><span class="line">        <span class="string">&#x27;min_child_samples&#x27;</span>: trial.suggest_int(<span class="string">&#x27;min_child_samples&#x27;</span>, <span class="number">20</span>, <span class="number">100</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    model = LGBMRegressor(**params)</span><br><span class="line">    model.fit(X_train, y_train)</span><br><span class="line">    <span class="keyword">return</span> model.score(X_val, y_val)</span><br><span class="line"></span><br><span class="line">study = optuna.create_study(direction=<span class="string">&#x27;maximize&#x27;</span>)</span><br><span class="line">study.optimize(objective, n_trials=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Best trial:&#x27;</span>)</span><br><span class="line">trial = study.best_trial</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Value: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(trial.value))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Params: &#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> trial.params.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;    &#123;&#125;: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(key, value))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>通过贝叶斯优化方法来进行超参数优化。</p>
<ol>
<li>拆分数据集为训练集和测试集。 </li>
<li>定义超参数搜索空间。 </li>
<li>创建评估函数，训练LGBMClassifier模型，计算准确率。</li>
<li>使用贝叶斯优化，找出最佳超参数。</li>
</ol>
<p><img src="/img/downloaded/aHR0cHM6_9b8549bd50b14edda88219cbd2c99c40.png" alt="在这里插入图片描述"><br>真的跑很久。。。还没跑完</p>
<h4 id="网格搜索（Grid-Search）"><a href="#网格搜索（Grid-Search）" class="headerlink" title="网格搜索（Grid Search）"></a>网格搜索（Grid Search）</h4><blockquote>
<p>使用LightGBM</p>
</blockquote>
<p><strong>伪代码</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数搜索空间</span></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">10</span>],</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">0.2</span>],</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">100</span>, <span class="number">200</span>, <span class="number">300</span>],</span><br><span class="line">    <span class="string">&#x27;num_leaves&#x27;</span>: [<span class="number">31</span>, <span class="number">63</span>, <span class="number">127</span>],</span><br><span class="line">    <span class="string">&#x27;min_child_samples&#x27;</span>: [<span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建LightGBM分类器</span></span><br><span class="line">estimator = lgb.LGBMClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建GridSearchCV对象</span></span><br><span class="line">grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行网格搜索</span></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最佳参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Best parameters:&#x27;</span>, grid_search.best_params_)</span><br></pre></td></tr></table></figure>

<h4 id="随机搜索（Random-Search）"><a href="#随机搜索（Random-Search）" class="headerlink" title="随机搜索（Random Search）"></a>随机搜索（Random Search）</h4><blockquote>
<p>使用LightGBM</p>
</blockquote>
<p><strong>伪代码</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> randint, uniform</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数的连续搜索空间</span></span><br><span class="line">param_dist = &#123;</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: randint(<span class="number">3</span>, <span class="number">10</span>),</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: uniform(<span class="number">0.01</span>, <span class="number">0.2</span>),</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: randint(<span class="number">100</span>, <span class="number">300</span>),</span><br><span class="line">    <span class="string">&#x27;num_leaves&#x27;</span>: randint(<span class="number">31</span>, <span class="number">127</span>),</span><br><span class="line">    <span class="string">&#x27;min_child_samples&#x27;</span>: randint(<span class="number">5</span>, <span class="number">20</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建LightGBM分类器</span></span><br><span class="line">estimator = lgb.LGBMClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建RandomizedSearchCV对象</span></span><br><span class="line">random_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_dist, n_iter=<span class="number">100</span>, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行随机搜索</span></span><br><span class="line">random_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最佳参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Best parameters:&#x27;</span>, random_search.best_params_)</span><br></pre></td></tr></table></figure>
<h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><blockquote>
<p>多模型可以结合使得稳定</p>
</blockquote>
<blockquote>
<p>集成学习就是把多个弱分类器或回归模型组合起来，变成一个强分类器或回归模型，从而提高预测的准确性。</p>
</blockquote>
<p>实现集成学习的方式有很多种，比如通过投票决定最终结果、取平均值来预测、或者给每个模型分配不同的权重。集成学习的主要思想是通过多个模型之间的合作，来弥补每个模型的不足，使整体模型的预测能力更强。</p>
<blockquote>
<p>常见的集成学习方法:</p>
<ol>
<li>Bagging（自助聚合）：通过在原始数据集上进行多次重采样来创建多个子集，分别训练多个模型，最后进行平均或多数投票决策。</li>
<li>Boosting：训练多个模型，每个模型都尝试纠正前一个模型的错误，通常是序列处理。</li>
<li>Stacking：训练多个不同的模型，然后再训练一个新的模型来综合这些模型的输出。</li>
</ol>
</blockquote>
<h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><p>Stacking 是一种集成学习技术，它将多个模型的预测结果作为输入，然后使用另一个模型（通常称为元模型或元分类器）来进行最终的预测。</p>
<p>举例一个使用Python的 <code>scikit-learn</code> 库实现Stacking：</p>
<p><strong>伪代码</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> StackingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拆分数据集为训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义基模型列表</span></span><br><span class="line">estimators = [</span><br><span class="line">    (<span class="string">&#x27;rf&#x27;</span>, RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)),</span><br><span class="line">    (<span class="string">&#x27;gb&#x27;</span>, GradientBoostingClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)),</span><br><span class="line">    (<span class="string">&#x27;svc&#x27;</span>, SVC(probability=<span class="literal">True</span>, kernel=<span class="string">&#x27;linear&#x27;</span>))</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加元模型</span></span><br><span class="line">estimators.append((<span class="string">&#x27;lr&#x27;</span>, LogisticRegression()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建Stacking分类器</span></span><br><span class="line">stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练Stacking分类器</span></span><br><span class="line">stacking_clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测测试集</span></span><br><span class="line">y_pred = stacking_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test set accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="Stacking模型是什么？"><a href="#Stacking模型是什么？" class="headerlink" title="Stacking模型是什么？"></a>Stacking模型是什么？</h4><p>想象一下，你有好几个不同的老师，他们每个人都对同一组学生进行考试评分。Stacking模型就像是一个“超级老师”，它收集这些不同老师给的分数，然后根据这些分数再给出一个最终的评分。</p>
<h4 id="基模型"><a href="#基模型" class="headerlink" title="基模型"></a>基模型</h4><p>在这个例子里，我们有三个“老师”：</p>
<ul>
<li>第一个老师用的是“随机森林”方法来评分。</li>
<li>第二个老师用的是“梯度提升”方法。</li>
<li>第三个老师用的是“支持向量机”方法。</li>
</ul>
<h4 id="元模型"><a href="#元模型" class="headerlink" title="元模型"></a>元模型</h4><p>然后，我们有一个“超级老师”，也就是我们的元模型，它用的是“逻辑回归”方法来根据前面三个老师的评分给出最终的评分。</p>
<h4 id="为什么要这么做？"><a href="#为什么要这么做？" class="headerlink" title="为什么要这么做？"></a>为什么要这么做？</h4><ul>
<li>有时候，不同的老师（模型）对同一组学生（数据）的看法会有所不同。通过综合他们的意见，我们可以得到一个更全面、更准确的评分。</li>
<li>但是，这也有风险，如果这些老师（模型）都倾向于犯同样的错误，那么“超级老师”也可能跟着犯错。</li>
</ul>
<h4 id="如何实现？"><a href="#如何实现？" class="headerlink" title="如何实现？"></a>如何实现？</h4><ol>
<li>我们首先把学生（数据）分成两部分：一部分用来让每个老师单独评分（训练集），另一部分用来测试最终的评分结果（测试集）。</li>
<li>每个老师都用他们的方法给训练集的学生打分。</li>
<li>然后，我们把这些分数收集起来，让“超级老师”来根据这些分数给出最终的评分。</li>
<li>我们用测试集来看看“超级老师”的评分有多准确。</li>
</ol>
<h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ul>
<li>支持向量机老师需要一个特别的设置（<code>probability=True</code>），这样它才能给出每个学生可能得到每个分数的概率，这对于“超级老师”来说很重要。</li>
<li>我们要小心，不要让“超级老师”太复杂，否则它可能会过度拟合，也就是说，它可能只是在模仿训练集中的分数，而不是真正理解学生的能力。</li>
</ul>
<p>总的来说，Stacking模型是一种很有趣的方法，可以让我们把不同的模型结合起来，得到更好的预测结果。但是，我们也需要小心，确保它不会变得太复杂，导致在新数据上表现不佳。</p>
<h3 id="官方给出的lgb举例"><a href="#官方给出的lgb举例" class="headerlink" title="官方给出的lgb举例"></a>官方给出的lgb举例</h3><blockquote>
<p>假设已有LightGBM、XGBoost和一个简单的神经网络模型，下面是一个使用Stacking方法的Python示例代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> StackingRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设已有数据集 df</span></span><br><span class="line">X = df.drop(<span class="string">&#x27;target&#x27;</span>, axis=<span class="number">1</span>)  <span class="comment"># 特征列</span></span><br><span class="line">y = df[<span class="string">&#x27;target&#x27;</span>]  <span class="comment"># 目标列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义基模型</span></span><br><span class="line">estimators = [</span><br><span class="line">    (<span class="string">&#x27;lgb&#x27;</span>, lgb.LGBMRegressor(objective=<span class="string">&#x27;regression&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;xgb&#x27;</span>, XGBRegressor(objective=<span class="string">&#x27;reg:squarederror&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;mlp&#x27;</span>, MLPRegressor(hidden_layer_sizes=(<span class="number">50</span>, <span class="number">30</span>), max_iter=<span class="number">500</span>))</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义最终的meta-regressor</span></span><br><span class="line">final_estimator = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建Stacking模型</span></span><br><span class="line">stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=final_estimator, cv=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">stacking_regressor.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">y_pred = stacking_regressor.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test MSE: <span class="subst">&#123;mse:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 看每个单独模型的性能</span></span><br><span class="line"><span class="keyword">for</span> name, est <span class="keyword">in</span> stacking_regressor.named_estimators_.items():</span><br><span class="line">    y_pred_individual = est.predict(X_test)</span><br><span class="line">    mse_individual = mean_squared_error(y_test, y_pred_individual)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> Test MSE: <span class="subst">&#123;mse_individual:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h3 id="混合学习"><a href="#混合学习" class="headerlink" title="混合学习"></a>混合学习</h3><p>在解决复杂的生物信息学问题时，机器学习和深度学习的混合方法可以提供强大的工具。<br>这种方法包括两个主要部分：使用深度学习模型进行特征提取，然后使用传统的机器学习模型进行最终的决策。可以使用PyTorch构建深度学习部分，然后将输出特征传递给LightGBM进行分类或回归。这种混合方法结合了深度学习的特征学习能力和传统机器学习模型的效率与解释性，可以在生物信息学问题中提供强大的解决方案。</p>
<h4 id="构建PyTorch模型"><a href="#构建PyTorch模型" class="headerlink" title="构建PyTorch模型"></a>构建PyTorch模型</h4><p>首先，我们定义一个简单的卷积神经网络（CNN）来处理序列数据。这个模型将用于提取有用的特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, TensorDataset</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RegressionCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sequence_length</span>):</span><br><span class="line">        <span class="built_in">super</span>(RegressionCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv1d(in_channels=<span class="number">1</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool1d(kernel_size=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.flatten = nn.Flatten()</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">32</span> * ((sequence_length // <span class="number">2</span>) - <span class="number">1</span>), <span class="number">100</span>)  <span class="comment"># Adjust size accordingly</span></span><br><span class="line">        <span class="variable language_">self</span>.regressor = nn.Linear(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.regressor(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设df是包含序列和目标值的DataFrame</span></span><br><span class="line">sequence_length = <span class="number">100</span>  <span class="comment"># 假定每个序列的长度</span></span><br><span class="line">X = np.array([np.array(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, <span class="built_in">list</span>(seq)))) <span class="keyword">for</span> seq <span class="keyword">in</span> df[<span class="string">&#x27;sequence&#x27;</span>]])</span><br><span class="line">X = X.reshape(X.shape[<span class="number">0</span>], <span class="number">1</span>, sequence_length)</span><br><span class="line">y = df[<span class="string">&#x27;target&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))</span><br><span class="line">test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DataLoader</span></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型和优化器</span></span><br><span class="line">model = RegressionCNN(sequence_length)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, train_loader</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output.view(-<span class="number">1</span>), target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取特征</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_features</span>(<span class="params">model, loader</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    features = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> loader:</span><br><span class="line">            output = model(data)</span><br><span class="line">            features.extend(output.view(-<span class="number">1</span>).numpy())</span><br><span class="line">            labels.extend(target.numpy())</span><br><span class="line">    <span class="keyword">return</span> np.array(features), np.array(labels)</span><br><span class="line"></span><br><span class="line">train_model(model, train_loader)</span><br><span class="line">X_train_features, y_train = extract_features(model, train_loader)</span><br><span class="line">X_test_features, y_test = extract_features(model, test_loader)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="使用LightGBM进行回归"><a href="#使用LightGBM进行回归" class="headerlink" title="使用LightGBM进行回归"></a>使用LightGBM进行回归</h4><p>在获取特征后，我们可以使用LightGBM进行回归预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 使用LightGBM进行最终的预测</span></span><br><span class="line">lgb_regressor = lgb.LGBMRegressor(n_estimators=<span class="number">100</span>, learning_rate=<span class="number">0.05</span>, max_depth=<span class="number">5</span>)</span><br><span class="line">lgb_regressor.fit(X_train_features.reshape(-<span class="number">1</span>, <span class="number">1</span>), y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测和评估</span></span><br><span class="line">y_pred = lgb_regressor.predict(X_test_features.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test MSE: <span class="subst">&#123;mse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="其他思路"><a href="#其他思路" class="headerlink" title="其他思路"></a>其他思路</h3><ul>
<li>集成额外的生物信息学数据库来增强特征。</li>
<li>实施自动化特征选择流程以减少模型复杂性和过拟合。</li>
<li>尝试动态调整学习率，如学习率预热和循环学习率。</li>
<li>考虑多目标优化，同时优化不同评价指标或设计更全面的评价函数。</li>
<li>生物学角度新特征</li>
</ul>
<h3 id="新模型构建"><a href="#新模型构建" class="headerlink" title="新模型构建"></a>新模型构建</h3><ul>
<li>使用attention机制进行end2end的建模，将siRNA序列和target gene序列进行拼接，并捕捉它们之间的相关模式。</li>
<li>利用现有的生物序列基础模型，生成siRNA和target gene序列的表征向量，并将其输入模型以提高预测效果。</li>
</ul>
<h3 id="外部数据集（官方未禁用）"><a href="#外部数据集（官方未禁用）" class="headerlink" title="外部数据集（官方未禁用）"></a>外部数据集（官方未禁用）</h3><h3 id="笔记发布前最新成绩"><a href="#笔记发布前最新成绩" class="headerlink" title="笔记发布前最新成绩"></a>笔记发布前最新成绩</h3><p><img src="/img/downloaded/aHR0cHM6_83ccd8a65a3f431cbbb97b21f3bd31a7.png" alt="在这里插入图片描述"></p>
<h2 id="引用文档"><a href="#引用文档" class="headerlink" title="引用文档"></a>引用文档</h2><blockquote>
<p>siRNA和shRNA:通过基因沉默抑制蛋白表达的工具<br><a target="_blank" rel="noopener" href="http://www.labome.cn/method/siRNAs-and-shRNAs-Tools-for-Protein-Knockdown-by-Gene-Silencing.html">http://www.labome.cn/method/siRNAs-and-shRNAs-Tools-for-Protein-Knockdown-by-Gene-Silencing.html</a><br>Datawhale<br><a target="_blank" rel="noopener" href="https://linklearner.com/activity/12/4/16">https://linklearner.com/activity/12/4/16</a><br>Datawhale<br><a target="_blank" rel="noopener" href="https://linklearner.com/activity/12/4/11">https://linklearner.com/activity/12/4/11</a><br>Datawhale<br><a target="_blank" rel="noopener" href="https://linklearner.com/activity/12/4/5">https://linklearner.com/activity/12/4/5</a><br>Datawhale<br><a target="_blank" rel="noopener" href="https://linklearner.com/activity/12/4/4">https://linklearner.com/activity/12/4/4</a></p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://canjisam.github.io">CanJisam</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://canjisam.github.io/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/">https://canjisam.github.io/2025/03/10/%E4%BB%8E%E9%9B%B6%E5%85%A5%E9%97%A8-AI-for-Science%EF%BC%88AI-%E8%8D%AF%E7%89%A9-%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://canjisam.github.io" target="_blank">诒森的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI4Science/">AI4Science</a></div><div class="post-share"><div class="social-share" data-image="/img/cover/9f13ef7ffc274ea1974a8c4bd3849b26_0.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/03/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%83%A8%E5%88%86/" title="数据结构部分"><img class="cover" src="/img/cover/9f13ef7ffc274ea1974a8c4bd3849b26_2.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">数据结构部分</div></div><div class="info-2"><div class="info-item-1">数据结构部分线性数据结构数组(Array) 定义：连续内存空间存储同类型数据 特点：随机访问，固定大小 操作：插入、删除、查找、遍历、排序  链表(Linked List) 单向链表：每个节点存储数据和后继指针 双向链表：每个节点存储数据和前驱、后继指针 循环链表：尾节点指向头节点 操作：插入、删除、查找、遍历、排序  栈(Stack) 定义：后进先出(LIFO)的线性表 操作：压栈(push)、出栈(pop)、获取栈顶(top) 应用：函数调用、表达式求值、括号匹配  队列(Queue) 定义：先进先出(FIFO)的线性表 类型：普通队列、循环队列、双端队列 操作：入队(enqueue)、出队(dequeue) 应用：任务调度、缓冲区管理  非线性数据结构树(Tree)二叉树(Binary Tree) 完全二叉树 满二叉树 遍历：前序、中序、后序、层序  二叉搜索树(BST) 定义：左子树小于根节点，右子树大于根节点 操作：插入、删除、查找 平均时间复杂度：O(log n)  平衡二叉树(AVL...</div></div></div></a><a class="pagination-related" href="/2025/03/10/408%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%80%83%E7%A0%94%E5%A4%A7%E7%BA%B2%E8%AF%A6%E8%A7%A3/" title="408数据结构考研大纲详解"><img class="cover" src="/img/cover/eca45645431b46fea6db1634a45287b2_3.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">408数据结构考研大纲详解</div></div><div class="info-2"><div class="info-item-1">408数据结构考研大纲详解本文根据计算机专业考研408数据结构大纲，系统地整理了数据结构的核心知识点，包括基本概念、线性表、栈与队列、树与二叉树、图、查找和排序等内容。每个部分都包含了定义、性质、基本操作及其算法实现、时间复杂度分析和典型应用场景，帮助考生全面掌握数据结构的重要知识点。 一、绪论1. 基本概念数据结构是计算机存储、组织数据的方式。数据结构是指相互之间存在一种或多种特定关系的数据元素的集合。 基本术语：  数据：描述客观事物的符号，是计算机中可以操作的对象 数据元素：数据的基本单位 数据项：构成数据元素的不可分割的最小单位 数据对象：性质相同的数据元素的集合 数据类型：一组性质相同的值的集合及定义在此集合上的一组操作 抽象数据类型(ADT)：一个数学模型及定义在该模型上的一组操作  2....</div></div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/cover/avator.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">CanJisam</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">55</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">93</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/canjisam"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/canjisam" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:canjisam@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎关注微信公众号：昨宵梦寐与君语（国内访问更稳定）</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%B9%B3%E5%8F%B0"><span class="toc-number">1.</span> <span class="toc-text">使用平台</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E6%93%8D%E4%BD%9C"><span class="toc-number">1.1.</span> <span class="toc-text">主要操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E8%A7%88"><span class="toc-number">1.1.1.</span> <span class="toc-text">总览</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%B5%9B%E5%B9%B3%E5%8F%B0"><span class="toc-number">2.</span> <span class="toc-text">参赛平台</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task-1-%E8%B7%91%E9%80%9A%E5%9F%BA%E7%BA%BF"><span class="toc-number">3.</span> <span class="toc-text">Task 1 跑通基线</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E7%94%A8%E5%AE%8C%E5%B9%B3%E5%8F%B0%E8%AE%B0%E5%BE%97%E5%85%B3%E9%97%AD%E5%AE%9E%E4%BE%8B%EF%BC%88%E5%8F%B3%E4%B8%8A%E8%A7%92%EF%BC%89"><span class="toc-number">3.0.0.1.</span> <span class="toc-text">注意用完平台记得关闭实例（右上角）!!!</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E7%94%A8%E5%AE%8C%E5%B9%B3%E5%8F%B0%E8%AE%B0%E5%BE%97%E5%85%B3%E9%97%AD%E5%AE%9E%E4%BE%8B%EF%BC%88%E5%8F%B3%E4%B8%8A%E8%A7%92%EF%BC%89-1"><span class="toc-number">3.0.0.2.</span> <span class="toc-text">注意用完平台记得关闭实例（右上角）!!!</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E7%94%A8%E5%AE%8C%E5%B9%B3%E5%8F%B0%E8%AE%B0%E5%BE%97%E5%85%B3%E9%97%AD%E5%AE%9E%E4%BE%8B%EF%BC%88%E5%8F%B3%E4%B8%8A%E8%A7%92%EF%BC%89-2"><span class="toc-number">3.0.0.3.</span> <span class="toc-text">注意用完平台记得关闭实例（右上角）!!! </span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E4%BA%A4%E6%96%87%E4%BB%B6%E8%8E%B7%E5%BE%97%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%88%86%E6%95%B0"><span class="toc-number">3.1.</span> <span class="toc-text">提交文件获得第一个分数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%82%B9%E5%87%BB%E6%8F%90%E4%BA%A4%E7%BB%93%E6%9E%9C%E5%92%8C%E9%80%89%E4%B8%AD%E5%88%9A%E5%88%9A%E4%B8%8B%E8%BD%BD%E7%9A%84%E6%96%87%E4%BB%B6%E7%AD%89%E5%BE%85%E4%B8%8A%E4%BC%A0"><span class="toc-number">3.1.1.</span> <span class="toc-text">点击提交结果和选中刚刚下载的文件等待上传</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%82%B9%E5%87%BB%E6%88%91%E7%9A%84%E6%88%90%E7%BB%A9%E6%9F%A5%E7%9C%8B%E5%88%86%E6%95%B0"><span class="toc-number">3.1.2.</span> <span class="toc-text">点击我的成绩查看分数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E8%A1%A8%E5%A4%B4%E8%AF%B4%E6%98%8E"><span class="toc-number">3.1.3.</span> <span class="toc-text">训练数据表头说明</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E7%9A%84%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93"><span class="toc-number">3.1.3.1.</span> <span class="toc-text">特征的分析总结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Task1-%E7%9F%A5%E8%AF%86%E7%82%B9%E7%BB%88%E7%BB%93"><span class="toc-number">3.2.</span> <span class="toc-text">Task1 知识点终结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%88%86%E8%AF%8D%E5%99%A8%E7%B1%BB"><span class="toc-number">3.2.1.</span> <span class="toc-text">基因组分词器类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#n-gram"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">n-gram</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GRU%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.2.</span> <span class="toc-text">GRU的神经网络模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#GRU%E7%9A%84%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">GRU的数学模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E9%97%A8%EF%BC%88Update-Gate%EF%BC%89"><span class="toc-number">3.2.2.1.1.</span> <span class="toc-text">更新门（Update Gate）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%87%8D%E7%BD%AE%E9%97%A8%EF%BC%88Reset-Gate%EF%BC%89"><span class="toc-number">3.2.2.1.2.</span> <span class="toc-text">重置门（Reset Gate）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%80%99%E9%80%89%E9%9A%90%E8%97%8F%E7%8A%B6%E6%80%81%EF%BC%88Candidate-Hidden-State%EF%BC%89"><span class="toc-number">3.2.2.1.3.</span> <span class="toc-text">候选隐藏状态（Candidate Hidden State）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E9%9A%90%E8%97%8F%E7%8A%B6%E6%80%81%EF%BC%88Final-Hidden-State%EF%BC%89"><span class="toc-number">3.2.2.1.4.</span> <span class="toc-text">最终隐藏状态（Final Hidden State）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">3.2.2.2.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E7%A7%91%E7%9F%A5%E8%AF%86"><span class="toc-number">3.2.3.</span> <span class="toc-text">学科知识</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RNA%E5%B9%B2%E6%89%B0%EF%BC%88RNAi%EF%BC%89"><span class="toc-number">3.2.3.1.</span> <span class="toc-text">RNA干扰（RNAi）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Dicer-%E9%85%B6"><span class="toc-number">3.2.3.2.</span> <span class="toc-text">Dicer 酶</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RNAi%E4%BD%9C%E7%94%A8%E6%9C%BA%E5%88%B6"><span class="toc-number">3.2.3.3.</span> <span class="toc-text">RNAi作用机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8C%96%E5%AD%A6%E4%BF%AE%E9%A5%B0siRNA"><span class="toc-number">3.2.3.4.</span> <span class="toc-text">化学修饰siRNA</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-number">3.2.4.</span> <span class="toc-text">机器学习知识点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#MAE-Mean-Absolute-Error"><span class="toc-number">3.2.4.1.</span> <span class="toc-text">MAE (Mean Absolute Error)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AC%E5%9B%9E%E7%8E%87%EF%BC%88Recall%EF%BC%89"><span class="toc-number">3.2.4.2.</span> <span class="toc-text">召回率（Recall）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#F1%E5%BE%97%E5%88%86"><span class="toc-number">3.2.4.3.</span> <span class="toc-text">F1得分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B2%BE%E7%A1%AE%E5%BA%A6%EF%BC%88Precision%EF%BC%89"><span class="toc-number">3.2.4.4.</span> <span class="toc-text">精确度（Precision）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B5%9B%E9%A2%98%E8%AF%84%E5%88%86%E4%BB%A3%E7%A0%81"><span class="toc-number">3.2.4.4.1.</span> <span class="toc-text">赛题评分代码</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%BC%E5%90%88%E8%AF%84%E5%88%86"><span class="toc-number">3.2.4.5.</span> <span class="toc-text">综合评分</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-1"><span class="toc-number">3.2.4.5.1.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Sigmoid%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.4.6.</span> <span class="toc-text">Sigmoid函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadamard%E4%B9%98%E7%A7%AF"><span class="toc-number">3.2.4.7.</span> <span class="toc-text">Hadamard乘积</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task2"><span class="toc-number">4.</span> <span class="toc-text">Task2</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E8%AF%BB%E5%AE%98%E6%96%B9baseline"><span class="toc-number">4.1.</span> <span class="toc-text">解读官方baseline</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#set-random-seed"><span class="toc-number">4.2.</span> <span class="toc-text">set_random_seed</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SiRNADataset"><span class="toc-number">4.3.</span> <span class="toc-text">SiRNADataset</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SiRNADataset%E7%B1%BB%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">4.3.1.</span> <span class="toc-text">SiRNADataset类的方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="toc-number">4.3.1.1.</span> <span class="toc-text">初始化方法：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#len-%E6%96%B9%E6%B3%95"><span class="toc-number">4.3.1.2.</span> <span class="toc-text">__len__方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#getitem-%E6%96%B9%E6%B3%95"><span class="toc-number">4.3.1.3.</span> <span class="toc-text">__getitem__方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tokenize-and-encode%E6%96%B9%E6%B3%95"><span class="toc-number">4.3.1.4.</span> <span class="toc-text">tokenize_and_encode方法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SiRNAModel-%E7%B1%BB"><span class="toc-number">4.4.</span> <span class="toc-text">SiRNAModel 类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#nn-Module%E7%B1%BB"><span class="toc-number">4.4.1.</span> <span class="toc-text">nn.Module类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#nn-Module%E7%B1%BB%E7%9A%84%E4%BD%9C%E7%94%A8%E6%9C%89%EF%BC%9A"><span class="toc-number">4.4.1.1.</span> <span class="toc-text">nn.Module类的作用有：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%93%E6%9E%84"><span class="toc-number">4.4.1.1.1.</span> <span class="toc-text">定义模型的结构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%87%BD%E6%95%B0"><span class="toc-number">4.4.1.1.2.</span> <span class="toc-text">前向传播函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E7%AE%A1%E7%90%86"><span class="toc-number">4.4.1.1.3.</span> <span class="toc-text">参数管理</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#parameters"><span class="toc-number">4.4.1.1.3.1.</span> <span class="toc-text">parameters()</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#named-parameters"><span class="toc-number">4.4.1.1.3.2.</span> <span class="toc-text">named_parameters()</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD"><span class="toc-number">4.4.1.1.4.</span> <span class="toc-text">模型保存和加载</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#state-dict"><span class="toc-number">4.4.1.1.5.</span> <span class="toc-text">state_dict()</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#load-state-dict"><span class="toc-number">4.4.1.1.6.</span> <span class="toc-text">load_state_dict()</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%B0%86%E5%BA%8F%E5%88%97%E8%BD%AC%E6%8D%A2%E6%88%90%E5%BC%A0%E9%87%8F%E8%BE%93%E5%85%A5%E5%88%B0%E6%A8%A1%E5%9E%8B%E9%87%8C"><span class="toc-number">4.5.</span> <span class="toc-text">如何将序列转换成张量输入到模型里</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%B8%BAsiRNA%E5%BA%8F%E5%88%97%E5%88%86%E9%85%8D%E5%94%AF%E4%B8%80%E6%A0%87%E8%AF%86%E7%AC%A6"><span class="toc-number">4.6.</span> <span class="toc-text">如何为siRNA序列分配唯一标识符</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A6%96%E5%85%88%E8%BF%9B%E8%A1%8C%E5%88%86%E8%AF%8D%E5%A4%84%E7%90%86"><span class="toc-number">4.6.1.</span> <span class="toc-text">首先进行分词处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E6%9C%AA%E6%A0%BC%E5%BC%8F%E5%8C%96%E7%9A%84siRNA-antisense-seq%E7%AD%89%E5%BA%8F%E5%88%97"><span class="toc-number">4.6.1.1.</span> <span class="toc-text">对于未格式化的siRNA_antisense_seq等序列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E6%A0%BC%E5%BC%8F%E5%8C%96%E7%9A%84modified-siRNA-antisense-seq-list%E7%AD%89%E5%BA%8F%E5%88%97"><span class="toc-number">4.6.1.2.</span> <span class="toc-text">对于格式化的modified_siRNA_antisense_seq_list等序列</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E6%89%80%E6%9C%89token%E6%9E%84%E5%BB%BA%E8%AF%8D%E6%B1%87%E8%A1%A8%E3%80%82"><span class="toc-number">4.6.2.</span> <span class="toc-text">基于数据集中所有token构建词汇表。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%9F%BA%E5%9B%A0%E8%AF%8D%E6%B1%87%E8%A1%A8%E4%BB%A3%E7%A0%81"><span class="toc-number">4.6.3.</span> <span class="toc-text">创建基因词汇表代码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%A5%E8%8E%B7%E5%BE%97%E5%BA%8F%E5%88%97%E7%9A%84%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6"><span class="toc-number">4.6.3.1.</span> <span class="toc-text">来获得序列的最大长度</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SiRNADataset%E7%B1%BB"><span class="toc-number">4.6.4.</span> <span class="toc-text">SiRNADataset类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Dataset%E7%B1%BB"><span class="toc-number">4.6.4.1.</span> <span class="toc-text">Dataset类</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RNN%EF%BC%88%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%89%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-number">4.6.5.</span> <span class="toc-text">RNN（递归神经网络）知识点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RNN%E7%9A%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">4.6.5.1.</span> <span class="toc-text">RNN的训练过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RNN-%E7%9A%84%E7%89%B9%E7%82%B9"><span class="toc-number">4.6.5.2.</span> <span class="toc-text">RNN 的特点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%EF%BC%88EDA%EF%BC%89"><span class="toc-number">4.7.</span> <span class="toc-text">数据的特征工程 （EDA）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="toc-number">4.7.1.</span> <span class="toc-text">基本操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86"><span class="toc-number">4.7.1.1.</span> <span class="toc-text">缺失值处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8%E5%80%BC%E5%A4%84%E7%90%86"><span class="toc-number">4.7.1.2.</span> <span class="toc-text">异常值处理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E7%B1%BB%E5%88%AB%E5%9E%8B%E5%8F%98%E9%87%8F"><span class="toc-number">4.7.2.</span> <span class="toc-text">处理类别型变量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E5%94%AF%E4%B8%80%E5%80%BC"><span class="toc-number">4.7.2.1.</span> <span class="toc-text">统计唯一值</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#nunique"><span class="toc-number">4.7.2.1.1.</span> <span class="toc-text">nunique()</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E6%AF%8F%E4%B8%AA%E5%80%BC%E7%9A%84%E9%A2%91%E7%8E%87%E5%88%86%E5%B8%83"><span class="toc-number">4.7.3.</span> <span class="toc-text">统计每个值的频率分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#value-counts"><span class="toc-number">4.7.3.1.</span> <span class="toc-text">value_counts()</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#one-hot%E7%89%B9%E5%BE%81%E7%9A%84%E6%9E%84%E9%80%A0"><span class="toc-number">4.7.4.</span> <span class="toc-text">one-hot特征的构造</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0"><span class="toc-number">4.7.5.</span> <span class="toc-text">时间特征构造</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E8%BF%B0%E5%AF%B9%E6%AF%8F%E4%B8%80%E4%B8%AAsiRNA-duplex-id%E7%9A%84%E8%BF%87%E7%A8%8B%E5%90%8C%E4%B8%8B"><span class="toc-number">4.7.5.1.</span> <span class="toc-text">上述对每一个siRNA_duplex_id的过程同下</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8C%85%E5%90%AB%E6%9F%90%E4%BA%9B%E5%8D%95%E8%AF%8D"><span class="toc-number">4.7.6.</span> <span class="toc-text">包含某些单词</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9df%E4%B8%AD%E7%9A%84cell-line-donor%E5%88%97%E6%9E%84%E9%80%A0%E7%89%B9%E5%BE%81"><span class="toc-number">4.7.6.1.</span> <span class="toc-text">对df中的cell_line_donor列构造特征</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%B0%8F%E7%BB%93"><span class="toc-number">4.7.6.1.1.</span> <span class="toc-text">代码小结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E7%A2%B1%E5%9F%BA%E7%9A%84%E6%A8%A1%E5%BC%8F%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0"><span class="toc-number">4.7.7.</span> <span class="toc-text">对碱基的模式进行特征构造</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E4%B8%8A%E4%B8%80%E4%B8%AAtask%E4%B8%AD%E7%9A%84rna%E7%9F%A5%E8%AF%86%E6%8F%90%E5%8F%96"><span class="toc-number">4.7.7.1.</span> <span class="toc-text">根据上一个task中的rna知识提取</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%B0%8F%E7%BB%93-1"><span class="toc-number">4.7.7.1.1.</span> <span class="toc-text">代码小结</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%90%8E%E9%80%89%E6%8B%A9%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="toc-number">4.8.</span> <span class="toc-text">最后选择模型预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%95%B0"><span class="toc-number">4.8.1.</span> <span class="toc-text">分数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84LightGBM%E5%8F%82%E6%95%B0"><span class="toc-number">4.8.2.</span> <span class="toc-text">一些常用的LightGBM参数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#boosting-type"><span class="toc-number">4.8.2.1.</span> <span class="toc-text">boosting_type</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#objective"><span class="toc-number">4.8.2.2.</span> <span class="toc-text">objective</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#metric"><span class="toc-number">4.8.2.3.</span> <span class="toc-text">metric</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#max-depth"><span class="toc-number">4.8.2.4.</span> <span class="toc-text">max_depth</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#learning-rate"><span class="toc-number">4.8.2.5.</span> <span class="toc-text">learning_rate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#num-boost-round"><span class="toc-number">4.8.2.6.</span> <span class="toc-text">num_boost_round</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#valid-sets"><span class="toc-number">4.8.2.7.</span> <span class="toc-text">valid_sets</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#callbacks"><span class="toc-number">4.8.2.8.</span> <span class="toc-text">callbacks</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#num-leaves"><span class="toc-number">4.8.2.9.</span> <span class="toc-text">num_leaves</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#min-data-in-leaf"><span class="toc-number">4.8.2.10.</span> <span class="toc-text">min_data_in_leaf</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#subsample"><span class="toc-number">4.8.2.11.</span> <span class="toc-text">subsample</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#verbose"><span class="toc-number">4.8.2.12.</span> <span class="toc-text">verbose</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#random-state"><span class="toc-number">4.8.2.13.</span> <span class="toc-text">random_state</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#device-type"><span class="toc-number">4.8.2.14.</span> <span class="toc-text">device_type</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%95%B0-1"><span class="toc-number">4.8.3.</span> <span class="toc-text">分数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Task3"><span class="toc-number">5.</span> <span class="toc-text">Task3</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9task2%E5%BC%95%E5%85%A5%E7%94%9F%E7%89%A9%E7%9F%A5%E8%AF%86"><span class="toc-number">5.1.</span> <span class="toc-text">对task2引入生物知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E9%A5%B0siRNA%E6%9E%84%E5%BB%BA%E7%89%B9%E5%BE%81"><span class="toc-number">5.1.1.</span> <span class="toc-text">修饰siRNA构建特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E9%A5%B0siRNA%E5%BA%8F%E5%88%97%E8%BF%9B%E8%A1%8Cn-gram%E7%9A%84%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1"><span class="toc-number">5.1.2.</span> <span class="toc-text">修饰siRNA序列进行n-gram的词频统计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#tokenizer-%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F"><span class="toc-number">5.1.2.1.</span> <span class="toc-text">tokenizer 的工作方式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#tokenizer1-ngram-1-stride-1"><span class="toc-number">5.1.2.1.1.</span> <span class="toc-text">tokenizer1 (ngram&#x3D;1, stride&#x3D;1)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tokenizer2-ngram-2-stride-2"><span class="toc-number">5.1.2.1.2.</span> <span class="toc-text">tokenizer2 (ngram&#x3D;2, stride&#x3D;2)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tokenizer3-ngram-3-stride-3"><span class="toc-number">5.1.2.1.3.</span> <span class="toc-text">tokenizer3 (ngram&#x3D;3, stride&#x3D;3)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tokenizer6-ngram-6-stride-6"><span class="toc-number">5.1.2.1.4.</span> <span class="toc-text">tokenizer6 (ngram&#x3D;6, stride&#x3D;6)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#siRNA%E5%BA%8F%E5%88%97%E4%B8%8Etarget%E5%BA%8F%E5%88%97%E5%AF%B9%E6%AF%94"><span class="toc-number">5.1.3.</span> <span class="toc-text">siRNA序列与target序列对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E7%94%9F%E7%89%A9%E7%89%B9%E5%BE%81"><span class="toc-number">5.1.4.</span> <span class="toc-text">其他生物特征</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lgb%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96"><span class="toc-number">5.2.</span> <span class="toc-text">lgb模型优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%8ERemaining%E8%8C%83%E5%9B%B4%E6%A0%B7%E6%9C%AC%E9%AB%98%E6%9D%83%E9%87%8D"><span class="toc-number">5.2.1.</span> <span class="toc-text">低Remaining范围样本高权重</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%AE%98%E6%96%B9%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E4%BD%9C%E4%B8%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">5.2.2.</span> <span class="toc-text">使用官方评价指标作为损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="toc-number">5.2.3.</span> <span class="toc-text">自适应学习率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%8A%98%E4%BA%A4%E5%8F%89%E8%AE%AD%E7%BB%83"><span class="toc-number">5.2.4.</span> <span class="toc-text">多折交叉训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E6%88%90%E4%BB%A5%E4%B8%8A%E6%93%8D%E4%BD%9C%E7%9A%84%E5%88%86%E6%95%B0"><span class="toc-number">5.2.5.</span> <span class="toc-text">完成以上操作的分数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96"><span class="toc-number">5.2.6.</span> <span class="toc-text">超参数优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96-%E6%8E%A8%E8%8D%90%EF%BC%89"><span class="toc-number">5.2.6.1.</span> <span class="toc-text">贝叶斯优化(推荐）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2%EF%BC%88Grid-Search%EF%BC%89"><span class="toc-number">5.2.6.2.</span> <span class="toc-text">网格搜索（Grid Search）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%90%9C%E7%B4%A2%EF%BC%88Random-Search%EF%BC%89"><span class="toc-number">5.2.6.3.</span> <span class="toc-text">随机搜索（Random Search）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.3.</span> <span class="toc-text">集成学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Stacking"><span class="toc-number">5.3.1.</span> <span class="toc-text">Stacking</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Stacking%E6%A8%A1%E5%9E%8B%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">5.3.1.1.</span> <span class="toc-text">Stacking模型是什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.3.1.2.</span> <span class="toc-text">基模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.3.1.3.</span> <span class="toc-text">元模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%99%E4%B9%88%E5%81%9A%EF%BC%9F"><span class="toc-number">5.3.1.4.</span> <span class="toc-text">为什么要这么做？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%EF%BC%9F"><span class="toc-number">5.3.1.5.</span> <span class="toc-text">如何实现？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">5.3.1.6.</span> <span class="toc-text">注意事项</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%98%E6%96%B9%E7%BB%99%E5%87%BA%E7%9A%84lgb%E4%B8%BE%E4%BE%8B"><span class="toc-number">5.3.2.</span> <span class="toc-text">官方给出的lgb举例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.3.3.</span> <span class="toc-text">混合学习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%84%E5%BB%BAPyTorch%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.3.3.1.</span> <span class="toc-text">构建PyTorch模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8LightGBM%E8%BF%9B%E8%A1%8C%E5%9B%9E%E5%BD%92"><span class="toc-number">5.3.3.2.</span> <span class="toc-text">使用LightGBM进行回归</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%80%9D%E8%B7%AF"><span class="toc-number">5.3.4.</span> <span class="toc-text">其他思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B0%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA"><span class="toc-number">5.3.5.</span> <span class="toc-text">新模型构建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88%E5%AE%98%E6%96%B9%E6%9C%AA%E7%A6%81%E7%94%A8%EF%BC%89"><span class="toc-number">5.3.6.</span> <span class="toc-text">外部数据集（官方未禁用）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%94%E8%AE%B0%E5%8F%91%E5%B8%83%E5%89%8D%E6%9C%80%E6%96%B0%E6%88%90%E7%BB%A9"><span class="toc-number">5.3.7.</span> <span class="toc-text">笔记发布前最新成绩</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E7%94%A8%E6%96%87%E6%A1%A3"><span class="toc-number">5.4.</span> <span class="toc-text">引用文档</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/08/18/Linux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3/" title="Linux系统管理核心知识点详解"><img src="/img/cover/9f13ef7ffc274ea1974a8c4bd3849b26_0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux系统管理核心知识点详解"/></a><div class="content"><a class="title" href="/2025/08/18/Linux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3/" title="Linux系统管理核心知识点详解">Linux系统管理核心知识点详解</a><time datetime="2025-08-18T15:46:10.000Z" title="发表于 2025-08-18 23:46:10">2025-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/18/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3/" title="计算机网络核心知识点详解"><img src="/img/cover/eca45645431b46fea6db1634a45287b2_1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机网络核心知识点详解"/></a><div class="content"><a class="title" href="/2025/08/18/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3/" title="计算机网络核心知识点详解">计算机网络核心知识点详解</a><time datetime="2025-08-18T15:33:50.000Z" title="发表于 2025-08-18 23:33:50">2025-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/18/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%AC%94%E8%AF%95%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3/" title="数据结构与算法笔试核心知识点详解"><img src="/img/cover/eca45645431b46fea6db1634a45287b2_3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据结构与算法笔试核心知识点详解"/></a><div class="content"><a class="title" href="/2025/08/18/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%AC%94%E8%AF%95%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3/" title="数据结构与算法笔试核心知识点详解">数据结构与算法笔试核心知识点详解</a><time datetime="2025-08-18T14:54:27.000Z" title="发表于 2025-08-18 22:54:27">2025-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/18/JVM%E5%8E%9F%E7%90%86%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/" title="JVM原理深度解析与调优实战"><img src="/img/cover/9f13ef7ffc274ea1974a8c4bd3849b26_2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JVM原理深度解析与调优实战"/></a><div class="content"><a class="title" href="/2025/08/18/JVM%E5%8E%9F%E7%90%86%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/" title="JVM原理深度解析与调优实战">JVM原理深度解析与调优实战</a><time datetime="2025-08-18T14:54:20.000Z" title="发表于 2025-08-18 22:54:20">2025-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/15/JWT%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3/" title="JWT技术详解：原理、应用与最佳实践"><img src="/img/cover/9f13ef7ffc274ea1974a8c4bd3849b26_0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JWT技术详解：原理、应用与最佳实践"/></a><div class="content"><a class="title" href="/2025/08/15/JWT%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3/" title="JWT技术详解：原理、应用与最佳实践">JWT技术详解：原理、应用与最佳实践</a><time datetime="2025-08-15T14:13:47.000Z" title="发表于 2025-08-15 22:13:47">2025-08-15</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/cover/footer-bg.jpg);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By CanJisam</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = {"distractionFreeMode":true}

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: 'Ov23lifFntnoMvOg1Fir',
      clientSecret: '0596c9896ad9c699f2188c823bce11b2d3d231e6',
      repo: 'canjisam.github.io',
      owner: 'canjisam',
      admin: ['canjisam'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || '9a5ffc6f8c21876af0eb95a38f4b35f3'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script>window.XF_API_KEY="33ec326f4348794e214e464ff2990f32"; window.XF_API_SECRET="NDQ3NGYyZWMwZWQ0ZWQ4ZWUzMTMwY2Y4";</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章..." type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>